{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Feature Selection Methods.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Aveef7E_8BKQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EmzjXWrL5Nwy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "5ca4dd4e-3c2a-4d94-b959-bb6c9ed6e773"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XjM9qJAE5Tuk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_path = '/content/drive/My Drive/Projects/Chocolate Features/chocolate.csv'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MuHiRr_p7b5t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data=pd.read_csv(data_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YABR9p6P8Oov",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 149
        },
        "outputId": "13393124-5b7d-49b9-9d51-abeb13c2a611"
      },
      "source": [
        "data.head(2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>ref</th>\n",
              "      <th>company</th>\n",
              "      <th>company_location</th>\n",
              "      <th>review_date</th>\n",
              "      <th>country_of_bean_origin</th>\n",
              "      <th>specific_bean_origin_or_bar_name</th>\n",
              "      <th>cocoa_percent</th>\n",
              "      <th>rating</th>\n",
              "      <th>counts_of_ingredients</th>\n",
              "      <th>beans</th>\n",
              "      <th>cocoa_butter</th>\n",
              "      <th>vanilla</th>\n",
              "      <th>lecithin</th>\n",
              "      <th>salt</th>\n",
              "      <th>sugar</th>\n",
              "      <th>sweetener_without_sugar</th>\n",
              "      <th>first_taste</th>\n",
              "      <th>second_taste</th>\n",
              "      <th>third_taste</th>\n",
              "      <th>fourth_taste</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>2454</td>\n",
              "      <td>5150</td>\n",
              "      <td>U.S.A</td>\n",
              "      <td>2019</td>\n",
              "      <td>Madagascar</td>\n",
              "      <td>Bejofo Estate, batch 1</td>\n",
              "      <td>76.0</td>\n",
              "      <td>3.75</td>\n",
              "      <td>3</td>\n",
              "      <td>have_bean</td>\n",
              "      <td>have_cocoa_butter</td>\n",
              "      <td>have_not_vanila</td>\n",
              "      <td>have_not_lecithin</td>\n",
              "      <td>have_not_salt</td>\n",
              "      <td>have_sugar</td>\n",
              "      <td>have_not_sweetener_without_sugar</td>\n",
              "      <td>cocoa</td>\n",
              "      <td>blackberry</td>\n",
              "      <td>full body</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>2458</td>\n",
              "      <td>5150</td>\n",
              "      <td>U.S.A</td>\n",
              "      <td>2019</td>\n",
              "      <td>Dominican republic</td>\n",
              "      <td>Zorzal, batch 1</td>\n",
              "      <td>76.0</td>\n",
              "      <td>3.50</td>\n",
              "      <td>3</td>\n",
              "      <td>have_bean</td>\n",
              "      <td>have_cocoa_butter</td>\n",
              "      <td>have_not_vanila</td>\n",
              "      <td>have_not_lecithin</td>\n",
              "      <td>have_not_salt</td>\n",
              "      <td>have_sugar</td>\n",
              "      <td>have_not_sweetener_without_sugar</td>\n",
              "      <td>cocoa</td>\n",
              "      <td>vegetal</td>\n",
              "      <td>savory</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0   ref company  ... second_taste  third_taste fourth_taste\n",
              "0           0  2454    5150  ...   blackberry    full body          NaN\n",
              "1           1  2458    5150  ...      vegetal       savory          NaN\n",
              "\n",
              "[2 rows x 21 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0pHU-rTw9Tt7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "a34f90c1-eae6-4963-cd29-07ec45874636"
      },
      "source": [
        "data.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2224, 21)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fd9VOf1q7VPN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 148
        },
        "outputId": "2444b900-edfd-42df-9f57-ef79fd435b0b"
      },
      "source": [
        "data.columns"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['Unnamed: 0', 'ref', 'company', 'company_location', 'review_date',\n",
              "       'country_of_bean_origin', 'specific_bean_origin_or_bar_name',\n",
              "       'cocoa_percent', 'rating', 'counts_of_ingredients', 'beans',\n",
              "       'cocoa_butter', 'vanilla', 'lecithin', 'salt', 'sugar',\n",
              "       'sweetener_without_sugar', 'first_taste', 'second_taste', 'third_taste',\n",
              "       'fourth_taste'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8v3bsi5m8Nph",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Removing unnecessary columns\n",
        "data = data.drop(['ref', 'Unnamed: 0','company'], axis = 1) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hX1LN7NG9YYF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "8ebd86f5-3a91-450e-9e6c-e04811192a50"
      },
      "source": [
        "data.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2224, 18)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bAMLyMdqG3W8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 486
        },
        "outputId": "39bf42e2-4180-43fd-d47c-962f70e34d63"
      },
      "source": [
        "data.info()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 2224 entries, 0 to 2223\n",
            "Data columns (total 18 columns):\n",
            " #   Column                            Non-Null Count  Dtype  \n",
            "---  ------                            --------------  -----  \n",
            " 0   company_location                  2224 non-null   object \n",
            " 1   review_date                       2224 non-null   int64  \n",
            " 2   country_of_bean_origin            2224 non-null   object \n",
            " 3   specific_bean_origin_or_bar_name  2224 non-null   object \n",
            " 4   cocoa_percent                     2224 non-null   float64\n",
            " 5   rating                            2224 non-null   float64\n",
            " 6   counts_of_ingredients             2224 non-null   int64  \n",
            " 7   beans                             2224 non-null   object \n",
            " 8   cocoa_butter                      2224 non-null   object \n",
            " 9   vanilla                           2224 non-null   object \n",
            " 10  lecithin                          2224 non-null   object \n",
            " 11  salt                              2224 non-null   object \n",
            " 12  sugar                             2224 non-null   object \n",
            " 13  sweetener_without_sugar           2224 non-null   object \n",
            " 14  first_taste                       2224 non-null   object \n",
            " 15  second_taste                      2147 non-null   object \n",
            " 16  third_taste                       1604 non-null   object \n",
            " 17  fourth_taste                      242 non-null    object \n",
            "dtypes: float64(2), int64(2), object(14)\n",
            "memory usage: 312.9+ KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "55TUSQp7JCDl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cat_features = ['company_location','review_date','country_of_bean_origin',\n",
        "                'specific_bean_origin_or_bar_name','beans','cocoa_butter',\n",
        "                'vanilla','lecithin','salt','sugar','sweetener_without_sugar',\n",
        "                'first_taste','second_taste','third_taste','fourth_taste']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sbTAHb858ofA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# One-hot encoding\n",
        "hot_chocolate = pd.get_dummies(data,columns=cat_features)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IOTpzsiJ82Fk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "f8763fc1-5a1d-435f-982e-5af84e101418"
      },
      "source": [
        "hot_chocolate.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2224, 2912)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zf-1lf-y88BM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "c35b33f5-43e1-42c4-b357-fc7305135723"
      },
      "source": [
        "data_choc = pd.concat([data, hot_chocolate], axis=1)\n",
        "data_choc.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2224, 2930)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gPwZyUOc9Dv1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Dropping original columns\n",
        "data_finale = data_choc.drop(columns=cat_features,axis = 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MkdfqoVT9Ntl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "5fa5174f-0372-48c5-a6f3-2708064081d8"
      },
      "source": [
        "data_finale.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2224, 2915)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8HHHljMxH6HI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "outputId": "79130b0e-78d2-44e5-ba46-1dda58a17de3"
      },
      "source": [
        "# Checking if there are any duplicate columns\n",
        "dups = data_finale.columns.duplicated()\n",
        "for i in dups:\n",
        "  if i==True:\n",
        "    print(i)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "True\n",
            "True\n",
            "True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xpsgXt_iIMGe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 112
        },
        "outputId": "2786b5ab-ea79-428c-86fd-4707c5c9eec4"
      },
      "source": [
        "# Checking the duplicate column\n",
        "dup_cols = data_finale.loc[:,data_finale.columns.duplicated()]\n",
        "dup_cols.head(2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>cocoa_percent</th>\n",
              "      <th>rating</th>\n",
              "      <th>counts_of_ingredients</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>76.0</td>\n",
              "      <td>3.75</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>76.0</td>\n",
              "      <td>3.50</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   cocoa_percent  rating  counts_of_ingredients\n",
              "0           76.0    3.75                      3\n",
              "1           76.0    3.50                      3"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QiU40GzEIdll",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "outputId": "92228f2e-b8b7-4b7c-b7fc-0e0ea90aafa4"
      },
      "source": [
        "for col in data.columns:\n",
        "  if col in dup_cols.columns:\n",
        "    print(col)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cocoa_percent\n",
            "rating\n",
            "counts_of_ingredients\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GjyM177I9u_o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Removing duplicate columns\n",
        "a = data_finale.loc[:,~data_finale.columns.duplicated()]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dd3QerSf-SZf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "0b3bdc79-88d7-4c8c-da56-b1ab0b7f95aa"
      },
      "source": [
        "a.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2224, 2912)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wr_b2QQDJLLr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        },
        "outputId": "f3ab3505-8159-4bab-9882-479378e1b556"
      },
      "source": [
        "# Checking how many columns each category column is one-hot encoded into\n",
        "for cat in cat_features:\n",
        "  count=0\n",
        "  for cols in data_finale.columns:\n",
        "    if cat in cols:\n",
        "      count=count+1\n",
        "  print(cat,count)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "company_location 66\n",
            "review_date 15\n",
            "country_of_bean_origin 62\n",
            "specific_bean_origin_or_bar_name 1398\n",
            "beans 2\n",
            "cocoa_butter 2\n",
            "vanilla 15\n",
            "lecithin 2\n",
            "salt 9\n",
            "sugar 15\n",
            "sweetener_without_sugar 2\n",
            "first_taste 456\n",
            "second_taste 479\n",
            "third_taste 332\n",
            "fourth_taste 88\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Lcgk8UyLe3V",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "outputId": "60376c5b-0b49-4e9c-a510-abf37b141f79"
      },
      "source": [
        "data_finale.fourth_taste_woody.value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    2222\n",
              "1       2\n",
              "Name: fourth_taste_woody, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oic1U0dW_DtB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "b = a.drop('fourth_taste_woody', axis = 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "verpPF7e_XXH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = b.iloc[:,0:2800]\n",
        "y = a.iloc[:,-1] "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SF0g7E1Z_g58",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 223
        },
        "outputId": "6fdcd558-4c0d-467e-ce1c-cbfef3d5d4f3"
      },
      "source": [
        "X.columns"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['cocoa_percent', 'rating', 'counts_of_ingredients',\n",
              "       'company_location_Argentina', 'company_location_Australia',\n",
              "       'company_location_Austria', 'company_location_Belgium',\n",
              "       'company_location_Bolivia', 'company_location_Brazil',\n",
              "       'company_location_Canada',\n",
              "       ...\n",
              "       'third_taste_synthetic', 'third_taste_tang', 'third_taste_tangerine',\n",
              "       'third_taste_tangy', 'third_taste_tangy wine', 'third_taste_tannic',\n",
              "       'third_taste_tart', 'third_taste_tart red berry', 'third_taste_tea',\n",
              "       'third_taste_then off'],\n",
              "      dtype='object', length=2800)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qn8rRkCW_Y-a",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "e8f8081e-8d1f-45ab-922b-52628f33a159"
      },
      "source": [
        "X.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2224, 2800)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "So-2cjrbA7H6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 223
        },
        "outputId": "47316d09-1a85-4d88-ceb5-0ecb8dc1558f"
      },
      "source": [
        "feature_names = X.iloc[:,0:2800].columns\n",
        "feature_names"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['cocoa_percent', 'rating', 'counts_of_ingredients',\n",
              "       'company_location_Argentina', 'company_location_Australia',\n",
              "       'company_location_Austria', 'company_location_Belgium',\n",
              "       'company_location_Bolivia', 'company_location_Brazil',\n",
              "       'company_location_Canada',\n",
              "       ...\n",
              "       'third_taste_synthetic', 'third_taste_tang', 'third_taste_tangerine',\n",
              "       'third_taste_tangy', 'third_taste_tangy wine', 'third_taste_tannic',\n",
              "       'third_taste_tart', 'third_taste_tart red berry', 'third_taste_tea',\n",
              "       'third_taste_then off'],\n",
              "      dtype='object', length=2800)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4CBU4y9Y_YdM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "253074a2-7585-4f6c-8dbd-ed4213a6c1b6"
      },
      "source": [
        "y.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2224,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sgBNXcAN3WmE",
        "colab_type": "text"
      },
      "source": [
        "# SelectFromModel"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y86WxOMj2z3X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.linear_model import LassoCV\n",
        "from sklearn.feature_selection import SelectFromModel"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WpaorAwF3Xb6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Fit the model\n",
        "clf = LassoCV().fit(X, y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T7GD0W6r3ewa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Selected features\n",
        "importance = np.abs(clf.coef_)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZNEATOYQAtWM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "outputId": "1e5dd017-7c10-43a9-a664-1573163d9b99"
      },
      "source": [
        "print(importance)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1.03255436e-18 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
            " 0.00000000e+00 0.00000000e+00]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BLe0VWvEAvHb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 92
        },
        "outputId": "93e82a84-7d32-4f26-c99d-0109c9e0a0e3"
      },
      "source": [
        "idx_third = importance.argsort()[-3]\n",
        "threshold = importance[idx_third] + 0.01\n",
        "idx_features = (-importance).argsort()[:10]\n",
        "name_features = np.array(feature_names)[idx_features]\n",
        "print('Selected features: {}'.format(name_features))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Selected features: ['cocoa_percent' 'first_taste_pungent raisin' 'first_taste_pure'\n",
            " 'first_taste_raisins' 'first_taste_raisiny' 'first_taste_raspberry'\n",
            " 'first_taste_raw' 'first_taste_red berry' 'first_taste_red fruit'\n",
            " 'first_taste_red wine']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4l97uyL43ojt",
        "colab_type": "text"
      },
      "source": [
        "# Feature ranking with recursive feature elimination"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d7QuujZACZYK",
        "colab_type": "text"
      },
      "source": [
        "> > # With SVC and RFECV"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mw55sMkc3pr-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.svm import SVC\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.feature_selection import RFECV\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XIt0U74a3vaw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 167
        },
        "outputId": "f51bc3d4-eb86-4635-d655-ffb9f7b64ab8"
      },
      "source": [
        "#Fit the model\n",
        "svc = SVC(kernel=\"linear\")\n",
        "rfecv = RFECV(estimator=svc, step=1, cv=StratifiedKFold(2), scoring='accuracy')\n",
        "rfecv.fit(X, y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RFECV(cv=StratifiedKFold(n_splits=2, random_state=None, shuffle=False),\n",
              "      estimator=SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None,\n",
              "                    coef0=0.0, decision_function_shape='ovr', degree=3,\n",
              "                    gamma='scale', kernel='linear', max_iter=-1,\n",
              "                    probability=False, random_state=None, shrinking=True,\n",
              "                    tol=0.001, verbose=False),\n",
              "      min_features_to_select=1, n_jobs=None, scoring='accuracy', step=1,\n",
              "      verbose=0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "23gZltBq3w2L",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 111
        },
        "outputId": "08378e2f-c9b1-458c-b7f4-4444071d9641"
      },
      "source": [
        "#Selected features\n",
        "print(X.columns[rfecv.get_support()])\n",
        "print(\"Optimal number of features : %d\" % rfecv.n_features_)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Index(['specific_bean_origin_or_bar_name_Malo Island, batch Ma20/19',\n",
            "       'specific_bean_origin_or_bar_name_Venezuela, Trinidad',\n",
            "       'second_taste_sweet'],\n",
            "      dtype='object')\n",
            "Optimal number of features : 3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YjRCjVd3BtBo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "9f8f7a61-8728-49d0-d419-ca44ad9961ca"
      },
      "source": [
        "for i in range(X.shape[1]):\n",
        "    print ('Column: %d, Selected %s, Rank: %.3f' % (i, rfecv.support_[i], rfecv.ranking_[i]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Column: 0, Selected False, Rank: 130.000\n",
            "Column: 1, Selected False, Rank: 24.000\n",
            "Column: 2, Selected False, Rank: 30.000\n",
            "Column: 3, Selected False, Rank: 138.000\n",
            "Column: 4, Selected False, Rank: 137.000\n",
            "Column: 5, Selected False, Rank: 136.000\n",
            "Column: 6, Selected False, Rank: 135.000\n",
            "Column: 7, Selected False, Rank: 134.000\n",
            "Column: 8, Selected False, Rank: 147.000\n",
            "Column: 9, Selected False, Rank: 59.000\n",
            "Column: 10, Selected False, Rank: 145.000\n",
            "Column: 11, Selected False, Rank: 146.000\n",
            "Column: 12, Selected False, Rank: 155.000\n",
            "Column: 13, Selected False, Rank: 159.000\n",
            "Column: 14, Selected False, Rank: 162.000\n",
            "Column: 15, Selected False, Rank: 163.000\n",
            "Column: 16, Selected False, Rank: 166.000\n",
            "Column: 17, Selected False, Rank: 168.000\n",
            "Column: 18, Selected False, Rank: 170.000\n",
            "Column: 19, Selected False, Rank: 172.000\n",
            "Column: 20, Selected False, Rank: 73.000\n",
            "Column: 21, Selected False, Rank: 173.000\n",
            "Column: 22, Selected False, Rank: 171.000\n",
            "Column: 23, Selected False, Rank: 169.000\n",
            "Column: 24, Selected False, Rank: 180.000\n",
            "Column: 25, Selected False, Rank: 182.000\n",
            "Column: 26, Selected False, Rank: 184.000\n",
            "Column: 27, Selected False, Rank: 186.000\n",
            "Column: 28, Selected False, Rank: 187.000\n",
            "Column: 29, Selected False, Rank: 190.000\n",
            "Column: 30, Selected False, Rank: 192.000\n",
            "Column: 31, Selected False, Rank: 193.000\n",
            "Column: 32, Selected False, Rank: 97.000\n",
            "Column: 33, Selected False, Rank: 198.000\n",
            "Column: 34, Selected False, Rank: 200.000\n",
            "Column: 35, Selected False, Rank: 201.000\n",
            "Column: 36, Selected False, Rank: 98.000\n",
            "Column: 37, Selected False, Rank: 139.000\n",
            "Column: 38, Selected False, Rank: 176.000\n",
            "Column: 39, Selected False, Rank: 174.000\n",
            "Column: 40, Selected False, Rank: 178.000\n",
            "Column: 41, Selected False, Rank: 179.000\n",
            "Column: 42, Selected False, Rank: 28.000\n",
            "Column: 43, Selected False, Rank: 149.000\n",
            "Column: 44, Selected False, Rank: 151.000\n",
            "Column: 45, Selected False, Rank: 202.000\n",
            "Column: 46, Selected False, Rank: 204.000\n",
            "Column: 47, Selected False, Rank: 206.000\n",
            "Column: 48, Selected False, Rank: 208.000\n",
            "Column: 49, Selected False, Rank: 210.000\n",
            "Column: 50, Selected False, Rank: 212.000\n",
            "Column: 51, Selected False, Rank: 214.000\n",
            "Column: 52, Selected False, Rank: 216.000\n",
            "Column: 53, Selected False, Rank: 218.000\n",
            "Column: 54, Selected False, Rank: 220.000\n",
            "Column: 55, Selected False, Rank: 222.000\n",
            "Column: 56, Selected False, Rank: 224.000\n",
            "Column: 57, Selected False, Rank: 226.000\n",
            "Column: 58, Selected False, Rank: 228.000\n",
            "Column: 59, Selected False, Rank: 230.000\n",
            "Column: 60, Selected False, Rank: 232.000\n",
            "Column: 61, Selected False, Rank: 234.000\n",
            "Column: 62, Selected False, Rank: 117.000\n",
            "Column: 63, Selected False, Rank: 175.000\n",
            "Column: 64, Selected False, Rank: 42.000\n",
            "Column: 65, Selected False, Rank: 10.000\n",
            "Column: 66, Selected False, Rank: 68.000\n",
            "Column: 67, Selected False, Rank: 129.000\n",
            "Column: 68, Selected False, Rank: 143.000\n",
            "Column: 69, Selected False, Rank: 53.000\n",
            "Column: 70, Selected False, Rank: 116.000\n",
            "Column: 71, Selected False, Rank: 39.000\n",
            "Column: 72, Selected False, Rank: 55.000\n",
            "Column: 73, Selected False, Rank: 164.000\n",
            "Column: 74, Selected False, Rank: 5.000\n",
            "Column: 75, Selected False, Rank: 33.000\n",
            "Column: 76, Selected False, Rank: 23.000\n",
            "Column: 77, Selected False, Rank: 31.000\n",
            "Column: 78, Selected False, Rank: 71.000\n",
            "Column: 79, Selected False, Rank: 32.000\n",
            "Column: 80, Selected False, Rank: 266.000\n",
            "Column: 81, Selected False, Rank: 194.000\n",
            "Column: 82, Selected False, Rank: 7.000\n",
            "Column: 83, Selected False, Rank: 238.000\n",
            "Column: 84, Selected False, Rank: 240.000\n",
            "Column: 85, Selected False, Rank: 27.000\n",
            "Column: 86, Selected False, Rank: 4.000\n",
            "Column: 87, Selected False, Rank: 260.000\n",
            "Column: 88, Selected False, Rank: 262.000\n",
            "Column: 89, Selected False, Rank: 246.000\n",
            "Column: 90, Selected False, Rank: 248.000\n",
            "Column: 91, Selected False, Rank: 250.000\n",
            "Column: 92, Selected False, Rank: 252.000\n",
            "Column: 93, Selected False, Rank: 254.000\n",
            "Column: 94, Selected False, Rank: 48.000\n",
            "Column: 95, Selected False, Rank: 195.000\n",
            "Column: 96, Selected False, Rank: 25.000\n",
            "Column: 97, Selected False, Rank: 325.000\n",
            "Column: 98, Selected False, Rank: 324.000\n",
            "Column: 99, Selected False, Rank: 289.000\n",
            "Column: 100, Selected False, Rank: 291.000\n",
            "Column: 101, Selected False, Rank: 293.000\n",
            "Column: 102, Selected False, Rank: 69.000\n",
            "Column: 103, Selected False, Rank: 297.000\n",
            "Column: 104, Selected False, Rank: 299.000\n",
            "Column: 105, Selected False, Rank: 104.000\n",
            "Column: 106, Selected False, Rank: 303.000\n",
            "Column: 107, Selected False, Rank: 37.000\n",
            "Column: 108, Selected False, Rank: 306.000\n",
            "Column: 109, Selected False, Rank: 274.000\n",
            "Column: 110, Selected False, Rank: 276.000\n",
            "Column: 111, Selected False, Rank: 277.000\n",
            "Column: 112, Selected False, Rank: 51.000\n",
            "Column: 113, Selected False, Rank: 282.000\n",
            "Column: 114, Selected False, Rank: 103.000\n",
            "Column: 115, Selected False, Rank: 294.000\n",
            "Column: 116, Selected False, Rank: 300.000\n",
            "Column: 117, Selected False, Rank: 199.000\n",
            "Column: 118, Selected False, Rank: 197.000\n",
            "Column: 119, Selected False, Rank: 112.000\n",
            "Column: 120, Selected False, Rank: 19.000\n",
            "Column: 121, Selected False, Rank: 63.000\n",
            "Column: 122, Selected False, Rank: 374.000\n",
            "Column: 123, Selected False, Rank: 376.000\n",
            "Column: 124, Selected False, Rank: 378.000\n",
            "Column: 125, Selected False, Rank: 380.000\n",
            "Column: 126, Selected False, Rank: 360.000\n",
            "Column: 127, Selected False, Rank: 384.000\n",
            "Column: 128, Selected False, Rank: 386.000\n",
            "Column: 129, Selected False, Rank: 388.000\n",
            "Column: 130, Selected False, Rank: 390.000\n",
            "Column: 131, Selected False, Rank: 392.000\n",
            "Column: 132, Selected False, Rank: 394.000\n",
            "Column: 133, Selected False, Rank: 396.000\n",
            "Column: 134, Selected False, Rank: 398.000\n",
            "Column: 135, Selected False, Rank: 400.000\n",
            "Column: 136, Selected False, Rank: 402.000\n",
            "Column: 137, Selected False, Rank: 404.000\n",
            "Column: 138, Selected False, Rank: 362.000\n",
            "Column: 139, Selected False, Rank: 363.000\n",
            "Column: 140, Selected False, Rank: 313.000\n",
            "Column: 141, Selected False, Rank: 83.000\n",
            "Column: 142, Selected False, Rank: 383.000\n",
            "Column: 143, Selected False, Rank: 3.000\n",
            "Column: 144, Selected False, Rank: 84.000\n",
            "Column: 145, Selected False, Rank: 128.000\n",
            "Column: 146, Selected False, Rank: 413.000\n",
            "Column: 147, Selected False, Rank: 415.000\n",
            "Column: 148, Selected False, Rank: 417.000\n",
            "Column: 149, Selected False, Rank: 428.000\n",
            "Column: 150, Selected False, Rank: 419.000\n",
            "Column: 151, Selected False, Rank: 421.000\n",
            "Column: 152, Selected False, Rank: 423.000\n",
            "Column: 153, Selected False, Rank: 436.000\n",
            "Column: 154, Selected False, Rank: 425.000\n",
            "Column: 155, Selected False, Rank: 429.000\n",
            "Column: 156, Selected False, Rank: 431.000\n",
            "Column: 157, Selected False, Rank: 433.000\n",
            "Column: 158, Selected False, Rank: 78.000\n",
            "Column: 159, Selected False, Rank: 438.000\n",
            "Column: 160, Selected False, Rank: 440.000\n",
            "Column: 161, Selected False, Rank: 442.000\n",
            "Column: 162, Selected False, Rank: 444.000\n",
            "Column: 163, Selected False, Rank: 446.000\n",
            "Column: 164, Selected False, Rank: 448.000\n",
            "Column: 165, Selected False, Rank: 450.000\n",
            "Column: 166, Selected False, Rank: 452.000\n",
            "Column: 167, Selected False, Rank: 454.000\n",
            "Column: 168, Selected False, Rank: 456.000\n",
            "Column: 169, Selected False, Rank: 458.000\n",
            "Column: 170, Selected False, Rank: 460.000\n",
            "Column: 171, Selected False, Rank: 462.000\n",
            "Column: 172, Selected False, Rank: 464.000\n",
            "Column: 173, Selected False, Rank: 466.000\n",
            "Column: 174, Selected False, Rank: 468.000\n",
            "Column: 175, Selected False, Rank: 470.000\n",
            "Column: 176, Selected False, Rank: 472.000\n",
            "Column: 177, Selected False, Rank: 474.000\n",
            "Column: 178, Selected False, Rank: 476.000\n",
            "Column: 179, Selected False, Rank: 478.000\n",
            "Column: 180, Selected False, Rank: 480.000\n",
            "Column: 181, Selected False, Rank: 482.000\n",
            "Column: 182, Selected False, Rank: 484.000\n",
            "Column: 183, Selected False, Rank: 486.000\n",
            "Column: 184, Selected False, Rank: 488.000\n",
            "Column: 185, Selected False, Rank: 490.000\n",
            "Column: 186, Selected False, Rank: 492.000\n",
            "Column: 187, Selected False, Rank: 494.000\n",
            "Column: 188, Selected False, Rank: 496.000\n",
            "Column: 189, Selected False, Rank: 498.000\n",
            "Column: 190, Selected False, Rank: 500.000\n",
            "Column: 191, Selected False, Rank: 502.000\n",
            "Column: 192, Selected False, Rank: 504.000\n",
            "Column: 193, Selected False, Rank: 506.000\n",
            "Column: 194, Selected False, Rank: 509.000\n",
            "Column: 195, Selected False, Rank: 508.000\n",
            "Column: 196, Selected False, Rank: 408.000\n",
            "Column: 197, Selected False, Rank: 514.000\n",
            "Column: 198, Selected False, Rank: 516.000\n",
            "Column: 199, Selected False, Rank: 518.000\n",
            "Column: 200, Selected False, Rank: 520.000\n",
            "Column: 201, Selected False, Rank: 522.000\n",
            "Column: 202, Selected False, Rank: 524.000\n",
            "Column: 203, Selected False, Rank: 526.000\n",
            "Column: 204, Selected False, Rank: 528.000\n",
            "Column: 205, Selected False, Rank: 530.000\n",
            "Column: 206, Selected False, Rank: 532.000\n",
            "Column: 207, Selected False, Rank: 410.000\n",
            "Column: 208, Selected False, Rank: 510.000\n",
            "Column: 209, Selected False, Rank: 329.000\n",
            "Column: 210, Selected False, Rank: 62.000\n",
            "Column: 211, Selected False, Rank: 536.000\n",
            "Column: 212, Selected False, Rank: 538.000\n",
            "Column: 213, Selected False, Rank: 540.000\n",
            "Column: 214, Selected False, Rank: 542.000\n",
            "Column: 215, Selected False, Rank: 544.000\n",
            "Column: 216, Selected False, Rank: 546.000\n",
            "Column: 217, Selected False, Rank: 548.000\n",
            "Column: 218, Selected False, Rank: 550.000\n",
            "Column: 219, Selected False, Rank: 552.000\n",
            "Column: 220, Selected False, Rank: 554.000\n",
            "Column: 221, Selected False, Rank: 556.000\n",
            "Column: 222, Selected False, Rank: 558.000\n",
            "Column: 223, Selected False, Rank: 560.000\n",
            "Column: 224, Selected False, Rank: 562.000\n",
            "Column: 225, Selected False, Rank: 564.000\n",
            "Column: 226, Selected False, Rank: 566.000\n",
            "Column: 227, Selected False, Rank: 568.000\n",
            "Column: 228, Selected False, Rank: 570.000\n",
            "Column: 229, Selected False, Rank: 572.000\n",
            "Column: 230, Selected False, Rank: 574.000\n",
            "Column: 231, Selected False, Rank: 576.000\n",
            "Column: 232, Selected False, Rank: 578.000\n",
            "Column: 233, Selected False, Rank: 580.000\n",
            "Column: 234, Selected False, Rank: 582.000\n",
            "Column: 235, Selected False, Rank: 584.000\n",
            "Column: 236, Selected False, Rank: 586.000\n",
            "Column: 237, Selected False, Rank: 588.000\n",
            "Column: 238, Selected False, Rank: 590.000\n",
            "Column: 239, Selected False, Rank: 592.000\n",
            "Column: 240, Selected False, Rank: 594.000\n",
            "Column: 241, Selected False, Rank: 596.000\n",
            "Column: 242, Selected False, Rank: 598.000\n",
            "Column: 243, Selected False, Rank: 600.000\n",
            "Column: 244, Selected False, Rank: 602.000\n",
            "Column: 245, Selected False, Rank: 604.000\n",
            "Column: 246, Selected False, Rank: 606.000\n",
            "Column: 247, Selected False, Rank: 608.000\n",
            "Column: 248, Selected False, Rank: 610.000\n",
            "Column: 249, Selected False, Rank: 612.000\n",
            "Column: 250, Selected False, Rank: 614.000\n",
            "Column: 251, Selected False, Rank: 616.000\n",
            "Column: 252, Selected False, Rank: 618.000\n",
            "Column: 253, Selected False, Rank: 620.000\n",
            "Column: 254, Selected False, Rank: 622.000\n",
            "Column: 255, Selected False, Rank: 624.000\n",
            "Column: 256, Selected False, Rank: 626.000\n",
            "Column: 257, Selected False, Rank: 628.000\n",
            "Column: 258, Selected False, Rank: 630.000\n",
            "Column: 259, Selected False, Rank: 632.000\n",
            "Column: 260, Selected False, Rank: 634.000\n",
            "Column: 261, Selected False, Rank: 636.000\n",
            "Column: 262, Selected False, Rank: 638.000\n",
            "Column: 263, Selected False, Rank: 640.000\n",
            "Column: 264, Selected False, Rank: 642.000\n",
            "Column: 265, Selected False, Rank: 644.000\n",
            "Column: 266, Selected False, Rank: 646.000\n",
            "Column: 267, Selected False, Rank: 648.000\n",
            "Column: 268, Selected False, Rank: 650.000\n",
            "Column: 269, Selected False, Rank: 652.000\n",
            "Column: 270, Selected False, Rank: 654.000\n",
            "Column: 271, Selected False, Rank: 656.000\n",
            "Column: 272, Selected False, Rank: 658.000\n",
            "Column: 273, Selected False, Rank: 660.000\n",
            "Column: 274, Selected False, Rank: 662.000\n",
            "Column: 275, Selected False, Rank: 664.000\n",
            "Column: 276, Selected False, Rank: 666.000\n",
            "Column: 277, Selected False, Rank: 668.000\n",
            "Column: 278, Selected False, Rank: 670.000\n",
            "Column: 279, Selected False, Rank: 672.000\n",
            "Column: 280, Selected False, Rank: 674.000\n",
            "Column: 281, Selected False, Rank: 676.000\n",
            "Column: 282, Selected False, Rank: 694.000\n",
            "Column: 283, Selected False, Rank: 696.000\n",
            "Column: 284, Selected False, Rank: 698.000\n",
            "Column: 285, Selected False, Rank: 700.000\n",
            "Column: 286, Selected False, Rank: 702.000\n",
            "Column: 287, Selected False, Rank: 704.000\n",
            "Column: 288, Selected False, Rank: 706.000\n",
            "Column: 289, Selected False, Rank: 708.000\n",
            "Column: 290, Selected False, Rank: 678.000\n",
            "Column: 291, Selected False, Rank: 680.000\n",
            "Column: 292, Selected False, Rank: 682.000\n",
            "Column: 293, Selected False, Rank: 691.000\n",
            "Column: 294, Selected False, Rank: 690.000\n",
            "Column: 295, Selected False, Rank: 684.000\n",
            "Column: 296, Selected False, Rank: 686.000\n",
            "Column: 297, Selected False, Rank: 714.000\n",
            "Column: 298, Selected False, Rank: 716.000\n",
            "Column: 299, Selected False, Rank: 718.000\n",
            "Column: 300, Selected False, Rank: 720.000\n",
            "Column: 301, Selected False, Rank: 722.000\n",
            "Column: 302, Selected False, Rank: 724.000\n",
            "Column: 303, Selected False, Rank: 726.000\n",
            "Column: 304, Selected False, Rank: 728.000\n",
            "Column: 305, Selected False, Rank: 730.000\n",
            "Column: 306, Selected False, Rank: 732.000\n",
            "Column: 307, Selected False, Rank: 734.000\n",
            "Column: 308, Selected False, Rank: 736.000\n",
            "Column: 309, Selected False, Rank: 738.000\n",
            "Column: 310, Selected False, Rank: 740.000\n",
            "Column: 311, Selected False, Rank: 742.000\n",
            "Column: 312, Selected False, Rank: 744.000\n",
            "Column: 313, Selected False, Rank: 746.000\n",
            "Column: 314, Selected False, Rank: 748.000\n",
            "Column: 315, Selected False, Rank: 750.000\n",
            "Column: 316, Selected False, Rank: 752.000\n",
            "Column: 317, Selected False, Rank: 754.000\n",
            "Column: 318, Selected False, Rank: 756.000\n",
            "Column: 319, Selected False, Rank: 758.000\n",
            "Column: 320, Selected False, Rank: 760.000\n",
            "Column: 321, Selected False, Rank: 762.000\n",
            "Column: 322, Selected False, Rank: 764.000\n",
            "Column: 323, Selected False, Rank: 766.000\n",
            "Column: 324, Selected False, Rank: 768.000\n",
            "Column: 325, Selected False, Rank: 770.000\n",
            "Column: 326, Selected False, Rank: 772.000\n",
            "Column: 327, Selected False, Rank: 774.000\n",
            "Column: 328, Selected False, Rank: 776.000\n",
            "Column: 329, Selected False, Rank: 778.000\n",
            "Column: 330, Selected False, Rank: 780.000\n",
            "Column: 331, Selected False, Rank: 782.000\n",
            "Column: 332, Selected False, Rank: 784.000\n",
            "Column: 333, Selected False, Rank: 786.000\n",
            "Column: 334, Selected False, Rank: 788.000\n",
            "Column: 335, Selected False, Rank: 790.000\n",
            "Column: 336, Selected False, Rank: 792.000\n",
            "Column: 337, Selected False, Rank: 794.000\n",
            "Column: 338, Selected False, Rank: 796.000\n",
            "Column: 339, Selected False, Rank: 798.000\n",
            "Column: 340, Selected False, Rank: 800.000\n",
            "Column: 341, Selected False, Rank: 802.000\n",
            "Column: 342, Selected False, Rank: 804.000\n",
            "Column: 343, Selected False, Rank: 806.000\n",
            "Column: 344, Selected False, Rank: 808.000\n",
            "Column: 345, Selected False, Rank: 810.000\n",
            "Column: 346, Selected False, Rank: 812.000\n",
            "Column: 347, Selected False, Rank: 814.000\n",
            "Column: 348, Selected False, Rank: 816.000\n",
            "Column: 349, Selected False, Rank: 828.000\n",
            "Column: 350, Selected False, Rank: 830.000\n",
            "Column: 351, Selected False, Rank: 832.000\n",
            "Column: 352, Selected False, Rank: 834.000\n",
            "Column: 353, Selected False, Rank: 836.000\n",
            "Column: 354, Selected False, Rank: 838.000\n",
            "Column: 355, Selected False, Rank: 840.000\n",
            "Column: 356, Selected False, Rank: 842.000\n",
            "Column: 357, Selected False, Rank: 844.000\n",
            "Column: 358, Selected False, Rank: 846.000\n",
            "Column: 359, Selected False, Rank: 848.000\n",
            "Column: 360, Selected False, Rank: 850.000\n",
            "Column: 361, Selected False, Rank: 852.000\n",
            "Column: 362, Selected False, Rank: 854.000\n",
            "Column: 363, Selected False, Rank: 856.000\n",
            "Column: 364, Selected False, Rank: 858.000\n",
            "Column: 365, Selected False, Rank: 860.000\n",
            "Column: 366, Selected False, Rank: 862.000\n",
            "Column: 367, Selected False, Rank: 865.000\n",
            "Column: 368, Selected False, Rank: 864.000\n",
            "Column: 369, Selected False, Rank: 818.000\n",
            "Column: 370, Selected False, Rank: 820.000\n",
            "Column: 371, Selected False, Rank: 867.000\n",
            "Column: 372, Selected False, Rank: 869.000\n",
            "Column: 373, Selected False, Rank: 868.000\n",
            "Column: 374, Selected False, Rank: 866.000\n",
            "Column: 375, Selected False, Rank: 827.000\n",
            "Column: 376, Selected False, Rank: 826.000\n",
            "Column: 377, Selected False, Rank: 822.000\n",
            "Column: 378, Selected False, Rank: 825.000\n",
            "Column: 379, Selected False, Rank: 824.000\n",
            "Column: 380, Selected False, Rank: 692.000\n",
            "Column: 381, Selected False, Rank: 693.000\n",
            "Column: 382, Selected False, Rank: 688.000\n",
            "Column: 383, Selected False, Rank: 689.000\n",
            "Column: 384, Selected False, Rank: 91.000\n",
            "Column: 385, Selected False, Rank: 901.000\n",
            "Column: 386, Selected False, Rank: 903.000\n",
            "Column: 387, Selected False, Rank: 905.000\n",
            "Column: 388, Selected False, Rank: 907.000\n",
            "Column: 389, Selected False, Rank: 909.000\n",
            "Column: 390, Selected False, Rank: 911.000\n",
            "Column: 391, Selected False, Rank: 913.000\n",
            "Column: 392, Selected False, Rank: 915.000\n",
            "Column: 393, Selected False, Rank: 917.000\n",
            "Column: 394, Selected False, Rank: 919.000\n",
            "Column: 395, Selected False, Rank: 921.000\n",
            "Column: 396, Selected False, Rank: 109.000\n",
            "Column: 397, Selected False, Rank: 925.000\n",
            "Column: 398, Selected False, Rank: 927.000\n",
            "Column: 399, Selected False, Rank: 929.000\n",
            "Column: 400, Selected False, Rank: 931.000\n",
            "Column: 401, Selected False, Rank: 933.000\n",
            "Column: 402, Selected False, Rank: 935.000\n",
            "Column: 403, Selected False, Rank: 937.000\n",
            "Column: 404, Selected False, Rank: 939.000\n",
            "Column: 405, Selected False, Rank: 941.000\n",
            "Column: 406, Selected False, Rank: 943.000\n",
            "Column: 407, Selected False, Rank: 945.000\n",
            "Column: 408, Selected False, Rank: 947.000\n",
            "Column: 409, Selected False, Rank: 949.000\n",
            "Column: 410, Selected False, Rank: 951.000\n",
            "Column: 411, Selected False, Rank: 953.000\n",
            "Column: 412, Selected False, Rank: 955.000\n",
            "Column: 413, Selected False, Rank: 957.000\n",
            "Column: 414, Selected False, Rank: 959.000\n",
            "Column: 415, Selected False, Rank: 961.000\n",
            "Column: 416, Selected False, Rank: 963.000\n",
            "Column: 417, Selected False, Rank: 965.000\n",
            "Column: 418, Selected False, Rank: 967.000\n",
            "Column: 419, Selected False, Rank: 969.000\n",
            "Column: 420, Selected False, Rank: 971.000\n",
            "Column: 421, Selected False, Rank: 973.000\n",
            "Column: 422, Selected False, Rank: 975.000\n",
            "Column: 423, Selected False, Rank: 977.000\n",
            "Column: 424, Selected False, Rank: 85.000\n",
            "Column: 425, Selected False, Rank: 981.000\n",
            "Column: 426, Selected False, Rank: 983.000\n",
            "Column: 427, Selected False, Rank: 985.000\n",
            "Column: 428, Selected False, Rank: 987.000\n",
            "Column: 429, Selected False, Rank: 989.000\n",
            "Column: 430, Selected False, Rank: 991.000\n",
            "Column: 431, Selected False, Rank: 993.000\n",
            "Column: 432, Selected False, Rank: 995.000\n",
            "Column: 433, Selected False, Rank: 997.000\n",
            "Column: 434, Selected False, Rank: 999.000\n",
            "Column: 435, Selected False, Rank: 1001.000\n",
            "Column: 436, Selected False, Rank: 1003.000\n",
            "Column: 437, Selected False, Rank: 1005.000\n",
            "Column: 438, Selected False, Rank: 1007.000\n",
            "Column: 439, Selected False, Rank: 126.000\n",
            "Column: 440, Selected False, Rank: 1011.000\n",
            "Column: 441, Selected False, Rank: 1013.000\n",
            "Column: 442, Selected False, Rank: 1015.000\n",
            "Column: 443, Selected False, Rank: 1017.000\n",
            "Column: 444, Selected False, Rank: 1019.000\n",
            "Column: 445, Selected False, Rank: 1021.000\n",
            "Column: 446, Selected False, Rank: 1023.000\n",
            "Column: 447, Selected False, Rank: 1025.000\n",
            "Column: 448, Selected False, Rank: 1027.000\n",
            "Column: 449, Selected False, Rank: 1029.000\n",
            "Column: 450, Selected False, Rank: 1031.000\n",
            "Column: 451, Selected False, Rank: 1033.000\n",
            "Column: 452, Selected False, Rank: 1035.000\n",
            "Column: 453, Selected False, Rank: 1037.000\n",
            "Column: 454, Selected False, Rank: 1039.000\n",
            "Column: 455, Selected False, Rank: 1041.000\n",
            "Column: 456, Selected False, Rank: 1043.000\n",
            "Column: 457, Selected False, Rank: 1045.000\n",
            "Column: 458, Selected False, Rank: 1047.000\n",
            "Column: 459, Selected False, Rank: 1049.000\n",
            "Column: 460, Selected False, Rank: 1051.000\n",
            "Column: 461, Selected False, Rank: 1053.000\n",
            "Column: 462, Selected False, Rank: 1055.000\n",
            "Column: 463, Selected False, Rank: 1057.000\n",
            "Column: 464, Selected False, Rank: 1059.000\n",
            "Column: 465, Selected False, Rank: 1061.000\n",
            "Column: 466, Selected False, Rank: 1063.000\n",
            "Column: 467, Selected False, Rank: 1065.000\n",
            "Column: 468, Selected False, Rank: 1067.000\n",
            "Column: 469, Selected False, Rank: 1069.000\n",
            "Column: 470, Selected False, Rank: 1071.000\n",
            "Column: 471, Selected False, Rank: 1073.000\n",
            "Column: 472, Selected False, Rank: 1075.000\n",
            "Column: 473, Selected False, Rank: 1077.000\n",
            "Column: 474, Selected False, Rank: 1079.000\n",
            "Column: 475, Selected False, Rank: 1081.000\n",
            "Column: 476, Selected False, Rank: 1083.000\n",
            "Column: 477, Selected False, Rank: 1085.000\n",
            "Column: 478, Selected False, Rank: 1087.000\n",
            "Column: 479, Selected False, Rank: 1089.000\n",
            "Column: 480, Selected False, Rank: 1091.000\n",
            "Column: 481, Selected False, Rank: 1093.000\n",
            "Column: 482, Selected False, Rank: 1095.000\n",
            "Column: 483, Selected False, Rank: 1097.000\n",
            "Column: 484, Selected False, Rank: 1099.000\n",
            "Column: 485, Selected False, Rank: 1101.000\n",
            "Column: 486, Selected False, Rank: 1103.000\n",
            "Column: 487, Selected False, Rank: 1105.000\n",
            "Column: 488, Selected False, Rank: 1107.000\n",
            "Column: 489, Selected False, Rank: 1109.000\n",
            "Column: 490, Selected False, Rank: 1111.000\n",
            "Column: 491, Selected False, Rank: 1113.000\n",
            "Column: 492, Selected False, Rank: 1115.000\n",
            "Column: 493, Selected False, Rank: 1117.000\n",
            "Column: 494, Selected False, Rank: 1119.000\n",
            "Column: 495, Selected False, Rank: 1121.000\n",
            "Column: 496, Selected False, Rank: 1123.000\n",
            "Column: 497, Selected False, Rank: 1125.000\n",
            "Column: 498, Selected False, Rank: 1127.000\n",
            "Column: 499, Selected False, Rank: 1129.000\n",
            "Column: 500, Selected False, Rank: 1131.000\n",
            "Column: 501, Selected False, Rank: 1133.000\n",
            "Column: 502, Selected False, Rank: 1135.000\n",
            "Column: 503, Selected False, Rank: 1137.000\n",
            "Column: 504, Selected False, Rank: 57.000\n",
            "Column: 505, Selected False, Rank: 1141.000\n",
            "Column: 506, Selected False, Rank: 1143.000\n",
            "Column: 507, Selected False, Rank: 1145.000\n",
            "Column: 508, Selected False, Rank: 1147.000\n",
            "Column: 509, Selected False, Rank: 1149.000\n",
            "Column: 510, Selected False, Rank: 1151.000\n",
            "Column: 511, Selected False, Rank: 1153.000\n",
            "Column: 512, Selected False, Rank: 1155.000\n",
            "Column: 513, Selected False, Rank: 1157.000\n",
            "Column: 514, Selected False, Rank: 1159.000\n",
            "Column: 515, Selected False, Rank: 1161.000\n",
            "Column: 516, Selected False, Rank: 1163.000\n",
            "Column: 517, Selected False, Rank: 1165.000\n",
            "Column: 518, Selected False, Rank: 1167.000\n",
            "Column: 519, Selected False, Rank: 1169.000\n",
            "Column: 520, Selected False, Rank: 1171.000\n",
            "Column: 521, Selected False, Rank: 1173.000\n",
            "Column: 522, Selected False, Rank: 1175.000\n",
            "Column: 523, Selected False, Rank: 1177.000\n",
            "Column: 524, Selected False, Rank: 1179.000\n",
            "Column: 525, Selected False, Rank: 1181.000\n",
            "Column: 526, Selected False, Rank: 1183.000\n",
            "Column: 527, Selected False, Rank: 1185.000\n",
            "Column: 528, Selected False, Rank: 1187.000\n",
            "Column: 529, Selected False, Rank: 1189.000\n",
            "Column: 530, Selected False, Rank: 1191.000\n",
            "Column: 531, Selected False, Rank: 1193.000\n",
            "Column: 532, Selected False, Rank: 1195.000\n",
            "Column: 533, Selected False, Rank: 1197.000\n",
            "Column: 534, Selected False, Rank: 1199.000\n",
            "Column: 535, Selected False, Rank: 1201.000\n",
            "Column: 536, Selected False, Rank: 1203.000\n",
            "Column: 537, Selected False, Rank: 1205.000\n",
            "Column: 538, Selected False, Rank: 1207.000\n",
            "Column: 539, Selected False, Rank: 1209.000\n",
            "Column: 540, Selected False, Rank: 1211.000\n",
            "Column: 541, Selected False, Rank: 1213.000\n",
            "Column: 542, Selected False, Rank: 1215.000\n",
            "Column: 543, Selected False, Rank: 1217.000\n",
            "Column: 544, Selected False, Rank: 1219.000\n",
            "Column: 545, Selected False, Rank: 1221.000\n",
            "Column: 546, Selected False, Rank: 1223.000\n",
            "Column: 547, Selected False, Rank: 1225.000\n",
            "Column: 548, Selected False, Rank: 1227.000\n",
            "Column: 549, Selected False, Rank: 1229.000\n",
            "Column: 550, Selected False, Rank: 1231.000\n",
            "Column: 551, Selected False, Rank: 35.000\n",
            "Column: 552, Selected False, Rank: 1235.000\n",
            "Column: 553, Selected False, Rank: 121.000\n",
            "Column: 554, Selected False, Rank: 1239.000\n",
            "Column: 555, Selected False, Rank: 1241.000\n",
            "Column: 556, Selected False, Rank: 1243.000\n",
            "Column: 557, Selected False, Rank: 1245.000\n",
            "Column: 558, Selected False, Rank: 1247.000\n",
            "Column: 559, Selected False, Rank: 1249.000\n",
            "Column: 560, Selected False, Rank: 1251.000\n",
            "Column: 561, Selected False, Rank: 1253.000\n",
            "Column: 562, Selected False, Rank: 1255.000\n",
            "Column: 563, Selected False, Rank: 1257.000\n",
            "Column: 564, Selected False, Rank: 1259.000\n",
            "Column: 565, Selected False, Rank: 1261.000\n",
            "Column: 566, Selected False, Rank: 1263.000\n",
            "Column: 567, Selected False, Rank: 1265.000\n",
            "Column: 568, Selected False, Rank: 1267.000\n",
            "Column: 569, Selected False, Rank: 1269.000\n",
            "Column: 570, Selected False, Rank: 95.000\n",
            "Column: 571, Selected False, Rank: 1273.000\n",
            "Column: 572, Selected False, Rank: 1275.000\n",
            "Column: 573, Selected False, Rank: 1277.000\n",
            "Column: 574, Selected False, Rank: 43.000\n",
            "Column: 575, Selected False, Rank: 1281.000\n",
            "Column: 576, Selected False, Rank: 1283.000\n",
            "Column: 577, Selected False, Rank: 1285.000\n",
            "Column: 578, Selected False, Rank: 1287.000\n",
            "Column: 579, Selected False, Rank: 1289.000\n",
            "Column: 580, Selected False, Rank: 1291.000\n",
            "Column: 581, Selected False, Rank: 1293.000\n",
            "Column: 582, Selected False, Rank: 1295.000\n",
            "Column: 583, Selected False, Rank: 1297.000\n",
            "Column: 584, Selected False, Rank: 1299.000\n",
            "Column: 585, Selected False, Rank: 1301.000\n",
            "Column: 586, Selected False, Rank: 1303.000\n",
            "Column: 587, Selected False, Rank: 1305.000\n",
            "Column: 588, Selected False, Rank: 1307.000\n",
            "Column: 589, Selected False, Rank: 1309.000\n",
            "Column: 590, Selected False, Rank: 1311.000\n",
            "Column: 591, Selected False, Rank: 1313.000\n",
            "Column: 592, Selected False, Rank: 1315.000\n",
            "Column: 593, Selected False, Rank: 1317.000\n",
            "Column: 594, Selected False, Rank: 1319.000\n",
            "Column: 595, Selected False, Rank: 1321.000\n",
            "Column: 596, Selected False, Rank: 1323.000\n",
            "Column: 597, Selected False, Rank: 1325.000\n",
            "Column: 598, Selected False, Rank: 1327.000\n",
            "Column: 599, Selected False, Rank: 1329.000\n",
            "Column: 600, Selected False, Rank: 1331.000\n",
            "Column: 601, Selected False, Rank: 1333.000\n",
            "Column: 602, Selected False, Rank: 1335.000\n",
            "Column: 603, Selected False, Rank: 1337.000\n",
            "Column: 604, Selected False, Rank: 1339.000\n",
            "Column: 605, Selected False, Rank: 1341.000\n",
            "Column: 606, Selected False, Rank: 1343.000\n",
            "Column: 607, Selected False, Rank: 1345.000\n",
            "Column: 608, Selected False, Rank: 1347.000\n",
            "Column: 609, Selected False, Rank: 1349.000\n",
            "Column: 610, Selected False, Rank: 1351.000\n",
            "Column: 611, Selected False, Rank: 1353.000\n",
            "Column: 612, Selected False, Rank: 1355.000\n",
            "Column: 613, Selected False, Rank: 1357.000\n",
            "Column: 614, Selected False, Rank: 1359.000\n",
            "Column: 615, Selected False, Rank: 1361.000\n",
            "Column: 616, Selected False, Rank: 1363.000\n",
            "Column: 617, Selected False, Rank: 1365.000\n",
            "Column: 618, Selected False, Rank: 1367.000\n",
            "Column: 619, Selected False, Rank: 1369.000\n",
            "Column: 620, Selected False, Rank: 1371.000\n",
            "Column: 621, Selected False, Rank: 1373.000\n",
            "Column: 622, Selected False, Rank: 1375.000\n",
            "Column: 623, Selected False, Rank: 1377.000\n",
            "Column: 624, Selected False, Rank: 1379.000\n",
            "Column: 625, Selected False, Rank: 1381.000\n",
            "Column: 626, Selected False, Rank: 1383.000\n",
            "Column: 627, Selected False, Rank: 1385.000\n",
            "Column: 628, Selected False, Rank: 1387.000\n",
            "Column: 629, Selected False, Rank: 1389.000\n",
            "Column: 630, Selected False, Rank: 1391.000\n",
            "Column: 631, Selected False, Rank: 1393.000\n",
            "Column: 632, Selected False, Rank: 1395.000\n",
            "Column: 633, Selected False, Rank: 1397.000\n",
            "Column: 634, Selected False, Rank: 1399.000\n",
            "Column: 635, Selected False, Rank: 1401.000\n",
            "Column: 636, Selected False, Rank: 1403.000\n",
            "Column: 637, Selected False, Rank: 1405.000\n",
            "Column: 638, Selected False, Rank: 1407.000\n",
            "Column: 639, Selected False, Rank: 1409.000\n",
            "Column: 640, Selected False, Rank: 1411.000\n",
            "Column: 641, Selected False, Rank: 1413.000\n",
            "Column: 642, Selected False, Rank: 1415.000\n",
            "Column: 643, Selected False, Rank: 1417.000\n",
            "Column: 644, Selected False, Rank: 1419.000\n",
            "Column: 645, Selected False, Rank: 1421.000\n",
            "Column: 646, Selected False, Rank: 1423.000\n",
            "Column: 647, Selected False, Rank: 1425.000\n",
            "Column: 648, Selected False, Rank: 1427.000\n",
            "Column: 649, Selected False, Rank: 1429.000\n",
            "Column: 650, Selected False, Rank: 1431.000\n",
            "Column: 651, Selected False, Rank: 1433.000\n",
            "Column: 652, Selected False, Rank: 1435.000\n",
            "Column: 653, Selected False, Rank: 1437.000\n",
            "Column: 654, Selected False, Rank: 1439.000\n",
            "Column: 655, Selected False, Rank: 1441.000\n",
            "Column: 656, Selected False, Rank: 119.000\n",
            "Column: 657, Selected False, Rank: 1445.000\n",
            "Column: 658, Selected False, Rank: 1447.000\n",
            "Column: 659, Selected False, Rank: 1449.000\n",
            "Column: 660, Selected False, Rank: 1451.000\n",
            "Column: 661, Selected False, Rank: 1453.000\n",
            "Column: 662, Selected False, Rank: 1455.000\n",
            "Column: 663, Selected False, Rank: 1457.000\n",
            "Column: 664, Selected False, Rank: 1459.000\n",
            "Column: 665, Selected False, Rank: 1461.000\n",
            "Column: 666, Selected False, Rank: 1463.000\n",
            "Column: 667, Selected False, Rank: 1465.000\n",
            "Column: 668, Selected False, Rank: 1467.000\n",
            "Column: 669, Selected False, Rank: 1469.000\n",
            "Column: 670, Selected False, Rank: 1471.000\n",
            "Column: 671, Selected False, Rank: 1473.000\n",
            "Column: 672, Selected False, Rank: 1475.000\n",
            "Column: 673, Selected False, Rank: 1477.000\n",
            "Column: 674, Selected False, Rank: 1479.000\n",
            "Column: 675, Selected False, Rank: 1481.000\n",
            "Column: 676, Selected False, Rank: 1483.000\n",
            "Column: 677, Selected False, Rank: 1485.000\n",
            "Column: 678, Selected False, Rank: 1487.000\n",
            "Column: 679, Selected False, Rank: 1489.000\n",
            "Column: 680, Selected False, Rank: 81.000\n",
            "Column: 681, Selected False, Rank: 1493.000\n",
            "Column: 682, Selected False, Rank: 1495.000\n",
            "Column: 683, Selected False, Rank: 1497.000\n",
            "Column: 684, Selected False, Rank: 1499.000\n",
            "Column: 685, Selected False, Rank: 1501.000\n",
            "Column: 686, Selected False, Rank: 1503.000\n",
            "Column: 687, Selected False, Rank: 1505.000\n",
            "Column: 688, Selected False, Rank: 1507.000\n",
            "Column: 689, Selected False, Rank: 1509.000\n",
            "Column: 690, Selected False, Rank: 1511.000\n",
            "Column: 691, Selected False, Rank: 1513.000\n",
            "Column: 692, Selected False, Rank: 1515.000\n",
            "Column: 693, Selected False, Rank: 1517.000\n",
            "Column: 694, Selected False, Rank: 1519.000\n",
            "Column: 695, Selected False, Rank: 1521.000\n",
            "Column: 696, Selected False, Rank: 1523.000\n",
            "Column: 697, Selected False, Rank: 1525.000\n",
            "Column: 698, Selected False, Rank: 1527.000\n",
            "Column: 699, Selected False, Rank: 1529.000\n",
            "Column: 700, Selected False, Rank: 1531.000\n",
            "Column: 701, Selected False, Rank: 1533.000\n",
            "Column: 702, Selected False, Rank: 1535.000\n",
            "Column: 703, Selected False, Rank: 1537.000\n",
            "Column: 704, Selected False, Rank: 1539.000\n",
            "Column: 705, Selected False, Rank: 1541.000\n",
            "Column: 706, Selected False, Rank: 1543.000\n",
            "Column: 707, Selected False, Rank: 1545.000\n",
            "Column: 708, Selected False, Rank: 1547.000\n",
            "Column: 709, Selected False, Rank: 1549.000\n",
            "Column: 710, Selected False, Rank: 1551.000\n",
            "Column: 711, Selected False, Rank: 1553.000\n",
            "Column: 712, Selected False, Rank: 1555.000\n",
            "Column: 713, Selected False, Rank: 1557.000\n",
            "Column: 714, Selected False, Rank: 118.000\n",
            "Column: 715, Selected False, Rank: 1561.000\n",
            "Column: 716, Selected False, Rank: 1563.000\n",
            "Column: 717, Selected False, Rank: 1565.000\n",
            "Column: 718, Selected False, Rank: 1567.000\n",
            "Column: 719, Selected False, Rank: 1569.000\n",
            "Column: 720, Selected False, Rank: 1571.000\n",
            "Column: 721, Selected False, Rank: 1573.000\n",
            "Column: 722, Selected False, Rank: 1575.000\n",
            "Column: 723, Selected False, Rank: 1577.000\n",
            "Column: 724, Selected False, Rank: 1579.000\n",
            "Column: 725, Selected False, Rank: 1581.000\n",
            "Column: 726, Selected False, Rank: 1583.000\n",
            "Column: 727, Selected False, Rank: 1585.000\n",
            "Column: 728, Selected False, Rank: 1587.000\n",
            "Column: 729, Selected False, Rank: 1589.000\n",
            "Column: 730, Selected False, Rank: 1591.000\n",
            "Column: 731, Selected False, Rank: 1593.000\n",
            "Column: 732, Selected False, Rank: 1595.000\n",
            "Column: 733, Selected False, Rank: 1597.000\n",
            "Column: 734, Selected False, Rank: 1599.000\n",
            "Column: 735, Selected False, Rank: 1601.000\n",
            "Column: 736, Selected False, Rank: 1603.000\n",
            "Column: 737, Selected False, Rank: 1605.000\n",
            "Column: 738, Selected False, Rank: 1607.000\n",
            "Column: 739, Selected False, Rank: 1609.000\n",
            "Column: 740, Selected False, Rank: 1611.000\n",
            "Column: 741, Selected False, Rank: 1613.000\n",
            "Column: 742, Selected False, Rank: 1615.000\n",
            "Column: 743, Selected False, Rank: 1617.000\n",
            "Column: 744, Selected False, Rank: 1619.000\n",
            "Column: 745, Selected False, Rank: 1621.000\n",
            "Column: 746, Selected False, Rank: 1623.000\n",
            "Column: 747, Selected False, Rank: 1625.000\n",
            "Column: 748, Selected False, Rank: 1627.000\n",
            "Column: 749, Selected False, Rank: 1629.000\n",
            "Column: 750, Selected False, Rank: 1631.000\n",
            "Column: 751, Selected False, Rank: 1633.000\n",
            "Column: 752, Selected False, Rank: 1635.000\n",
            "Column: 753, Selected False, Rank: 1637.000\n",
            "Column: 754, Selected False, Rank: 1639.000\n",
            "Column: 755, Selected False, Rank: 1641.000\n",
            "Column: 756, Selected False, Rank: 1643.000\n",
            "Column: 757, Selected False, Rank: 1645.000\n",
            "Column: 758, Selected False, Rank: 1647.000\n",
            "Column: 759, Selected False, Rank: 1649.000\n",
            "Column: 760, Selected False, Rank: 1651.000\n",
            "Column: 761, Selected False, Rank: 1653.000\n",
            "Column: 762, Selected False, Rank: 1655.000\n",
            "Column: 763, Selected False, Rank: 1657.000\n",
            "Column: 764, Selected False, Rank: 1659.000\n",
            "Column: 765, Selected False, Rank: 1661.000\n",
            "Column: 766, Selected False, Rank: 1663.000\n",
            "Column: 767, Selected False, Rank: 1665.000\n",
            "Column: 768, Selected False, Rank: 1667.000\n",
            "Column: 769, Selected False, Rank: 1669.000\n",
            "Column: 770, Selected False, Rank: 1671.000\n",
            "Column: 771, Selected False, Rank: 1673.000\n",
            "Column: 772, Selected False, Rank: 1675.000\n",
            "Column: 773, Selected False, Rank: 1677.000\n",
            "Column: 774, Selected False, Rank: 1679.000\n",
            "Column: 775, Selected False, Rank: 1681.000\n",
            "Column: 776, Selected False, Rank: 115.000\n",
            "Column: 777, Selected False, Rank: 1685.000\n",
            "Column: 778, Selected False, Rank: 1687.000\n",
            "Column: 779, Selected False, Rank: 1689.000\n",
            "Column: 780, Selected False, Rank: 1691.000\n",
            "Column: 781, Selected False, Rank: 44.000\n",
            "Column: 782, Selected False, Rank: 1695.000\n",
            "Column: 783, Selected False, Rank: 1697.000\n",
            "Column: 784, Selected False, Rank: 1699.000\n",
            "Column: 785, Selected False, Rank: 1701.000\n",
            "Column: 786, Selected False, Rank: 1703.000\n",
            "Column: 787, Selected False, Rank: 1705.000\n",
            "Column: 788, Selected False, Rank: 1707.000\n",
            "Column: 789, Selected False, Rank: 1709.000\n",
            "Column: 790, Selected False, Rank: 1711.000\n",
            "Column: 791, Selected False, Rank: 1713.000\n",
            "Column: 792, Selected False, Rank: 1715.000\n",
            "Column: 793, Selected False, Rank: 1717.000\n",
            "Column: 794, Selected False, Rank: 1719.000\n",
            "Column: 795, Selected False, Rank: 1721.000\n",
            "Column: 796, Selected False, Rank: 1723.000\n",
            "Column: 797, Selected False, Rank: 1725.000\n",
            "Column: 798, Selected False, Rank: 1727.000\n",
            "Column: 799, Selected False, Rank: 1729.000\n",
            "Column: 800, Selected False, Rank: 1731.000\n",
            "Column: 801, Selected False, Rank: 1733.000\n",
            "Column: 802, Selected False, Rank: 1735.000\n",
            "Column: 803, Selected False, Rank: 1737.000\n",
            "Column: 804, Selected False, Rank: 1739.000\n",
            "Column: 805, Selected False, Rank: 1741.000\n",
            "Column: 806, Selected False, Rank: 1743.000\n",
            "Column: 807, Selected False, Rank: 1745.000\n",
            "Column: 808, Selected False, Rank: 1747.000\n",
            "Column: 809, Selected False, Rank: 1749.000\n",
            "Column: 810, Selected False, Rank: 1751.000\n",
            "Column: 811, Selected False, Rank: 108.000\n",
            "Column: 812, Selected False, Rank: 1755.000\n",
            "Column: 813, Selected False, Rank: 1757.000\n",
            "Column: 814, Selected False, Rank: 1759.000\n",
            "Column: 815, Selected False, Rank: 1761.000\n",
            "Column: 816, Selected False, Rank: 1763.000\n",
            "Column: 817, Selected False, Rank: 1765.000\n",
            "Column: 818, Selected False, Rank: 1767.000\n",
            "Column: 819, Selected False, Rank: 1769.000\n",
            "Column: 820, Selected False, Rank: 1771.000\n",
            "Column: 821, Selected False, Rank: 1773.000\n",
            "Column: 822, Selected False, Rank: 1775.000\n",
            "Column: 823, Selected False, Rank: 1777.000\n",
            "Column: 824, Selected False, Rank: 1779.000\n",
            "Column: 825, Selected False, Rank: 1781.000\n",
            "Column: 826, Selected False, Rank: 1783.000\n",
            "Column: 827, Selected False, Rank: 1785.000\n",
            "Column: 828, Selected False, Rank: 1787.000\n",
            "Column: 829, Selected False, Rank: 1789.000\n",
            "Column: 830, Selected False, Rank: 1791.000\n",
            "Column: 831, Selected False, Rank: 1793.000\n",
            "Column: 832, Selected False, Rank: 1795.000\n",
            "Column: 833, Selected False, Rank: 1797.000\n",
            "Column: 834, Selected False, Rank: 1799.000\n",
            "Column: 835, Selected False, Rank: 1801.000\n",
            "Column: 836, Selected False, Rank: 1803.000\n",
            "Column: 837, Selected False, Rank: 1805.000\n",
            "Column: 838, Selected False, Rank: 1807.000\n",
            "Column: 839, Selected False, Rank: 1809.000\n",
            "Column: 840, Selected False, Rank: 1811.000\n",
            "Column: 841, Selected False, Rank: 1813.000\n",
            "Column: 842, Selected False, Rank: 1815.000\n",
            "Column: 843, Selected False, Rank: 1817.000\n",
            "Column: 844, Selected False, Rank: 1819.000\n",
            "Column: 845, Selected False, Rank: 1821.000\n",
            "Column: 846, Selected False, Rank: 1823.000\n",
            "Column: 847, Selected False, Rank: 1825.000\n",
            "Column: 848, Selected False, Rank: 1827.000\n",
            "Column: 849, Selected False, Rank: 1829.000\n",
            "Column: 850, Selected False, Rank: 1831.000\n",
            "Column: 851, Selected False, Rank: 1833.000\n",
            "Column: 852, Selected False, Rank: 1835.000\n",
            "Column: 853, Selected False, Rank: 1837.000\n",
            "Column: 854, Selected False, Rank: 1839.000\n",
            "Column: 855, Selected False, Rank: 1841.000\n",
            "Column: 856, Selected False, Rank: 1843.000\n",
            "Column: 857, Selected False, Rank: 1845.000\n",
            "Column: 858, Selected False, Rank: 1847.000\n",
            "Column: 859, Selected False, Rank: 1849.000\n",
            "Column: 860, Selected False, Rank: 1851.000\n",
            "Column: 861, Selected False, Rank: 1853.000\n",
            "Column: 862, Selected False, Rank: 1855.000\n",
            "Column: 863, Selected False, Rank: 1857.000\n",
            "Column: 864, Selected False, Rank: 1859.000\n",
            "Column: 865, Selected False, Rank: 1861.000\n",
            "Column: 866, Selected False, Rank: 1863.000\n",
            "Column: 867, Selected False, Rank: 1865.000\n",
            "Column: 868, Selected False, Rank: 1867.000\n",
            "Column: 869, Selected False, Rank: 1869.000\n",
            "Column: 870, Selected False, Rank: 1871.000\n",
            "Column: 871, Selected False, Rank: 1873.000\n",
            "Column: 872, Selected False, Rank: 1875.000\n",
            "Column: 873, Selected False, Rank: 1877.000\n",
            "Column: 874, Selected False, Rank: 1879.000\n",
            "Column: 875, Selected False, Rank: 1881.000\n",
            "Column: 876, Selected False, Rank: 1883.000\n",
            "Column: 877, Selected False, Rank: 1885.000\n",
            "Column: 878, Selected False, Rank: 1887.000\n",
            "Column: 879, Selected False, Rank: 1889.000\n",
            "Column: 880, Selected False, Rank: 1891.000\n",
            "Column: 881, Selected False, Rank: 1893.000\n",
            "Column: 882, Selected False, Rank: 1895.000\n",
            "Column: 883, Selected False, Rank: 1897.000\n",
            "Column: 884, Selected False, Rank: 1899.000\n",
            "Column: 885, Selected False, Rank: 1901.000\n",
            "Column: 886, Selected False, Rank: 1903.000\n",
            "Column: 887, Selected False, Rank: 94.000\n",
            "Column: 888, Selected False, Rank: 1907.000\n",
            "Column: 889, Selected False, Rank: 1909.000\n",
            "Column: 890, Selected False, Rank: 1911.000\n",
            "Column: 891, Selected False, Rank: 1913.000\n",
            "Column: 892, Selected False, Rank: 1915.000\n",
            "Column: 893, Selected False, Rank: 1917.000\n",
            "Column: 894, Selected False, Rank: 1919.000\n",
            "Column: 895, Selected False, Rank: 1921.000\n",
            "Column: 896, Selected False, Rank: 1923.000\n",
            "Column: 897, Selected False, Rank: 1925.000\n",
            "Column: 898, Selected False, Rank: 1927.000\n",
            "Column: 899, Selected False, Rank: 1929.000\n",
            "Column: 900, Selected False, Rank: 1931.000\n",
            "Column: 901, Selected False, Rank: 1933.000\n",
            "Column: 902, Selected False, Rank: 1935.000\n",
            "Column: 903, Selected False, Rank: 1937.000\n",
            "Column: 904, Selected False, Rank: 1939.000\n",
            "Column: 905, Selected False, Rank: 1941.000\n",
            "Column: 906, Selected False, Rank: 1943.000\n",
            "Column: 907, Selected False, Rank: 1945.000\n",
            "Column: 908, Selected False, Rank: 1947.000\n",
            "Column: 909, Selected False, Rank: 11.000\n",
            "Column: 910, Selected False, Rank: 1951.000\n",
            "Column: 911, Selected True, Rank: 1.000\n",
            "Column: 912, Selected False, Rank: 1955.000\n",
            "Column: 913, Selected False, Rank: 1957.000\n",
            "Column: 914, Selected False, Rank: 1959.000\n",
            "Column: 915, Selected False, Rank: 1961.000\n",
            "Column: 916, Selected False, Rank: 1963.000\n",
            "Column: 917, Selected False, Rank: 1965.000\n",
            "Column: 918, Selected False, Rank: 1967.000\n",
            "Column: 919, Selected False, Rank: 1969.000\n",
            "Column: 920, Selected False, Rank: 1971.000\n",
            "Column: 921, Selected False, Rank: 1973.000\n",
            "Column: 922, Selected False, Rank: 1975.000\n",
            "Column: 923, Selected False, Rank: 1977.000\n",
            "Column: 924, Selected False, Rank: 1979.000\n",
            "Column: 925, Selected False, Rank: 1981.000\n",
            "Column: 926, Selected False, Rank: 1983.000\n",
            "Column: 927, Selected False, Rank: 1985.000\n",
            "Column: 928, Selected False, Rank: 1987.000\n",
            "Column: 929, Selected False, Rank: 1989.000\n",
            "Column: 930, Selected False, Rank: 1991.000\n",
            "Column: 931, Selected False, Rank: 1993.000\n",
            "Column: 932, Selected False, Rank: 1995.000\n",
            "Column: 933, Selected False, Rank: 1997.000\n",
            "Column: 934, Selected False, Rank: 1999.000\n",
            "Column: 935, Selected False, Rank: 2001.000\n",
            "Column: 936, Selected False, Rank: 2003.000\n",
            "Column: 937, Selected False, Rank: 2005.000\n",
            "Column: 938, Selected False, Rank: 2007.000\n",
            "Column: 939, Selected False, Rank: 2009.000\n",
            "Column: 940, Selected False, Rank: 2011.000\n",
            "Column: 941, Selected False, Rank: 2013.000\n",
            "Column: 942, Selected False, Rank: 2015.000\n",
            "Column: 943, Selected False, Rank: 2017.000\n",
            "Column: 944, Selected False, Rank: 2019.000\n",
            "Column: 945, Selected False, Rank: 2021.000\n",
            "Column: 946, Selected False, Rank: 2023.000\n",
            "Column: 947, Selected False, Rank: 2025.000\n",
            "Column: 948, Selected False, Rank: 2027.000\n",
            "Column: 949, Selected False, Rank: 2029.000\n",
            "Column: 950, Selected False, Rank: 2031.000\n",
            "Column: 951, Selected False, Rank: 2033.000\n",
            "Column: 952, Selected False, Rank: 2035.000\n",
            "Column: 953, Selected False, Rank: 2037.000\n",
            "Column: 954, Selected False, Rank: 2039.000\n",
            "Column: 955, Selected False, Rank: 2041.000\n",
            "Column: 956, Selected False, Rank: 2043.000\n",
            "Column: 957, Selected False, Rank: 2045.000\n",
            "Column: 958, Selected False, Rank: 2047.000\n",
            "Column: 959, Selected False, Rank: 2049.000\n",
            "Column: 960, Selected False, Rank: 2051.000\n",
            "Column: 961, Selected False, Rank: 2053.000\n",
            "Column: 962, Selected False, Rank: 2055.000\n",
            "Column: 963, Selected False, Rank: 2057.000\n",
            "Column: 964, Selected False, Rank: 2059.000\n",
            "Column: 965, Selected False, Rank: 2061.000\n",
            "Column: 966, Selected False, Rank: 2063.000\n",
            "Column: 967, Selected False, Rank: 2065.000\n",
            "Column: 968, Selected False, Rank: 2067.000\n",
            "Column: 969, Selected False, Rank: 2069.000\n",
            "Column: 970, Selected False, Rank: 2071.000\n",
            "Column: 971, Selected False, Rank: 2073.000\n",
            "Column: 972, Selected False, Rank: 2075.000\n",
            "Column: 973, Selected False, Rank: 2077.000\n",
            "Column: 974, Selected False, Rank: 2079.000\n",
            "Column: 975, Selected False, Rank: 2081.000\n",
            "Column: 976, Selected False, Rank: 2083.000\n",
            "Column: 977, Selected False, Rank: 2085.000\n",
            "Column: 978, Selected False, Rank: 2087.000\n",
            "Column: 979, Selected False, Rank: 2089.000\n",
            "Column: 980, Selected False, Rank: 2091.000\n",
            "Column: 981, Selected False, Rank: 2093.000\n",
            "Column: 982, Selected False, Rank: 2095.000\n",
            "Column: 983, Selected False, Rank: 2097.000\n",
            "Column: 984, Selected False, Rank: 2099.000\n",
            "Column: 985, Selected False, Rank: 2101.000\n",
            "Column: 986, Selected False, Rank: 2103.000\n",
            "Column: 987, Selected False, Rank: 2105.000\n",
            "Column: 988, Selected False, Rank: 2107.000\n",
            "Column: 989, Selected False, Rank: 2109.000\n",
            "Column: 990, Selected False, Rank: 2111.000\n",
            "Column: 991, Selected False, Rank: 2113.000\n",
            "Column: 992, Selected False, Rank: 2115.000\n",
            "Column: 993, Selected False, Rank: 2117.000\n",
            "Column: 994, Selected False, Rank: 2119.000\n",
            "Column: 995, Selected False, Rank: 2121.000\n",
            "Column: 996, Selected False, Rank: 2123.000\n",
            "Column: 997, Selected False, Rank: 40.000\n",
            "Column: 998, Selected False, Rank: 2127.000\n",
            "Column: 999, Selected False, Rank: 2129.000\n",
            "Column: 1000, Selected False, Rank: 2131.000\n",
            "Column: 1001, Selected False, Rank: 2133.000\n",
            "Column: 1002, Selected False, Rank: 2135.000\n",
            "Column: 1003, Selected False, Rank: 2137.000\n",
            "Column: 1004, Selected False, Rank: 2139.000\n",
            "Column: 1005, Selected False, Rank: 2141.000\n",
            "Column: 1006, Selected False, Rank: 2143.000\n",
            "Column: 1007, Selected False, Rank: 2145.000\n",
            "Column: 1008, Selected False, Rank: 2147.000\n",
            "Column: 1009, Selected False, Rank: 2149.000\n",
            "Column: 1010, Selected False, Rank: 2151.000\n",
            "Column: 1011, Selected False, Rank: 2153.000\n",
            "Column: 1012, Selected False, Rank: 2155.000\n",
            "Column: 1013, Selected False, Rank: 2157.000\n",
            "Column: 1014, Selected False, Rank: 2159.000\n",
            "Column: 1015, Selected False, Rank: 2161.000\n",
            "Column: 1016, Selected False, Rank: 2163.000\n",
            "Column: 1017, Selected False, Rank: 2165.000\n",
            "Column: 1018, Selected False, Rank: 2167.000\n",
            "Column: 1019, Selected False, Rank: 2169.000\n",
            "Column: 1020, Selected False, Rank: 2171.000\n",
            "Column: 1021, Selected False, Rank: 2173.000\n",
            "Column: 1022, Selected False, Rank: 2175.000\n",
            "Column: 1023, Selected False, Rank: 2177.000\n",
            "Column: 1024, Selected False, Rank: 2179.000\n",
            "Column: 1025, Selected False, Rank: 2181.000\n",
            "Column: 1026, Selected False, Rank: 2183.000\n",
            "Column: 1027, Selected False, Rank: 2185.000\n",
            "Column: 1028, Selected False, Rank: 2187.000\n",
            "Column: 1029, Selected False, Rank: 2189.000\n",
            "Column: 1030, Selected False, Rank: 2191.000\n",
            "Column: 1031, Selected False, Rank: 2193.000\n",
            "Column: 1032, Selected False, Rank: 2195.000\n",
            "Column: 1033, Selected False, Rank: 2197.000\n",
            "Column: 1034, Selected False, Rank: 2199.000\n",
            "Column: 1035, Selected False, Rank: 2201.000\n",
            "Column: 1036, Selected False, Rank: 2203.000\n",
            "Column: 1037, Selected False, Rank: 2205.000\n",
            "Column: 1038, Selected False, Rank: 2207.000\n",
            "Column: 1039, Selected False, Rank: 2209.000\n",
            "Column: 1040, Selected False, Rank: 2211.000\n",
            "Column: 1041, Selected False, Rank: 2213.000\n",
            "Column: 1042, Selected False, Rank: 2215.000\n",
            "Column: 1043, Selected False, Rank: 2217.000\n",
            "Column: 1044, Selected False, Rank: 2219.000\n",
            "Column: 1045, Selected False, Rank: 2221.000\n",
            "Column: 1046, Selected False, Rank: 2223.000\n",
            "Column: 1047, Selected False, Rank: 2225.000\n",
            "Column: 1048, Selected False, Rank: 2227.000\n",
            "Column: 1049, Selected False, Rank: 2229.000\n",
            "Column: 1050, Selected False, Rank: 2231.000\n",
            "Column: 1051, Selected False, Rank: 2233.000\n",
            "Column: 1052, Selected False, Rank: 2235.000\n",
            "Column: 1053, Selected False, Rank: 2237.000\n",
            "Column: 1054, Selected False, Rank: 2239.000\n",
            "Column: 1055, Selected False, Rank: 2241.000\n",
            "Column: 1056, Selected False, Rank: 2243.000\n",
            "Column: 1057, Selected False, Rank: 2245.000\n",
            "Column: 1058, Selected False, Rank: 2247.000\n",
            "Column: 1059, Selected False, Rank: 2249.000\n",
            "Column: 1060, Selected False, Rank: 2251.000\n",
            "Column: 1061, Selected False, Rank: 2253.000\n",
            "Column: 1062, Selected False, Rank: 2255.000\n",
            "Column: 1063, Selected False, Rank: 2257.000\n",
            "Column: 1064, Selected False, Rank: 2259.000\n",
            "Column: 1065, Selected False, Rank: 2261.000\n",
            "Column: 1066, Selected False, Rank: 2263.000\n",
            "Column: 1067, Selected False, Rank: 2265.000\n",
            "Column: 1068, Selected False, Rank: 2267.000\n",
            "Column: 1069, Selected False, Rank: 2269.000\n",
            "Column: 1070, Selected False, Rank: 2271.000\n",
            "Column: 1071, Selected False, Rank: 2273.000\n",
            "Column: 1072, Selected False, Rank: 2275.000\n",
            "Column: 1073, Selected False, Rank: 2277.000\n",
            "Column: 1074, Selected False, Rank: 2279.000\n",
            "Column: 1075, Selected False, Rank: 2281.000\n",
            "Column: 1076, Selected False, Rank: 2283.000\n",
            "Column: 1077, Selected False, Rank: 2285.000\n",
            "Column: 1078, Selected False, Rank: 2287.000\n",
            "Column: 1079, Selected False, Rank: 2289.000\n",
            "Column: 1080, Selected False, Rank: 2291.000\n",
            "Column: 1081, Selected False, Rank: 2293.000\n",
            "Column: 1082, Selected False, Rank: 2295.000\n",
            "Column: 1083, Selected False, Rank: 2297.000\n",
            "Column: 1084, Selected False, Rank: 2299.000\n",
            "Column: 1085, Selected False, Rank: 2301.000\n",
            "Column: 1086, Selected False, Rank: 2303.000\n",
            "Column: 1087, Selected False, Rank: 2305.000\n",
            "Column: 1088, Selected False, Rank: 2307.000\n",
            "Column: 1089, Selected False, Rank: 2309.000\n",
            "Column: 1090, Selected False, Rank: 2311.000\n",
            "Column: 1091, Selected False, Rank: 2313.000\n",
            "Column: 1092, Selected False, Rank: 2315.000\n",
            "Column: 1093, Selected False, Rank: 2317.000\n",
            "Column: 1094, Selected False, Rank: 2319.000\n",
            "Column: 1095, Selected False, Rank: 2321.000\n",
            "Column: 1096, Selected False, Rank: 2323.000\n",
            "Column: 1097, Selected False, Rank: 2325.000\n",
            "Column: 1098, Selected False, Rank: 79.000\n",
            "Column: 1099, Selected False, Rank: 2329.000\n",
            "Column: 1100, Selected False, Rank: 2331.000\n",
            "Column: 1101, Selected False, Rank: 2333.000\n",
            "Column: 1102, Selected False, Rank: 2335.000\n",
            "Column: 1103, Selected False, Rank: 2337.000\n",
            "Column: 1104, Selected False, Rank: 2339.000\n",
            "Column: 1105, Selected False, Rank: 2341.000\n",
            "Column: 1106, Selected False, Rank: 2343.000\n",
            "Column: 1107, Selected False, Rank: 2345.000\n",
            "Column: 1108, Selected False, Rank: 2347.000\n",
            "Column: 1109, Selected False, Rank: 2349.000\n",
            "Column: 1110, Selected False, Rank: 2351.000\n",
            "Column: 1111, Selected False, Rank: 2353.000\n",
            "Column: 1112, Selected False, Rank: 2355.000\n",
            "Column: 1113, Selected False, Rank: 2357.000\n",
            "Column: 1114, Selected False, Rank: 2359.000\n",
            "Column: 1115, Selected False, Rank: 2361.000\n",
            "Column: 1116, Selected False, Rank: 2363.000\n",
            "Column: 1117, Selected False, Rank: 2365.000\n",
            "Column: 1118, Selected False, Rank: 2367.000\n",
            "Column: 1119, Selected False, Rank: 2369.000\n",
            "Column: 1120, Selected False, Rank: 2371.000\n",
            "Column: 1121, Selected False, Rank: 2373.000\n",
            "Column: 1122, Selected False, Rank: 2375.000\n",
            "Column: 1123, Selected False, Rank: 2377.000\n",
            "Column: 1124, Selected False, Rank: 2379.000\n",
            "Column: 1125, Selected False, Rank: 2381.000\n",
            "Column: 1126, Selected False, Rank: 2383.000\n",
            "Column: 1127, Selected False, Rank: 2385.000\n",
            "Column: 1128, Selected False, Rank: 2387.000\n",
            "Column: 1129, Selected False, Rank: 2389.000\n",
            "Column: 1130, Selected False, Rank: 2391.000\n",
            "Column: 1131, Selected False, Rank: 2393.000\n",
            "Column: 1132, Selected False, Rank: 2395.000\n",
            "Column: 1133, Selected False, Rank: 96.000\n",
            "Column: 1134, Selected False, Rank: 2398.000\n",
            "Column: 1135, Selected False, Rank: 2400.000\n",
            "Column: 1136, Selected False, Rank: 2402.000\n",
            "Column: 1137, Selected False, Rank: 2404.000\n",
            "Column: 1138, Selected False, Rank: 2406.000\n",
            "Column: 1139, Selected False, Rank: 2408.000\n",
            "Column: 1140, Selected False, Rank: 2410.000\n",
            "Column: 1141, Selected False, Rank: 2412.000\n",
            "Column: 1142, Selected False, Rank: 2414.000\n",
            "Column: 1143, Selected False, Rank: 2416.000\n",
            "Column: 1144, Selected False, Rank: 2418.000\n",
            "Column: 1145, Selected False, Rank: 888.000\n",
            "Column: 1146, Selected False, Rank: 2424.000\n",
            "Column: 1147, Selected False, Rank: 2426.000\n",
            "Column: 1148, Selected False, Rank: 883.000\n",
            "Column: 1149, Selected False, Rank: 14.000\n",
            "Column: 1150, Selected False, Rank: 890.000\n",
            "Column: 1151, Selected False, Rank: 2434.000\n",
            "Column: 1152, Selected False, Rank: 2435.000\n",
            "Column: 1153, Selected False, Rank: 892.000\n",
            "Column: 1154, Selected False, Rank: 894.000\n",
            "Column: 1155, Selected False, Rank: 922.000\n",
            "Column: 1156, Selected False, Rank: 896.000\n",
            "Column: 1157, Selected False, Rank: 18.000\n",
            "Column: 1158, Selected False, Rank: 2436.000\n",
            "Column: 1159, Selected False, Rank: 2438.000\n",
            "Column: 1160, Selected False, Rank: 2440.000\n",
            "Column: 1161, Selected False, Rank: 2442.000\n",
            "Column: 1162, Selected False, Rank: 2444.000\n",
            "Column: 1163, Selected False, Rank: 2446.000\n",
            "Column: 1164, Selected False, Rank: 2448.000\n",
            "Column: 1165, Selected False, Rank: 2450.000\n",
            "Column: 1166, Selected False, Rank: 2452.000\n",
            "Column: 1167, Selected False, Rank: 2454.000\n",
            "Column: 1168, Selected False, Rank: 2456.000\n",
            "Column: 1169, Selected False, Rank: 2458.000\n",
            "Column: 1170, Selected False, Rank: 2460.000\n",
            "Column: 1171, Selected False, Rank: 2462.000\n",
            "Column: 1172, Selected False, Rank: 2464.000\n",
            "Column: 1173, Selected False, Rank: 2466.000\n",
            "Column: 1174, Selected False, Rank: 2468.000\n",
            "Column: 1175, Selected False, Rank: 2470.000\n",
            "Column: 1176, Selected False, Rank: 2472.000\n",
            "Column: 1177, Selected False, Rank: 2474.000\n",
            "Column: 1178, Selected False, Rank: 2476.000\n",
            "Column: 1179, Selected False, Rank: 2478.000\n",
            "Column: 1180, Selected False, Rank: 2480.000\n",
            "Column: 1181, Selected False, Rank: 2482.000\n",
            "Column: 1182, Selected False, Rank: 2484.000\n",
            "Column: 1183, Selected False, Rank: 2486.000\n",
            "Column: 1184, Selected False, Rank: 2488.000\n",
            "Column: 1185, Selected False, Rank: 2500.000\n",
            "Column: 1186, Selected False, Rank: 2502.000\n",
            "Column: 1187, Selected False, Rank: 2504.000\n",
            "Column: 1188, Selected False, Rank: 2506.000\n",
            "Column: 1189, Selected False, Rank: 2508.000\n",
            "Column: 1190, Selected False, Rank: 2510.000\n",
            "Column: 1191, Selected False, Rank: 2512.000\n",
            "Column: 1192, Selected False, Rank: 2514.000\n",
            "Column: 1193, Selected False, Rank: 2516.000\n",
            "Column: 1194, Selected False, Rank: 2518.000\n",
            "Column: 1195, Selected False, Rank: 2520.000\n",
            "Column: 1196, Selected False, Rank: 2522.000\n",
            "Column: 1197, Selected False, Rank: 2525.000\n",
            "Column: 1198, Selected False, Rank: 2524.000\n",
            "Column: 1199, Selected False, Rank: 2490.000\n",
            "Column: 1200, Selected False, Rank: 2492.000\n",
            "Column: 1201, Selected False, Rank: 2494.000\n",
            "Column: 1202, Selected False, Rank: 2496.000\n",
            "Column: 1203, Selected False, Rank: 2526.000\n",
            "Column: 1204, Selected False, Rank: 2528.000\n",
            "Column: 1205, Selected False, Rank: 2530.000\n",
            "Column: 1206, Selected False, Rank: 2532.000\n",
            "Column: 1207, Selected False, Rank: 2534.000\n",
            "Column: 1208, Selected False, Rank: 2537.000\n",
            "Column: 1209, Selected False, Rank: 2536.000\n",
            "Column: 1210, Selected False, Rank: 2499.000\n",
            "Column: 1211, Selected False, Rank: 2498.000\n",
            "Column: 1212, Selected False, Rank: 2432.000\n",
            "Column: 1213, Selected False, Rank: 978.000\n",
            "Column: 1214, Selected False, Rank: 1008.000\n",
            "Column: 1215, Selected False, Rank: 1138.000\n",
            "Column: 1216, Selected False, Rank: 1232.000\n",
            "Column: 1217, Selected False, Rank: 1236.000\n",
            "Column: 1218, Selected False, Rank: 1270.000\n",
            "Column: 1219, Selected False, Rank: 1278.000\n",
            "Column: 1220, Selected False, Rank: 1442.000\n",
            "Column: 1221, Selected False, Rank: 1490.000\n",
            "Column: 1222, Selected False, Rank: 1558.000\n",
            "Column: 1223, Selected False, Rank: 1682.000\n",
            "Column: 1224, Selected False, Rank: 1692.000\n",
            "Column: 1225, Selected False, Rank: 1752.000\n",
            "Column: 1226, Selected False, Rank: 1904.000\n",
            "Column: 1227, Selected False, Rank: 1948.000\n",
            "Column: 1228, Selected False, Rank: 1952.000\n",
            "Column: 1229, Selected False, Rank: 2124.000\n",
            "Column: 1230, Selected False, Rank: 2326.000\n",
            "Column: 1231, Selected False, Rank: 278.000\n",
            "Column: 1232, Selected False, Rank: 2538.000\n",
            "Column: 1233, Selected False, Rank: 2540.000\n",
            "Column: 1234, Selected False, Rank: 2542.000\n",
            "Column: 1235, Selected False, Rank: 2544.000\n",
            "Column: 1236, Selected False, Rank: 2546.000\n",
            "Column: 1237, Selected False, Rank: 2548.000\n",
            "Column: 1238, Selected False, Rank: 2550.000\n",
            "Column: 1239, Selected False, Rank: 2552.000\n",
            "Column: 1240, Selected False, Rank: 2554.000\n",
            "Column: 1241, Selected False, Rank: 2556.000\n",
            "Column: 1242, Selected False, Rank: 2558.000\n",
            "Column: 1243, Selected False, Rank: 2560.000\n",
            "Column: 1244, Selected False, Rank: 2562.000\n",
            "Column: 1245, Selected False, Rank: 2563.000\n",
            "Column: 1246, Selected False, Rank: 36.000\n",
            "Column: 1247, Selected False, Rank: 2568.000\n",
            "Column: 1248, Selected False, Rank: 2570.000\n",
            "Column: 1249, Selected False, Rank: 2572.000\n",
            "Column: 1250, Selected False, Rank: 2574.000\n",
            "Column: 1251, Selected False, Rank: 2576.000\n",
            "Column: 1252, Selected False, Rank: 2578.000\n",
            "Column: 1253, Selected False, Rank: 2580.000\n",
            "Column: 1254, Selected False, Rank: 2582.000\n",
            "Column: 1255, Selected False, Rank: 2584.000\n",
            "Column: 1256, Selected False, Rank: 2586.000\n",
            "Column: 1257, Selected False, Rank: 2588.000\n",
            "Column: 1258, Selected False, Rank: 2590.000\n",
            "Column: 1259, Selected False, Rank: 2592.000\n",
            "Column: 1260, Selected False, Rank: 2594.000\n",
            "Column: 1261, Selected False, Rank: 2596.000\n",
            "Column: 1262, Selected False, Rank: 2598.000\n",
            "Column: 1263, Selected False, Rank: 2600.000\n",
            "Column: 1264, Selected False, Rank: 2602.000\n",
            "Column: 1265, Selected False, Rank: 2604.000\n",
            "Column: 1266, Selected False, Rank: 2606.000\n",
            "Column: 1267, Selected False, Rank: 2608.000\n",
            "Column: 1268, Selected False, Rank: 2610.000\n",
            "Column: 1269, Selected False, Rank: 2612.000\n",
            "Column: 1270, Selected False, Rank: 2614.000\n",
            "Column: 1271, Selected False, Rank: 2616.000\n",
            "Column: 1272, Selected False, Rank: 2618.000\n",
            "Column: 1273, Selected False, Rank: 2619.000\n",
            "Column: 1274, Selected False, Rank: 50.000\n",
            "Column: 1275, Selected False, Rank: 2636.000\n",
            "Column: 1276, Selected False, Rank: 2638.000\n",
            "Column: 1277, Selected False, Rank: 2640.000\n",
            "Column: 1278, Selected False, Rank: 2642.000\n",
            "Column: 1279, Selected False, Rank: 2644.000\n",
            "Column: 1280, Selected False, Rank: 2646.000\n",
            "Column: 1281, Selected False, Rank: 2648.000\n",
            "Column: 1282, Selected False, Rank: 2650.000\n",
            "Column: 1283, Selected False, Rank: 2652.000\n",
            "Column: 1284, Selected False, Rank: 2654.000\n",
            "Column: 1285, Selected False, Rank: 2656.000\n",
            "Column: 1286, Selected False, Rank: 2658.000\n",
            "Column: 1287, Selected False, Rank: 2660.000\n",
            "Column: 1288, Selected False, Rank: 2662.000\n",
            "Column: 1289, Selected False, Rank: 2664.000\n",
            "Column: 1290, Selected False, Rank: 2666.000\n",
            "Column: 1291, Selected False, Rank: 2668.000\n",
            "Column: 1292, Selected False, Rank: 2670.000\n",
            "Column: 1293, Selected False, Rank: 2672.000\n",
            "Column: 1294, Selected False, Rank: 2674.000\n",
            "Column: 1295, Selected False, Rank: 2676.000\n",
            "Column: 1296, Selected False, Rank: 2678.000\n",
            "Column: 1297, Selected False, Rank: 2680.000\n",
            "Column: 1298, Selected False, Rank: 2682.000\n",
            "Column: 1299, Selected False, Rank: 2684.000\n",
            "Column: 1300, Selected False, Rank: 2686.000\n",
            "Column: 1301, Selected False, Rank: 2688.000\n",
            "Column: 1302, Selected False, Rank: 2690.000\n",
            "Column: 1303, Selected False, Rank: 2692.000\n",
            "Column: 1304, Selected False, Rank: 2694.000\n",
            "Column: 1305, Selected False, Rank: 2696.000\n",
            "Column: 1306, Selected False, Rank: 2698.000\n",
            "Column: 1307, Selected False, Rank: 2700.000\n",
            "Column: 1308, Selected False, Rank: 2702.000\n",
            "Column: 1309, Selected False, Rank: 2704.000\n",
            "Column: 1310, Selected False, Rank: 2706.000\n",
            "Column: 1311, Selected False, Rank: 2708.000\n",
            "Column: 1312, Selected False, Rank: 2710.000\n",
            "Column: 1313, Selected False, Rank: 2712.000\n",
            "Column: 1314, Selected False, Rank: 2714.000\n",
            "Column: 1315, Selected False, Rank: 2716.000\n",
            "Column: 1316, Selected False, Rank: 2718.000\n",
            "Column: 1317, Selected False, Rank: 2720.000\n",
            "Column: 1318, Selected False, Rank: 2722.000\n",
            "Column: 1319, Selected False, Rank: 2724.000\n",
            "Column: 1320, Selected False, Rank: 2726.000\n",
            "Column: 1321, Selected False, Rank: 2728.000\n",
            "Column: 1322, Selected False, Rank: 2729.000\n",
            "Column: 1323, Selected False, Rank: 2624.000\n",
            "Column: 1324, Selected False, Rank: 2626.000\n",
            "Column: 1325, Selected False, Rank: 2628.000\n",
            "Column: 1326, Selected False, Rank: 2630.000\n",
            "Column: 1327, Selected False, Rank: 2631.000\n",
            "Column: 1328, Selected False, Rank: 65.000\n",
            "Column: 1329, Selected False, Rank: 2732.000\n",
            "Column: 1330, Selected False, Rank: 2734.000\n",
            "Column: 1331, Selected False, Rank: 2736.000\n",
            "Column: 1332, Selected False, Rank: 2738.000\n",
            "Column: 1333, Selected False, Rank: 2740.000\n",
            "Column: 1334, Selected False, Rank: 2742.000\n",
            "Column: 1335, Selected False, Rank: 2744.000\n",
            "Column: 1336, Selected False, Rank: 2746.000\n",
            "Column: 1337, Selected False, Rank: 2748.000\n",
            "Column: 1338, Selected False, Rank: 2750.000\n",
            "Column: 1339, Selected False, Rank: 2752.000\n",
            "Column: 1340, Selected False, Rank: 2754.000\n",
            "Column: 1341, Selected False, Rank: 2755.000\n",
            "Column: 1342, Selected False, Rank: 106.000\n",
            "Column: 1343, Selected False, Rank: 2433.000\n",
            "Column: 1344, Selected False, Rank: 2431.000\n",
            "Column: 1345, Selected False, Rank: 308.000\n",
            "Column: 1346, Selected False, Rank: 310.000\n",
            "Column: 1347, Selected False, Rank: 314.000\n",
            "Column: 1348, Selected False, Rank: 316.000\n",
            "Column: 1349, Selected False, Rank: 318.000\n",
            "Column: 1350, Selected False, Rank: 320.000\n",
            "Column: 1351, Selected False, Rank: 41.000\n",
            "Column: 1352, Selected False, Rank: 330.000\n",
            "Column: 1353, Selected False, Rank: 332.000\n",
            "Column: 1354, Selected False, Rank: 334.000\n",
            "Column: 1355, Selected False, Rank: 336.000\n",
            "Column: 1356, Selected False, Rank: 338.000\n",
            "Column: 1357, Selected False, Rank: 340.000\n",
            "Column: 1358, Selected False, Rank: 342.000\n",
            "Column: 1359, Selected False, Rank: 344.000\n",
            "Column: 1360, Selected False, Rank: 346.000\n",
            "Column: 1361, Selected False, Rank: 348.000\n",
            "Column: 1362, Selected False, Rank: 350.000\n",
            "Column: 1363, Selected False, Rank: 352.000\n",
            "Column: 1364, Selected False, Rank: 354.000\n",
            "Column: 1365, Selected False, Rank: 356.000\n",
            "Column: 1366, Selected False, Rank: 364.000\n",
            "Column: 1367, Selected False, Rank: 366.000\n",
            "Column: 1368, Selected False, Rank: 870.000\n",
            "Column: 1369, Selected False, Rank: 872.000\n",
            "Column: 1370, Selected False, Rank: 874.000\n",
            "Column: 1371, Selected False, Rank: 876.000\n",
            "Column: 1372, Selected False, Rank: 878.000\n",
            "Column: 1373, Selected False, Rank: 880.000\n",
            "Column: 1374, Selected False, Rank: 884.000\n",
            "Column: 1375, Selected False, Rank: 2564.000\n",
            "Column: 1376, Selected False, Rank: 2620.000\n",
            "Column: 1377, Selected False, Rank: 2632.000\n",
            "Column: 1378, Selected False, Rank: 2756.000\n",
            "Column: 1379, Selected False, Rank: 2758.000\n",
            "Column: 1380, Selected False, Rank: 2760.000\n",
            "Column: 1381, Selected False, Rank: 2762.000\n",
            "Column: 1382, Selected False, Rank: 2764.000\n",
            "Column: 1383, Selected False, Rank: 2766.000\n",
            "Column: 1384, Selected False, Rank: 2768.000\n",
            "Column: 1385, Selected False, Rank: 2770.000\n",
            "Column: 1386, Selected False, Rank: 2772.000\n",
            "Column: 1387, Selected False, Rank: 2774.000\n",
            "Column: 1388, Selected False, Rank: 86.000\n",
            "Column: 1389, Selected False, Rank: 2778.000\n",
            "Column: 1390, Selected False, Rank: 2780.000\n",
            "Column: 1391, Selected False, Rank: 2782.000\n",
            "Column: 1392, Selected False, Rank: 2784.000\n",
            "Column: 1393, Selected False, Rank: 2786.000\n",
            "Column: 1394, Selected False, Rank: 2788.000\n",
            "Column: 1395, Selected False, Rank: 2790.000\n",
            "Column: 1396, Selected False, Rank: 2792.000\n",
            "Column: 1397, Selected False, Rank: 2794.000\n",
            "Column: 1398, Selected False, Rank: 2796.000\n",
            "Column: 1399, Selected False, Rank: 2798.000\n",
            "Column: 1400, Selected False, Rank: 2797.000\n",
            "Column: 1401, Selected False, Rank: 2795.000\n",
            "Column: 1402, Selected False, Rank: 2793.000\n",
            "Column: 1403, Selected False, Rank: 2791.000\n",
            "Column: 1404, Selected False, Rank: 2789.000\n",
            "Column: 1405, Selected False, Rank: 2787.000\n",
            "Column: 1406, Selected False, Rank: 2785.000\n",
            "Column: 1407, Selected False, Rank: 2783.000\n",
            "Column: 1408, Selected False, Rank: 2781.000\n",
            "Column: 1409, Selected False, Rank: 2779.000\n",
            "Column: 1410, Selected False, Rank: 2777.000\n",
            "Column: 1411, Selected False, Rank: 2753.000\n",
            "Column: 1412, Selected False, Rank: 2751.000\n",
            "Column: 1413, Selected False, Rank: 2749.000\n",
            "Column: 1414, Selected False, Rank: 2747.000\n",
            "Column: 1415, Selected False, Rank: 2745.000\n",
            "Column: 1416, Selected False, Rank: 2743.000\n",
            "Column: 1417, Selected False, Rank: 2741.000\n",
            "Column: 1418, Selected False, Rank: 2739.000\n",
            "Column: 1419, Selected False, Rank: 2737.000\n",
            "Column: 1420, Selected False, Rank: 2735.000\n",
            "Column: 1421, Selected False, Rank: 2733.000\n",
            "Column: 1422, Selected False, Rank: 2731.000\n",
            "Column: 1423, Selected False, Rank: 2727.000\n",
            "Column: 1424, Selected False, Rank: 2725.000\n",
            "Column: 1425, Selected False, Rank: 2723.000\n",
            "Column: 1426, Selected False, Rank: 2721.000\n",
            "Column: 1427, Selected False, Rank: 2719.000\n",
            "Column: 1428, Selected False, Rank: 2717.000\n",
            "Column: 1429, Selected False, Rank: 2715.000\n",
            "Column: 1430, Selected False, Rank: 2713.000\n",
            "Column: 1431, Selected False, Rank: 2711.000\n",
            "Column: 1432, Selected False, Rank: 2709.000\n",
            "Column: 1433, Selected False, Rank: 2707.000\n",
            "Column: 1434, Selected False, Rank: 2705.000\n",
            "Column: 1435, Selected False, Rank: 2703.000\n",
            "Column: 1436, Selected False, Rank: 2701.000\n",
            "Column: 1437, Selected False, Rank: 2699.000\n",
            "Column: 1438, Selected False, Rank: 2697.000\n",
            "Column: 1439, Selected False, Rank: 2695.000\n",
            "Column: 1440, Selected False, Rank: 2693.000\n",
            "Column: 1441, Selected False, Rank: 2691.000\n",
            "Column: 1442, Selected False, Rank: 2689.000\n",
            "Column: 1443, Selected False, Rank: 2687.000\n",
            "Column: 1444, Selected False, Rank: 2685.000\n",
            "Column: 1445, Selected False, Rank: 2683.000\n",
            "Column: 1446, Selected False, Rank: 2681.000\n",
            "Column: 1447, Selected False, Rank: 2679.000\n",
            "Column: 1448, Selected False, Rank: 2677.000\n",
            "Column: 1449, Selected False, Rank: 2675.000\n",
            "Column: 1450, Selected False, Rank: 2673.000\n",
            "Column: 1451, Selected False, Rank: 2671.000\n",
            "Column: 1452, Selected False, Rank: 2669.000\n",
            "Column: 1453, Selected False, Rank: 2667.000\n",
            "Column: 1454, Selected False, Rank: 2665.000\n",
            "Column: 1455, Selected False, Rank: 2663.000\n",
            "Column: 1456, Selected False, Rank: 2661.000\n",
            "Column: 1457, Selected False, Rank: 2659.000\n",
            "Column: 1458, Selected False, Rank: 2657.000\n",
            "Column: 1459, Selected False, Rank: 2655.000\n",
            "Column: 1460, Selected False, Rank: 2653.000\n",
            "Column: 1461, Selected False, Rank: 2651.000\n",
            "Column: 1462, Selected False, Rank: 2649.000\n",
            "Column: 1463, Selected False, Rank: 2647.000\n",
            "Column: 1464, Selected False, Rank: 2645.000\n",
            "Column: 1465, Selected False, Rank: 2643.000\n",
            "Column: 1466, Selected False, Rank: 2641.000\n",
            "Column: 1467, Selected False, Rank: 2639.000\n",
            "Column: 1468, Selected False, Rank: 2637.000\n",
            "Column: 1469, Selected False, Rank: 2635.000\n",
            "Column: 1470, Selected False, Rank: 2629.000\n",
            "Column: 1471, Selected False, Rank: 2627.000\n",
            "Column: 1472, Selected False, Rank: 2625.000\n",
            "Column: 1473, Selected False, Rank: 2623.000\n",
            "Column: 1474, Selected False, Rank: 2617.000\n",
            "Column: 1475, Selected False, Rank: 2615.000\n",
            "Column: 1476, Selected False, Rank: 2613.000\n",
            "Column: 1477, Selected False, Rank: 2611.000\n",
            "Column: 1478, Selected False, Rank: 2609.000\n",
            "Column: 1479, Selected False, Rank: 2607.000\n",
            "Column: 1480, Selected False, Rank: 2605.000\n",
            "Column: 1481, Selected False, Rank: 2603.000\n",
            "Column: 1482, Selected False, Rank: 2601.000\n",
            "Column: 1483, Selected False, Rank: 2599.000\n",
            "Column: 1484, Selected False, Rank: 2597.000\n",
            "Column: 1485, Selected False, Rank: 2595.000\n",
            "Column: 1486, Selected False, Rank: 2593.000\n",
            "Column: 1487, Selected False, Rank: 2591.000\n",
            "Column: 1488, Selected False, Rank: 2589.000\n",
            "Column: 1489, Selected False, Rank: 2587.000\n",
            "Column: 1490, Selected False, Rank: 2585.000\n",
            "Column: 1491, Selected False, Rank: 2583.000\n",
            "Column: 1492, Selected False, Rank: 2581.000\n",
            "Column: 1493, Selected True, Rank: 1.000\n",
            "Column: 1494, Selected False, Rank: 2535.000\n",
            "Column: 1495, Selected False, Rank: 2533.000\n",
            "Column: 1496, Selected False, Rank: 2531.000\n",
            "Column: 1497, Selected False, Rank: 2529.000\n",
            "Column: 1498, Selected False, Rank: 2527.000\n",
            "Column: 1499, Selected False, Rank: 127.000\n",
            "Column: 1500, Selected False, Rank: 2523.000\n",
            "Column: 1501, Selected False, Rank: 2521.000\n",
            "Column: 1502, Selected False, Rank: 2519.000\n",
            "Column: 1503, Selected False, Rank: 2517.000\n",
            "Column: 1504, Selected False, Rank: 2515.000\n",
            "Column: 1505, Selected False, Rank: 2513.000\n",
            "Column: 1506, Selected False, Rank: 2511.000\n",
            "Column: 1507, Selected False, Rank: 2509.000\n",
            "Column: 1508, Selected False, Rank: 2507.000\n",
            "Column: 1509, Selected False, Rank: 2505.000\n",
            "Column: 1510, Selected False, Rank: 2503.000\n",
            "Column: 1511, Selected False, Rank: 2501.000\n",
            "Column: 1512, Selected False, Rank: 58.000\n",
            "Column: 1513, Selected False, Rank: 2497.000\n",
            "Column: 1514, Selected False, Rank: 2495.000\n",
            "Column: 1515, Selected False, Rank: 2493.000\n",
            "Column: 1516, Selected False, Rank: 2491.000\n",
            "Column: 1517, Selected False, Rank: 2489.000\n",
            "Column: 1518, Selected False, Rank: 2487.000\n",
            "Column: 1519, Selected False, Rank: 2485.000\n",
            "Column: 1520, Selected False, Rank: 2483.000\n",
            "Column: 1521, Selected False, Rank: 2481.000\n",
            "Column: 1522, Selected False, Rank: 2479.000\n",
            "Column: 1523, Selected False, Rank: 2477.000\n",
            "Column: 1524, Selected False, Rank: 2475.000\n",
            "Column: 1525, Selected False, Rank: 2473.000\n",
            "Column: 1526, Selected False, Rank: 2471.000\n",
            "Column: 1527, Selected False, Rank: 2469.000\n",
            "Column: 1528, Selected False, Rank: 2467.000\n",
            "Column: 1529, Selected False, Rank: 2465.000\n",
            "Column: 1530, Selected False, Rank: 2463.000\n",
            "Column: 1531, Selected False, Rank: 2461.000\n",
            "Column: 1532, Selected False, Rank: 2459.000\n",
            "Column: 1533, Selected False, Rank: 2457.000\n",
            "Column: 1534, Selected False, Rank: 2455.000\n",
            "Column: 1535, Selected False, Rank: 2453.000\n",
            "Column: 1536, Selected False, Rank: 2451.000\n",
            "Column: 1537, Selected False, Rank: 2449.000\n",
            "Column: 1538, Selected False, Rank: 2447.000\n",
            "Column: 1539, Selected False, Rank: 2445.000\n",
            "Column: 1540, Selected False, Rank: 2443.000\n",
            "Column: 1541, Selected False, Rank: 2441.000\n",
            "Column: 1542, Selected False, Rank: 2439.000\n",
            "Column: 1543, Selected False, Rank: 2437.000\n",
            "Column: 1544, Selected False, Rank: 2422.000\n",
            "Column: 1545, Selected False, Rank: 66.000\n",
            "Column: 1546, Selected False, Rank: 75.000\n",
            "Column: 1547, Selected False, Rank: 15.000\n",
            "Column: 1548, Selected False, Rank: 21.000\n",
            "Column: 1549, Selected False, Rank: 20.000\n",
            "Column: 1550, Selected False, Rank: 13.000\n",
            "Column: 1551, Selected False, Rank: 132.000\n",
            "Column: 1552, Selected False, Rank: 196.000\n",
            "Column: 1553, Selected False, Rank: 188.000\n",
            "Column: 1554, Selected False, Rank: 133.000\n",
            "Column: 1555, Selected False, Rank: 131.000\n",
            "Column: 1556, Selected False, Rank: 203.000\n",
            "Column: 1557, Selected False, Rank: 205.000\n",
            "Column: 1558, Selected False, Rank: 207.000\n",
            "Column: 1559, Selected False, Rank: 209.000\n",
            "Column: 1560, Selected False, Rank: 211.000\n",
            "Column: 1561, Selected False, Rank: 213.000\n",
            "Column: 1562, Selected False, Rank: 215.000\n",
            "Column: 1563, Selected False, Rank: 217.000\n",
            "Column: 1564, Selected False, Rank: 219.000\n",
            "Column: 1565, Selected False, Rank: 221.000\n",
            "Column: 1566, Selected False, Rank: 223.000\n",
            "Column: 1567, Selected False, Rank: 225.000\n",
            "Column: 1568, Selected False, Rank: 227.000\n",
            "Column: 1569, Selected False, Rank: 229.000\n",
            "Column: 1570, Selected False, Rank: 231.000\n",
            "Column: 1571, Selected False, Rank: 233.000\n",
            "Column: 1572, Selected False, Rank: 235.000\n",
            "Column: 1573, Selected False, Rank: 257.000\n",
            "Column: 1574, Selected False, Rank: 258.000\n",
            "Column: 1575, Selected False, Rank: 236.000\n",
            "Column: 1576, Selected False, Rank: 237.000\n",
            "Column: 1577, Selected False, Rank: 239.000\n",
            "Column: 1578, Selected False, Rank: 2.000\n",
            "Column: 1579, Selected False, Rank: 242.000\n",
            "Column: 1580, Selected False, Rank: 243.000\n",
            "Column: 1581, Selected False, Rank: 244.000\n",
            "Column: 1582, Selected False, Rank: 245.000\n",
            "Column: 1583, Selected False, Rank: 247.000\n",
            "Column: 1584, Selected False, Rank: 249.000\n",
            "Column: 1585, Selected False, Rank: 105.000\n",
            "Column: 1586, Selected False, Rank: 253.000\n",
            "Column: 1587, Selected False, Rank: 255.000\n",
            "Column: 1588, Selected False, Rank: 287.000\n",
            "Column: 1589, Selected False, Rank: 288.000\n",
            "Column: 1590, Selected False, Rank: 290.000\n",
            "Column: 1591, Selected False, Rank: 292.000\n",
            "Column: 1592, Selected False, Rank: 295.000\n",
            "Column: 1593, Selected False, Rank: 296.000\n",
            "Column: 1594, Selected False, Rank: 298.000\n",
            "Column: 1595, Selected False, Rank: 301.000\n",
            "Column: 1596, Selected False, Rank: 302.000\n",
            "Column: 1597, Selected False, Rank: 304.000\n",
            "Column: 1598, Selected False, Rank: 256.000\n",
            "Column: 1599, Selected False, Rank: 167.000\n",
            "Column: 1600, Selected False, Rank: 165.000\n",
            "Column: 1601, Selected False, Rank: 152.000\n",
            "Column: 1602, Selected False, Rank: 150.000\n",
            "Column: 1603, Selected False, Rank: 265.000\n",
            "Column: 1604, Selected False, Rank: 267.000\n",
            "Column: 1605, Selected False, Rank: 148.000\n",
            "Column: 1606, Selected False, Rank: 269.000\n",
            "Column: 1607, Selected False, Rank: 270.000\n",
            "Column: 1608, Selected False, Rank: 271.000\n",
            "Column: 1609, Selected False, Rank: 272.000\n",
            "Column: 1610, Selected False, Rank: 273.000\n",
            "Column: 1611, Selected False, Rank: 275.000\n",
            "Column: 1612, Selected False, Rank: 279.000\n",
            "Column: 1613, Selected False, Rank: 280.000\n",
            "Column: 1614, Selected False, Rank: 281.000\n",
            "Column: 1615, Selected False, Rank: 285.000\n",
            "Column: 1616, Selected False, Rank: 286.000\n",
            "Column: 1617, Selected False, Rank: 283.000\n",
            "Column: 1618, Selected False, Rank: 284.000\n",
            "Column: 1619, Selected False, Rank: 305.000\n",
            "Column: 1620, Selected False, Rank: 307.000\n",
            "Column: 1621, Selected False, Rank: 251.000\n",
            "Column: 1622, Selected False, Rank: 311.000\n",
            "Column: 1623, Selected False, Rank: 312.000\n",
            "Column: 1624, Selected False, Rank: 315.000\n",
            "Column: 1625, Selected False, Rank: 317.000\n",
            "Column: 1626, Selected False, Rank: 319.000\n",
            "Column: 1627, Selected False, Rank: 321.000\n",
            "Column: 1628, Selected False, Rank: 347.000\n",
            "Column: 1629, Selected False, Rank: 349.000\n",
            "Column: 1630, Selected False, Rank: 411.000\n",
            "Column: 1631, Selected False, Rank: 412.000\n",
            "Column: 1632, Selected False, Rank: 414.000\n",
            "Column: 1633, Selected False, Rank: 416.000\n",
            "Column: 1634, Selected False, Rank: 418.000\n",
            "Column: 1635, Selected False, Rank: 420.000\n",
            "Column: 1636, Selected False, Rank: 422.000\n",
            "Column: 1637, Selected False, Rank: 424.000\n",
            "Column: 1638, Selected False, Rank: 426.000\n",
            "Column: 1639, Selected False, Rank: 99.000\n",
            "Column: 1640, Selected False, Rank: 430.000\n",
            "Column: 1641, Selected False, Rank: 432.000\n",
            "Column: 1642, Selected False, Rank: 434.000\n",
            "Column: 1643, Selected False, Rank: 125.000\n",
            "Column: 1644, Selected False, Rank: 345.000\n",
            "Column: 1645, Selected False, Rank: 326.000\n",
            "Column: 1646, Selected False, Rank: 327.000\n",
            "Column: 1647, Selected False, Rank: 359.000\n",
            "Column: 1648, Selected False, Rank: 361.000\n",
            "Column: 1649, Selected False, Rank: 427.000\n",
            "Column: 1650, Selected False, Rank: 435.000\n",
            "Column: 1651, Selected False, Rank: 437.000\n",
            "Column: 1652, Selected False, Rank: 439.000\n",
            "Column: 1653, Selected False, Rank: 441.000\n",
            "Column: 1654, Selected False, Rank: 443.000\n",
            "Column: 1655, Selected False, Rank: 445.000\n",
            "Column: 1656, Selected False, Rank: 447.000\n",
            "Column: 1657, Selected False, Rank: 449.000\n",
            "Column: 1658, Selected False, Rank: 451.000\n",
            "Column: 1659, Selected False, Rank: 453.000\n",
            "Column: 1660, Selected False, Rank: 455.000\n",
            "Column: 1661, Selected False, Rank: 457.000\n",
            "Column: 1662, Selected False, Rank: 459.000\n",
            "Column: 1663, Selected False, Rank: 461.000\n",
            "Column: 1664, Selected False, Rank: 367.000\n",
            "Column: 1665, Selected False, Rank: 368.000\n",
            "Column: 1666, Selected False, Rank: 365.000\n",
            "Column: 1667, Selected False, Rank: 328.000\n",
            "Column: 1668, Selected False, Rank: 331.000\n",
            "Column: 1669, Selected False, Rank: 373.000\n",
            "Column: 1670, Selected False, Rank: 375.000\n",
            "Column: 1671, Selected False, Rank: 377.000\n",
            "Column: 1672, Selected False, Rank: 379.000\n",
            "Column: 1673, Selected False, Rank: 382.000\n",
            "Column: 1674, Selected False, Rank: 381.000\n",
            "Column: 1675, Selected False, Rank: 333.000\n",
            "Column: 1676, Selected False, Rank: 335.000\n",
            "Column: 1677, Selected False, Rank: 140.000\n",
            "Column: 1678, Selected False, Rank: 339.000\n",
            "Column: 1679, Selected False, Rank: 371.000\n",
            "Column: 1680, Selected False, Rank: 372.000\n",
            "Column: 1681, Selected False, Rank: 160.000\n",
            "Column: 1682, Selected False, Rank: 92.000\n",
            "Column: 1683, Selected False, Rank: 351.000\n",
            "Column: 1684, Selected False, Rank: 353.000\n",
            "Column: 1685, Selected False, Rank: 355.000\n",
            "Column: 1686, Selected False, Rank: 357.000\n",
            "Column: 1687, Selected False, Rank: 61.000\n",
            "Column: 1688, Selected False, Rank: 463.000\n",
            "Column: 1689, Selected False, Rank: 465.000\n",
            "Column: 1690, Selected False, Rank: 467.000\n",
            "Column: 1691, Selected False, Rank: 469.000\n",
            "Column: 1692, Selected False, Rank: 471.000\n",
            "Column: 1693, Selected False, Rank: 473.000\n",
            "Column: 1694, Selected False, Rank: 475.000\n",
            "Column: 1695, Selected False, Rank: 477.000\n",
            "Column: 1696, Selected False, Rank: 479.000\n",
            "Column: 1697, Selected False, Rank: 481.000\n",
            "Column: 1698, Selected False, Rank: 483.000\n",
            "Column: 1699, Selected False, Rank: 485.000\n",
            "Column: 1700, Selected False, Rank: 487.000\n",
            "Column: 1701, Selected False, Rank: 489.000\n",
            "Column: 1702, Selected False, Rank: 491.000\n",
            "Column: 1703, Selected False, Rank: 493.000\n",
            "Column: 1704, Selected False, Rank: 495.000\n",
            "Column: 1705, Selected False, Rank: 497.000\n",
            "Column: 1706, Selected False, Rank: 499.000\n",
            "Column: 1707, Selected False, Rank: 501.000\n",
            "Column: 1708, Selected False, Rank: 503.000\n",
            "Column: 1709, Selected False, Rank: 505.000\n",
            "Column: 1710, Selected False, Rank: 507.000\n",
            "Column: 1711, Selected False, Rank: 409.000\n",
            "Column: 1712, Selected False, Rank: 369.000\n",
            "Column: 1713, Selected False, Rank: 8.000\n",
            "Column: 1714, Selected False, Rank: 515.000\n",
            "Column: 1715, Selected False, Rank: 517.000\n",
            "Column: 1716, Selected False, Rank: 519.000\n",
            "Column: 1717, Selected False, Rank: 521.000\n",
            "Column: 1718, Selected False, Rank: 523.000\n",
            "Column: 1719, Selected False, Rank: 525.000\n",
            "Column: 1720, Selected False, Rank: 527.000\n",
            "Column: 1721, Selected False, Rank: 529.000\n",
            "Column: 1722, Selected False, Rank: 531.000\n",
            "Column: 1723, Selected False, Rank: 533.000\n",
            "Column: 1724, Selected False, Rank: 535.000\n",
            "Column: 1725, Selected False, Rank: 537.000\n",
            "Column: 1726, Selected False, Rank: 539.000\n",
            "Column: 1727, Selected False, Rank: 541.000\n",
            "Column: 1728, Selected False, Rank: 543.000\n",
            "Column: 1729, Selected False, Rank: 545.000\n",
            "Column: 1730, Selected False, Rank: 547.000\n",
            "Column: 1731, Selected False, Rank: 549.000\n",
            "Column: 1732, Selected False, Rank: 551.000\n",
            "Column: 1733, Selected False, Rank: 553.000\n",
            "Column: 1734, Selected False, Rank: 555.000\n",
            "Column: 1735, Selected False, Rank: 557.000\n",
            "Column: 1736, Selected False, Rank: 559.000\n",
            "Column: 1737, Selected False, Rank: 561.000\n",
            "Column: 1738, Selected False, Rank: 563.000\n",
            "Column: 1739, Selected False, Rank: 565.000\n",
            "Column: 1740, Selected False, Rank: 567.000\n",
            "Column: 1741, Selected False, Rank: 569.000\n",
            "Column: 1742, Selected False, Rank: 571.000\n",
            "Column: 1743, Selected False, Rank: 573.000\n",
            "Column: 1744, Selected False, Rank: 575.000\n",
            "Column: 1745, Selected False, Rank: 577.000\n",
            "Column: 1746, Selected False, Rank: 579.000\n",
            "Column: 1747, Selected False, Rank: 581.000\n",
            "Column: 1748, Selected False, Rank: 583.000\n",
            "Column: 1749, Selected False, Rank: 585.000\n",
            "Column: 1750, Selected False, Rank: 587.000\n",
            "Column: 1751, Selected False, Rank: 589.000\n",
            "Column: 1752, Selected False, Rank: 591.000\n",
            "Column: 1753, Selected False, Rank: 593.000\n",
            "Column: 1754, Selected False, Rank: 595.000\n",
            "Column: 1755, Selected False, Rank: 597.000\n",
            "Column: 1756, Selected False, Rank: 599.000\n",
            "Column: 1757, Selected False, Rank: 601.000\n",
            "Column: 1758, Selected False, Rank: 603.000\n",
            "Column: 1759, Selected False, Rank: 605.000\n",
            "Column: 1760, Selected False, Rank: 607.000\n",
            "Column: 1761, Selected False, Rank: 609.000\n",
            "Column: 1762, Selected False, Rank: 611.000\n",
            "Column: 1763, Selected False, Rank: 613.000\n",
            "Column: 1764, Selected False, Rank: 615.000\n",
            "Column: 1765, Selected False, Rank: 617.000\n",
            "Column: 1766, Selected False, Rank: 619.000\n",
            "Column: 1767, Selected False, Rank: 621.000\n",
            "Column: 1768, Selected False, Rank: 623.000\n",
            "Column: 1769, Selected False, Rank: 625.000\n",
            "Column: 1770, Selected False, Rank: 627.000\n",
            "Column: 1771, Selected False, Rank: 629.000\n",
            "Column: 1772, Selected False, Rank: 631.000\n",
            "Column: 1773, Selected False, Rank: 633.000\n",
            "Column: 1774, Selected False, Rank: 635.000\n",
            "Column: 1775, Selected False, Rank: 637.000\n",
            "Column: 1776, Selected False, Rank: 639.000\n",
            "Column: 1777, Selected False, Rank: 641.000\n",
            "Column: 1778, Selected False, Rank: 643.000\n",
            "Column: 1779, Selected False, Rank: 645.000\n",
            "Column: 1780, Selected False, Rank: 647.000\n",
            "Column: 1781, Selected False, Rank: 649.000\n",
            "Column: 1782, Selected False, Rank: 651.000\n",
            "Column: 1783, Selected False, Rank: 653.000\n",
            "Column: 1784, Selected False, Rank: 655.000\n",
            "Column: 1785, Selected False, Rank: 657.000\n",
            "Column: 1786, Selected False, Rank: 659.000\n",
            "Column: 1787, Selected False, Rank: 661.000\n",
            "Column: 1788, Selected False, Rank: 663.000\n",
            "Column: 1789, Selected False, Rank: 665.000\n",
            "Column: 1790, Selected False, Rank: 667.000\n",
            "Column: 1791, Selected False, Rank: 669.000\n",
            "Column: 1792, Selected False, Rank: 671.000\n",
            "Column: 1793, Selected False, Rank: 673.000\n",
            "Column: 1794, Selected False, Rank: 675.000\n",
            "Column: 1795, Selected False, Rank: 677.000\n",
            "Column: 1796, Selected False, Rank: 679.000\n",
            "Column: 1797, Selected False, Rank: 681.000\n",
            "Column: 1798, Selected False, Rank: 683.000\n",
            "Column: 1799, Selected False, Rank: 685.000\n",
            "Column: 1800, Selected False, Rank: 687.000\n",
            "Column: 1801, Selected False, Rank: 534.000\n",
            "Column: 1802, Selected False, Rank: 385.000\n",
            "Column: 1803, Selected False, Rank: 387.000\n",
            "Column: 1804, Selected False, Rank: 389.000\n",
            "Column: 1805, Selected False, Rank: 391.000\n",
            "Column: 1806, Selected False, Rank: 393.000\n",
            "Column: 1807, Selected False, Rank: 395.000\n",
            "Column: 1808, Selected False, Rank: 397.000\n",
            "Column: 1809, Selected False, Rank: 399.000\n",
            "Column: 1810, Selected False, Rank: 401.000\n",
            "Column: 1811, Selected False, Rank: 403.000\n",
            "Column: 1812, Selected False, Rank: 405.000\n",
            "Column: 1813, Selected False, Rank: 406.000\n",
            "Column: 1814, Selected False, Rank: 56.000\n",
            "Column: 1815, Selected False, Rank: 715.000\n",
            "Column: 1816, Selected False, Rank: 717.000\n",
            "Column: 1817, Selected False, Rank: 719.000\n",
            "Column: 1818, Selected False, Rank: 721.000\n",
            "Column: 1819, Selected False, Rank: 723.000\n",
            "Column: 1820, Selected False, Rank: 725.000\n",
            "Column: 1821, Selected False, Rank: 727.000\n",
            "Column: 1822, Selected False, Rank: 729.000\n",
            "Column: 1823, Selected False, Rank: 731.000\n",
            "Column: 1824, Selected False, Rank: 733.000\n",
            "Column: 1825, Selected False, Rank: 735.000\n",
            "Column: 1826, Selected False, Rank: 737.000\n",
            "Column: 1827, Selected False, Rank: 739.000\n",
            "Column: 1828, Selected False, Rank: 741.000\n",
            "Column: 1829, Selected False, Rank: 743.000\n",
            "Column: 1830, Selected False, Rank: 745.000\n",
            "Column: 1831, Selected False, Rank: 747.000\n",
            "Column: 1832, Selected False, Rank: 749.000\n",
            "Column: 1833, Selected False, Rank: 751.000\n",
            "Column: 1834, Selected False, Rank: 753.000\n",
            "Column: 1835, Selected False, Rank: 755.000\n",
            "Column: 1836, Selected False, Rank: 757.000\n",
            "Column: 1837, Selected False, Rank: 759.000\n",
            "Column: 1838, Selected False, Rank: 761.000\n",
            "Column: 1839, Selected False, Rank: 763.000\n",
            "Column: 1840, Selected False, Rank: 765.000\n",
            "Column: 1841, Selected False, Rank: 767.000\n",
            "Column: 1842, Selected False, Rank: 769.000\n",
            "Column: 1843, Selected False, Rank: 771.000\n",
            "Column: 1844, Selected False, Rank: 773.000\n",
            "Column: 1845, Selected False, Rank: 775.000\n",
            "Column: 1846, Selected False, Rank: 777.000\n",
            "Column: 1847, Selected False, Rank: 779.000\n",
            "Column: 1848, Selected False, Rank: 781.000\n",
            "Column: 1849, Selected False, Rank: 783.000\n",
            "Column: 1850, Selected False, Rank: 785.000\n",
            "Column: 1851, Selected False, Rank: 787.000\n",
            "Column: 1852, Selected False, Rank: 789.000\n",
            "Column: 1853, Selected False, Rank: 791.000\n",
            "Column: 1854, Selected False, Rank: 793.000\n",
            "Column: 1855, Selected False, Rank: 795.000\n",
            "Column: 1856, Selected False, Rank: 797.000\n",
            "Column: 1857, Selected False, Rank: 799.000\n",
            "Column: 1858, Selected False, Rank: 801.000\n",
            "Column: 1859, Selected False, Rank: 803.000\n",
            "Column: 1860, Selected False, Rank: 805.000\n",
            "Column: 1861, Selected False, Rank: 807.000\n",
            "Column: 1862, Selected False, Rank: 809.000\n",
            "Column: 1863, Selected False, Rank: 811.000\n",
            "Column: 1864, Selected False, Rank: 813.000\n",
            "Column: 1865, Selected False, Rank: 815.000\n",
            "Column: 1866, Selected False, Rank: 817.000\n",
            "Column: 1867, Selected False, Rank: 819.000\n",
            "Column: 1868, Selected False, Rank: 821.000\n",
            "Column: 1869, Selected False, Rank: 823.000\n",
            "Column: 1870, Selected False, Rank: 511.000\n",
            "Column: 1871, Selected False, Rank: 512.000\n",
            "Column: 1872, Selected False, Rank: 111.000\n",
            "Column: 1873, Selected False, Rank: 829.000\n",
            "Column: 1874, Selected False, Rank: 895.000\n",
            "Column: 1875, Selected False, Rank: 882.000\n",
            "Column: 1876, Selected False, Rank: 831.000\n",
            "Column: 1877, Selected False, Rank: 833.000\n",
            "Column: 1878, Selected False, Rank: 695.000\n",
            "Column: 1879, Selected False, Rank: 697.000\n",
            "Column: 1880, Selected False, Rank: 699.000\n",
            "Column: 1881, Selected False, Rank: 701.000\n",
            "Column: 1882, Selected False, Rank: 703.000\n",
            "Column: 1883, Selected False, Rank: 705.000\n",
            "Column: 1884, Selected False, Rank: 707.000\n",
            "Column: 1885, Selected False, Rank: 877.000\n",
            "Column: 1886, Selected False, Rank: 709.000\n",
            "Column: 1887, Selected False, Rank: 710.000\n",
            "Column: 1888, Selected False, Rank: 711.000\n",
            "Column: 1889, Selected False, Rank: 886.000\n",
            "Column: 1890, Selected False, Rank: 712.000\n",
            "Column: 1891, Selected False, Rank: 80.000\n",
            "Column: 1892, Selected False, Rank: 835.000\n",
            "Column: 1893, Selected False, Rank: 897.000\n",
            "Column: 1894, Selected False, Rank: 16.000\n",
            "Column: 1895, Selected False, Rank: 898.000\n",
            "Column: 1896, Selected False, Rank: 893.000\n",
            "Column: 1897, Selected False, Rank: 839.000\n",
            "Column: 1898, Selected False, Rank: 841.000\n",
            "Column: 1899, Selected False, Rank: 843.000\n",
            "Column: 1900, Selected False, Rank: 845.000\n",
            "Column: 1901, Selected False, Rank: 847.000\n",
            "Column: 1902, Selected False, Rank: 849.000\n",
            "Column: 1903, Selected False, Rank: 879.000\n",
            "Column: 1904, Selected False, Rank: 885.000\n",
            "Column: 1905, Selected False, Rank: 851.000\n",
            "Column: 1906, Selected False, Rank: 853.000\n",
            "Column: 1907, Selected False, Rank: 837.000\n",
            "Column: 1908, Selected False, Rank: 713.000\n",
            "Column: 1909, Selected False, Rank: 513.000\n",
            "Column: 1910, Selected False, Rank: 900.000\n",
            "Column: 1911, Selected False, Rank: 902.000\n",
            "Column: 1912, Selected False, Rank: 904.000\n",
            "Column: 1913, Selected False, Rank: 906.000\n",
            "Column: 1914, Selected False, Rank: 908.000\n",
            "Column: 1915, Selected False, Rank: 910.000\n",
            "Column: 1916, Selected False, Rank: 912.000\n",
            "Column: 1917, Selected False, Rank: 914.000\n",
            "Column: 1918, Selected False, Rank: 916.000\n",
            "Column: 1919, Selected False, Rank: 918.000\n",
            "Column: 1920, Selected False, Rank: 920.000\n",
            "Column: 1921, Selected False, Rank: 924.000\n",
            "Column: 1922, Selected False, Rank: 926.000\n",
            "Column: 1923, Selected False, Rank: 54.000\n",
            "Column: 1924, Selected False, Rank: 928.000\n",
            "Column: 1925, Selected False, Rank: 930.000\n",
            "Column: 1926, Selected False, Rank: 932.000\n",
            "Column: 1927, Selected False, Rank: 934.000\n",
            "Column: 1928, Selected False, Rank: 936.000\n",
            "Column: 1929, Selected False, Rank: 938.000\n",
            "Column: 1930, Selected False, Rank: 940.000\n",
            "Column: 1931, Selected False, Rank: 942.000\n",
            "Column: 1932, Selected False, Rank: 944.000\n",
            "Column: 1933, Selected False, Rank: 946.000\n",
            "Column: 1934, Selected False, Rank: 948.000\n",
            "Column: 1935, Selected False, Rank: 950.000\n",
            "Column: 1936, Selected False, Rank: 952.000\n",
            "Column: 1937, Selected False, Rank: 954.000\n",
            "Column: 1938, Selected False, Rank: 956.000\n",
            "Column: 1939, Selected False, Rank: 958.000\n",
            "Column: 1940, Selected False, Rank: 960.000\n",
            "Column: 1941, Selected False, Rank: 962.000\n",
            "Column: 1942, Selected False, Rank: 964.000\n",
            "Column: 1943, Selected False, Rank: 966.000\n",
            "Column: 1944, Selected False, Rank: 114.000\n",
            "Column: 1945, Selected False, Rank: 968.000\n",
            "Column: 1946, Selected False, Rank: 970.000\n",
            "Column: 1947, Selected False, Rank: 972.000\n",
            "Column: 1948, Selected False, Rank: 974.000\n",
            "Column: 1949, Selected False, Rank: 976.000\n",
            "Column: 1950, Selected False, Rank: 980.000\n",
            "Column: 1951, Selected False, Rank: 982.000\n",
            "Column: 1952, Selected False, Rank: 984.000\n",
            "Column: 1953, Selected False, Rank: 986.000\n",
            "Column: 1954, Selected False, Rank: 988.000\n",
            "Column: 1955, Selected False, Rank: 990.000\n",
            "Column: 1956, Selected False, Rank: 992.000\n",
            "Column: 1957, Selected False, Rank: 994.000\n",
            "Column: 1958, Selected False, Rank: 996.000\n",
            "Column: 1959, Selected False, Rank: 998.000\n",
            "Column: 1960, Selected False, Rank: 1000.000\n",
            "Column: 1961, Selected False, Rank: 1002.000\n",
            "Column: 1962, Selected False, Rank: 67.000\n",
            "Column: 1963, Selected False, Rank: 1004.000\n",
            "Column: 1964, Selected False, Rank: 1006.000\n",
            "Column: 1965, Selected False, Rank: 1010.000\n",
            "Column: 1966, Selected False, Rank: 1012.000\n",
            "Column: 1967, Selected False, Rank: 1014.000\n",
            "Column: 1968, Selected False, Rank: 1016.000\n",
            "Column: 1969, Selected False, Rank: 26.000\n",
            "Column: 1970, Selected False, Rank: 1018.000\n",
            "Column: 1971, Selected False, Rank: 1020.000\n",
            "Column: 1972, Selected False, Rank: 1022.000\n",
            "Column: 1973, Selected False, Rank: 1024.000\n",
            "Column: 1974, Selected False, Rank: 1026.000\n",
            "Column: 1975, Selected False, Rank: 1028.000\n",
            "Column: 1976, Selected False, Rank: 1030.000\n",
            "Column: 1977, Selected False, Rank: 76.000\n",
            "Column: 1978, Selected False, Rank: 1032.000\n",
            "Column: 1979, Selected False, Rank: 1034.000\n",
            "Column: 1980, Selected False, Rank: 87.000\n",
            "Column: 1981, Selected False, Rank: 1036.000\n",
            "Column: 1982, Selected False, Rank: 1038.000\n",
            "Column: 1983, Selected False, Rank: 1040.000\n",
            "Column: 1984, Selected False, Rank: 1042.000\n",
            "Column: 1985, Selected False, Rank: 1044.000\n",
            "Column: 1986, Selected False, Rank: 1046.000\n",
            "Column: 1987, Selected False, Rank: 1048.000\n",
            "Column: 1988, Selected False, Rank: 1050.000\n",
            "Column: 1989, Selected False, Rank: 1052.000\n",
            "Column: 1990, Selected False, Rank: 1054.000\n",
            "Column: 1991, Selected False, Rank: 6.000\n",
            "Column: 1992, Selected False, Rank: 93.000\n",
            "Column: 1993, Selected False, Rank: 1056.000\n",
            "Column: 1994, Selected False, Rank: 1058.000\n",
            "Column: 1995, Selected False, Rank: 1060.000\n",
            "Column: 1996, Selected False, Rank: 1062.000\n",
            "Column: 1997, Selected False, Rank: 1064.000\n",
            "Column: 1998, Selected False, Rank: 1066.000\n",
            "Column: 1999, Selected False, Rank: 1068.000\n",
            "Column: 2000, Selected False, Rank: 1070.000\n",
            "Column: 2001, Selected False, Rank: 1072.000\n",
            "Column: 2002, Selected False, Rank: 1074.000\n",
            "Column: 2003, Selected False, Rank: 1076.000\n",
            "Column: 2004, Selected False, Rank: 1078.000\n",
            "Column: 2005, Selected False, Rank: 1080.000\n",
            "Column: 2006, Selected False, Rank: 1082.000\n",
            "Column: 2007, Selected False, Rank: 1084.000\n",
            "Column: 2008, Selected False, Rank: 1086.000\n",
            "Column: 2009, Selected False, Rank: 1088.000\n",
            "Column: 2010, Selected False, Rank: 1090.000\n",
            "Column: 2011, Selected False, Rank: 1092.000\n",
            "Column: 2012, Selected False, Rank: 1094.000\n",
            "Column: 2013, Selected False, Rank: 1096.000\n",
            "Column: 2014, Selected False, Rank: 1098.000\n",
            "Column: 2015, Selected False, Rank: 1100.000\n",
            "Column: 2016, Selected False, Rank: 1102.000\n",
            "Column: 2017, Selected False, Rank: 1104.000\n",
            "Column: 2018, Selected False, Rank: 1106.000\n",
            "Column: 2019, Selected False, Rank: 1108.000\n",
            "Column: 2020, Selected False, Rank: 1110.000\n",
            "Column: 2021, Selected False, Rank: 1112.000\n",
            "Column: 2022, Selected False, Rank: 1114.000\n",
            "Column: 2023, Selected False, Rank: 113.000\n",
            "Column: 2024, Selected False, Rank: 1116.000\n",
            "Column: 2025, Selected False, Rank: 1118.000\n",
            "Column: 2026, Selected False, Rank: 1120.000\n",
            "Column: 2027, Selected False, Rank: 1122.000\n",
            "Column: 2028, Selected False, Rank: 1124.000\n",
            "Column: 2029, Selected False, Rank: 1126.000\n",
            "Column: 2030, Selected False, Rank: 1128.000\n",
            "Column: 2031, Selected False, Rank: 1130.000\n",
            "Column: 2032, Selected False, Rank: 1132.000\n",
            "Column: 2033, Selected False, Rank: 1134.000\n",
            "Column: 2034, Selected False, Rank: 1136.000\n",
            "Column: 2035, Selected False, Rank: 1140.000\n",
            "Column: 2036, Selected False, Rank: 1142.000\n",
            "Column: 2037, Selected False, Rank: 1144.000\n",
            "Column: 2038, Selected False, Rank: 1146.000\n",
            "Column: 2039, Selected False, Rank: 1148.000\n",
            "Column: 2040, Selected False, Rank: 1150.000\n",
            "Column: 2041, Selected False, Rank: 1152.000\n",
            "Column: 2042, Selected False, Rank: 1154.000\n",
            "Column: 2043, Selected False, Rank: 1156.000\n",
            "Column: 2044, Selected False, Rank: 1158.000\n",
            "Column: 2045, Selected False, Rank: 1160.000\n",
            "Column: 2046, Selected False, Rank: 1162.000\n",
            "Column: 2047, Selected False, Rank: 1164.000\n",
            "Column: 2048, Selected False, Rank: 1166.000\n",
            "Column: 2049, Selected False, Rank: 1168.000\n",
            "Column: 2050, Selected False, Rank: 1170.000\n",
            "Column: 2051, Selected False, Rank: 1172.000\n",
            "Column: 2052, Selected False, Rank: 1174.000\n",
            "Column: 2053, Selected False, Rank: 1176.000\n",
            "Column: 2054, Selected False, Rank: 1178.000\n",
            "Column: 2055, Selected False, Rank: 1180.000\n",
            "Column: 2056, Selected False, Rank: 1182.000\n",
            "Column: 2057, Selected False, Rank: 1184.000\n",
            "Column: 2058, Selected False, Rank: 1186.000\n",
            "Column: 2059, Selected False, Rank: 1188.000\n",
            "Column: 2060, Selected False, Rank: 1190.000\n",
            "Column: 2061, Selected False, Rank: 1192.000\n",
            "Column: 2062, Selected False, Rank: 1194.000\n",
            "Column: 2063, Selected False, Rank: 1196.000\n",
            "Column: 2064, Selected False, Rank: 1198.000\n",
            "Column: 2065, Selected False, Rank: 1200.000\n",
            "Column: 2066, Selected False, Rank: 1202.000\n",
            "Column: 2067, Selected False, Rank: 1204.000\n",
            "Column: 2068, Selected False, Rank: 1206.000\n",
            "Column: 2069, Selected False, Rank: 1208.000\n",
            "Column: 2070, Selected False, Rank: 1210.000\n",
            "Column: 2071, Selected False, Rank: 1212.000\n",
            "Column: 2072, Selected False, Rank: 1214.000\n",
            "Column: 2073, Selected False, Rank: 1216.000\n",
            "Column: 2074, Selected False, Rank: 1218.000\n",
            "Column: 2075, Selected False, Rank: 1220.000\n",
            "Column: 2076, Selected False, Rank: 1222.000\n",
            "Column: 2077, Selected False, Rank: 1224.000\n",
            "Column: 2078, Selected False, Rank: 1226.000\n",
            "Column: 2079, Selected False, Rank: 1228.000\n",
            "Column: 2080, Selected False, Rank: 1230.000\n",
            "Column: 2081, Selected False, Rank: 1234.000\n",
            "Column: 2082, Selected False, Rank: 1238.000\n",
            "Column: 2083, Selected False, Rank: 1240.000\n",
            "Column: 2084, Selected False, Rank: 1242.000\n",
            "Column: 2085, Selected False, Rank: 1244.000\n",
            "Column: 2086, Selected False, Rank: 1246.000\n",
            "Column: 2087, Selected False, Rank: 1248.000\n",
            "Column: 2088, Selected False, Rank: 1250.000\n",
            "Column: 2089, Selected False, Rank: 1252.000\n",
            "Column: 2090, Selected False, Rank: 1254.000\n",
            "Column: 2091, Selected False, Rank: 1256.000\n",
            "Column: 2092, Selected False, Rank: 1258.000\n",
            "Column: 2093, Selected False, Rank: 1260.000\n",
            "Column: 2094, Selected False, Rank: 1262.000\n",
            "Column: 2095, Selected False, Rank: 1264.000\n",
            "Column: 2096, Selected False, Rank: 1266.000\n",
            "Column: 2097, Selected False, Rank: 1268.000\n",
            "Column: 2098, Selected False, Rank: 1272.000\n",
            "Column: 2099, Selected False, Rank: 74.000\n",
            "Column: 2100, Selected False, Rank: 1274.000\n",
            "Column: 2101, Selected False, Rank: 1276.000\n",
            "Column: 2102, Selected False, Rank: 1280.000\n",
            "Column: 2103, Selected False, Rank: 1282.000\n",
            "Column: 2104, Selected False, Rank: 1284.000\n",
            "Column: 2105, Selected False, Rank: 1286.000\n",
            "Column: 2106, Selected False, Rank: 1288.000\n",
            "Column: 2107, Selected False, Rank: 1290.000\n",
            "Column: 2108, Selected False, Rank: 1292.000\n",
            "Column: 2109, Selected False, Rank: 1294.000\n",
            "Column: 2110, Selected False, Rank: 1296.000\n",
            "Column: 2111, Selected False, Rank: 1298.000\n",
            "Column: 2112, Selected False, Rank: 1300.000\n",
            "Column: 2113, Selected False, Rank: 1302.000\n",
            "Column: 2114, Selected False, Rank: 1304.000\n",
            "Column: 2115, Selected False, Rank: 1306.000\n",
            "Column: 2116, Selected False, Rank: 1308.000\n",
            "Column: 2117, Selected False, Rank: 1310.000\n",
            "Column: 2118, Selected False, Rank: 1312.000\n",
            "Column: 2119, Selected False, Rank: 1314.000\n",
            "Column: 2120, Selected False, Rank: 1316.000\n",
            "Column: 2121, Selected False, Rank: 1318.000\n",
            "Column: 2122, Selected False, Rank: 1320.000\n",
            "Column: 2123, Selected False, Rank: 1322.000\n",
            "Column: 2124, Selected False, Rank: 1324.000\n",
            "Column: 2125, Selected False, Rank: 1326.000\n",
            "Column: 2126, Selected False, Rank: 1328.000\n",
            "Column: 2127, Selected False, Rank: 1330.000\n",
            "Column: 2128, Selected False, Rank: 1332.000\n",
            "Column: 2129, Selected False, Rank: 1334.000\n",
            "Column: 2130, Selected False, Rank: 1336.000\n",
            "Column: 2131, Selected False, Rank: 1338.000\n",
            "Column: 2132, Selected False, Rank: 1340.000\n",
            "Column: 2133, Selected False, Rank: 1342.000\n",
            "Column: 2134, Selected False, Rank: 122.000\n",
            "Column: 2135, Selected False, Rank: 1344.000\n",
            "Column: 2136, Selected False, Rank: 1346.000\n",
            "Column: 2137, Selected False, Rank: 1348.000\n",
            "Column: 2138, Selected False, Rank: 1350.000\n",
            "Column: 2139, Selected False, Rank: 1352.000\n",
            "Column: 2140, Selected False, Rank: 1354.000\n",
            "Column: 2141, Selected False, Rank: 1356.000\n",
            "Column: 2142, Selected False, Rank: 1358.000\n",
            "Column: 2143, Selected False, Rank: 1360.000\n",
            "Column: 2144, Selected False, Rank: 1362.000\n",
            "Column: 2145, Selected False, Rank: 1364.000\n",
            "Column: 2146, Selected False, Rank: 1366.000\n",
            "Column: 2147, Selected False, Rank: 1368.000\n",
            "Column: 2148, Selected False, Rank: 1370.000\n",
            "Column: 2149, Selected False, Rank: 1372.000\n",
            "Column: 2150, Selected False, Rank: 1374.000\n",
            "Column: 2151, Selected False, Rank: 1376.000\n",
            "Column: 2152, Selected False, Rank: 1378.000\n",
            "Column: 2153, Selected False, Rank: 1380.000\n",
            "Column: 2154, Selected False, Rank: 1382.000\n",
            "Column: 2155, Selected False, Rank: 1384.000\n",
            "Column: 2156, Selected False, Rank: 1386.000\n",
            "Column: 2157, Selected False, Rank: 1388.000\n",
            "Column: 2158, Selected False, Rank: 1390.000\n",
            "Column: 2159, Selected False, Rank: 1392.000\n",
            "Column: 2160, Selected False, Rank: 1394.000\n",
            "Column: 2161, Selected False, Rank: 1396.000\n",
            "Column: 2162, Selected False, Rank: 1398.000\n",
            "Column: 2163, Selected False, Rank: 1400.000\n",
            "Column: 2164, Selected False, Rank: 1402.000\n",
            "Column: 2165, Selected False, Rank: 1404.000\n",
            "Column: 2166, Selected False, Rank: 1406.000\n",
            "Column: 2167, Selected False, Rank: 1408.000\n",
            "Column: 2168, Selected False, Rank: 1410.000\n",
            "Column: 2169, Selected False, Rank: 1412.000\n",
            "Column: 2170, Selected False, Rank: 1414.000\n",
            "Column: 2171, Selected False, Rank: 1416.000\n",
            "Column: 2172, Selected False, Rank: 1418.000\n",
            "Column: 2173, Selected False, Rank: 1420.000\n",
            "Column: 2174, Selected False, Rank: 1422.000\n",
            "Column: 2175, Selected False, Rank: 1424.000\n",
            "Column: 2176, Selected False, Rank: 1426.000\n",
            "Column: 2177, Selected False, Rank: 1428.000\n",
            "Column: 2178, Selected False, Rank: 1430.000\n",
            "Column: 2179, Selected False, Rank: 1432.000\n",
            "Column: 2180, Selected False, Rank: 1434.000\n",
            "Column: 2181, Selected False, Rank: 1436.000\n",
            "Column: 2182, Selected False, Rank: 1438.000\n",
            "Column: 2183, Selected False, Rank: 124.000\n",
            "Column: 2184, Selected False, Rank: 1440.000\n",
            "Column: 2185, Selected False, Rank: 1444.000\n",
            "Column: 2186, Selected False, Rank: 1446.000\n",
            "Column: 2187, Selected False, Rank: 1448.000\n",
            "Column: 2188, Selected False, Rank: 1450.000\n",
            "Column: 2189, Selected False, Rank: 1452.000\n",
            "Column: 2190, Selected False, Rank: 1454.000\n",
            "Column: 2191, Selected False, Rank: 1456.000\n",
            "Column: 2192, Selected False, Rank: 1458.000\n",
            "Column: 2193, Selected False, Rank: 1460.000\n",
            "Column: 2194, Selected False, Rank: 1462.000\n",
            "Column: 2195, Selected False, Rank: 1464.000\n",
            "Column: 2196, Selected False, Rank: 1466.000\n",
            "Column: 2197, Selected False, Rank: 1468.000\n",
            "Column: 2198, Selected False, Rank: 1470.000\n",
            "Column: 2199, Selected False, Rank: 1472.000\n",
            "Column: 2200, Selected False, Rank: 1474.000\n",
            "Column: 2201, Selected False, Rank: 1476.000\n",
            "Column: 2202, Selected False, Rank: 1478.000\n",
            "Column: 2203, Selected False, Rank: 1480.000\n",
            "Column: 2204, Selected False, Rank: 1482.000\n",
            "Column: 2205, Selected False, Rank: 1484.000\n",
            "Column: 2206, Selected False, Rank: 1486.000\n",
            "Column: 2207, Selected False, Rank: 1488.000\n",
            "Column: 2208, Selected False, Rank: 1492.000\n",
            "Column: 2209, Selected False, Rank: 1494.000\n",
            "Column: 2210, Selected False, Rank: 1496.000\n",
            "Column: 2211, Selected False, Rank: 1498.000\n",
            "Column: 2212, Selected False, Rank: 1500.000\n",
            "Column: 2213, Selected False, Rank: 1502.000\n",
            "Column: 2214, Selected False, Rank: 1504.000\n",
            "Column: 2215, Selected False, Rank: 1506.000\n",
            "Column: 2216, Selected False, Rank: 1508.000\n",
            "Column: 2217, Selected False, Rank: 1510.000\n",
            "Column: 2218, Selected False, Rank: 1512.000\n",
            "Column: 2219, Selected False, Rank: 1514.000\n",
            "Column: 2220, Selected False, Rank: 1516.000\n",
            "Column: 2221, Selected False, Rank: 1518.000\n",
            "Column: 2222, Selected False, Rank: 1520.000\n",
            "Column: 2223, Selected False, Rank: 1522.000\n",
            "Column: 2224, Selected False, Rank: 1524.000\n",
            "Column: 2225, Selected False, Rank: 1526.000\n",
            "Column: 2226, Selected False, Rank: 1528.000\n",
            "Column: 2227, Selected False, Rank: 1530.000\n",
            "Column: 2228, Selected False, Rank: 1532.000\n",
            "Column: 2229, Selected False, Rank: 1534.000\n",
            "Column: 2230, Selected False, Rank: 1536.000\n",
            "Column: 2231, Selected False, Rank: 1538.000\n",
            "Column: 2232, Selected False, Rank: 1540.000\n",
            "Column: 2233, Selected False, Rank: 1542.000\n",
            "Column: 2234, Selected False, Rank: 1544.000\n",
            "Column: 2235, Selected False, Rank: 1546.000\n",
            "Column: 2236, Selected False, Rank: 1548.000\n",
            "Column: 2237, Selected False, Rank: 1550.000\n",
            "Column: 2238, Selected False, Rank: 1552.000\n",
            "Column: 2239, Selected False, Rank: 1554.000\n",
            "Column: 2240, Selected False, Rank: 1556.000\n",
            "Column: 2241, Selected False, Rank: 1560.000\n",
            "Column: 2242, Selected False, Rank: 1562.000\n",
            "Column: 2243, Selected False, Rank: 1564.000\n",
            "Column: 2244, Selected False, Rank: 1566.000\n",
            "Column: 2245, Selected False, Rank: 1568.000\n",
            "Column: 2246, Selected False, Rank: 1570.000\n",
            "Column: 2247, Selected False, Rank: 1572.000\n",
            "Column: 2248, Selected False, Rank: 1574.000\n",
            "Column: 2249, Selected False, Rank: 1576.000\n",
            "Column: 2250, Selected False, Rank: 1578.000\n",
            "Column: 2251, Selected False, Rank: 1580.000\n",
            "Column: 2252, Selected False, Rank: 1582.000\n",
            "Column: 2253, Selected False, Rank: 1584.000\n",
            "Column: 2254, Selected False, Rank: 1586.000\n",
            "Column: 2255, Selected False, Rank: 1588.000\n",
            "Column: 2256, Selected False, Rank: 1590.000\n",
            "Column: 2257, Selected False, Rank: 1592.000\n",
            "Column: 2258, Selected False, Rank: 1594.000\n",
            "Column: 2259, Selected False, Rank: 1596.000\n",
            "Column: 2260, Selected False, Rank: 1598.000\n",
            "Column: 2261, Selected False, Rank: 1600.000\n",
            "Column: 2262, Selected False, Rank: 1602.000\n",
            "Column: 2263, Selected False, Rank: 1604.000\n",
            "Column: 2264, Selected False, Rank: 1606.000\n",
            "Column: 2265, Selected False, Rank: 1608.000\n",
            "Column: 2266, Selected False, Rank: 1610.000\n",
            "Column: 2267, Selected False, Rank: 1612.000\n",
            "Column: 2268, Selected False, Rank: 1614.000\n",
            "Column: 2269, Selected False, Rank: 1616.000\n",
            "Column: 2270, Selected False, Rank: 1618.000\n",
            "Column: 2271, Selected False, Rank: 1620.000\n",
            "Column: 2272, Selected False, Rank: 1622.000\n",
            "Column: 2273, Selected False, Rank: 1624.000\n",
            "Column: 2274, Selected False, Rank: 1626.000\n",
            "Column: 2275, Selected False, Rank: 1628.000\n",
            "Column: 2276, Selected False, Rank: 1630.000\n",
            "Column: 2277, Selected False, Rank: 1632.000\n",
            "Column: 2278, Selected False, Rank: 1634.000\n",
            "Column: 2279, Selected False, Rank: 1636.000\n",
            "Column: 2280, Selected False, Rank: 1638.000\n",
            "Column: 2281, Selected False, Rank: 1640.000\n",
            "Column: 2282, Selected False, Rank: 1642.000\n",
            "Column: 2283, Selected False, Rank: 1644.000\n",
            "Column: 2284, Selected False, Rank: 1646.000\n",
            "Column: 2285, Selected False, Rank: 1648.000\n",
            "Column: 2286, Selected False, Rank: 1650.000\n",
            "Column: 2287, Selected False, Rank: 1652.000\n",
            "Column: 2288, Selected False, Rank: 1654.000\n",
            "Column: 2289, Selected False, Rank: 1656.000\n",
            "Column: 2290, Selected False, Rank: 1658.000\n",
            "Column: 2291, Selected False, Rank: 1660.000\n",
            "Column: 2292, Selected False, Rank: 1662.000\n",
            "Column: 2293, Selected False, Rank: 1664.000\n",
            "Column: 2294, Selected False, Rank: 1666.000\n",
            "Column: 2295, Selected False, Rank: 1668.000\n",
            "Column: 2296, Selected False, Rank: 1670.000\n",
            "Column: 2297, Selected False, Rank: 1672.000\n",
            "Column: 2298, Selected False, Rank: 1674.000\n",
            "Column: 2299, Selected False, Rank: 1676.000\n",
            "Column: 2300, Selected False, Rank: 1678.000\n",
            "Column: 2301, Selected False, Rank: 1680.000\n",
            "Column: 2302, Selected False, Rank: 1684.000\n",
            "Column: 2303, Selected False, Rank: 1686.000\n",
            "Column: 2304, Selected False, Rank: 1688.000\n",
            "Column: 2305, Selected False, Rank: 1690.000\n",
            "Column: 2306, Selected False, Rank: 1694.000\n",
            "Column: 2307, Selected False, Rank: 1696.000\n",
            "Column: 2308, Selected False, Rank: 1698.000\n",
            "Column: 2309, Selected False, Rank: 1700.000\n",
            "Column: 2310, Selected False, Rank: 1702.000\n",
            "Column: 2311, Selected False, Rank: 1704.000\n",
            "Column: 2312, Selected False, Rank: 1706.000\n",
            "Column: 2313, Selected False, Rank: 1708.000\n",
            "Column: 2314, Selected False, Rank: 1710.000\n",
            "Column: 2315, Selected False, Rank: 1712.000\n",
            "Column: 2316, Selected False, Rank: 1714.000\n",
            "Column: 2317, Selected False, Rank: 1716.000\n",
            "Column: 2318, Selected False, Rank: 1718.000\n",
            "Column: 2319, Selected False, Rank: 1720.000\n",
            "Column: 2320, Selected False, Rank: 1722.000\n",
            "Column: 2321, Selected False, Rank: 72.000\n",
            "Column: 2322, Selected False, Rank: 22.000\n",
            "Column: 2323, Selected False, Rank: 1724.000\n",
            "Column: 2324, Selected False, Rank: 1726.000\n",
            "Column: 2325, Selected False, Rank: 1728.000\n",
            "Column: 2326, Selected False, Rank: 1730.000\n",
            "Column: 2327, Selected False, Rank: 1732.000\n",
            "Column: 2328, Selected False, Rank: 1734.000\n",
            "Column: 2329, Selected False, Rank: 1736.000\n",
            "Column: 2330, Selected False, Rank: 1738.000\n",
            "Column: 2331, Selected False, Rank: 1740.000\n",
            "Column: 2332, Selected False, Rank: 1742.000\n",
            "Column: 2333, Selected False, Rank: 1744.000\n",
            "Column: 2334, Selected False, Rank: 1746.000\n",
            "Column: 2335, Selected False, Rank: 1748.000\n",
            "Column: 2336, Selected False, Rank: 1750.000\n",
            "Column: 2337, Selected False, Rank: 1754.000\n",
            "Column: 2338, Selected False, Rank: 1756.000\n",
            "Column: 2339, Selected False, Rank: 1758.000\n",
            "Column: 2340, Selected False, Rank: 1760.000\n",
            "Column: 2341, Selected False, Rank: 1762.000\n",
            "Column: 2342, Selected False, Rank: 1764.000\n",
            "Column: 2343, Selected False, Rank: 1766.000\n",
            "Column: 2344, Selected False, Rank: 1768.000\n",
            "Column: 2345, Selected False, Rank: 1770.000\n",
            "Column: 2346, Selected False, Rank: 1772.000\n",
            "Column: 2347, Selected False, Rank: 1774.000\n",
            "Column: 2348, Selected False, Rank: 1776.000\n",
            "Column: 2349, Selected False, Rank: 1778.000\n",
            "Column: 2350, Selected False, Rank: 46.000\n",
            "Column: 2351, Selected False, Rank: 1780.000\n",
            "Column: 2352, Selected False, Rank: 1782.000\n",
            "Column: 2353, Selected False, Rank: 1784.000\n",
            "Column: 2354, Selected False, Rank: 1786.000\n",
            "Column: 2355, Selected False, Rank: 1788.000\n",
            "Column: 2356, Selected False, Rank: 1790.000\n",
            "Column: 2357, Selected False, Rank: 1792.000\n",
            "Column: 2358, Selected False, Rank: 1794.000\n",
            "Column: 2359, Selected False, Rank: 1796.000\n",
            "Column: 2360, Selected False, Rank: 1798.000\n",
            "Column: 2361, Selected False, Rank: 1800.000\n",
            "Column: 2362, Selected False, Rank: 1802.000\n",
            "Column: 2363, Selected False, Rank: 1804.000\n",
            "Column: 2364, Selected False, Rank: 1806.000\n",
            "Column: 2365, Selected False, Rank: 1808.000\n",
            "Column: 2366, Selected False, Rank: 1810.000\n",
            "Column: 2367, Selected False, Rank: 1812.000\n",
            "Column: 2368, Selected False, Rank: 1814.000\n",
            "Column: 2369, Selected False, Rank: 1816.000\n",
            "Column: 2370, Selected False, Rank: 1818.000\n",
            "Column: 2371, Selected False, Rank: 1820.000\n",
            "Column: 2372, Selected False, Rank: 1822.000\n",
            "Column: 2373, Selected False, Rank: 1824.000\n",
            "Column: 2374, Selected False, Rank: 1826.000\n",
            "Column: 2375, Selected False, Rank: 1828.000\n",
            "Column: 2376, Selected False, Rank: 1830.000\n",
            "Column: 2377, Selected False, Rank: 1832.000\n",
            "Column: 2378, Selected False, Rank: 1834.000\n",
            "Column: 2379, Selected False, Rank: 1836.000\n",
            "Column: 2380, Selected False, Rank: 1838.000\n",
            "Column: 2381, Selected False, Rank: 1840.000\n",
            "Column: 2382, Selected False, Rank: 1842.000\n",
            "Column: 2383, Selected False, Rank: 1844.000\n",
            "Column: 2384, Selected False, Rank: 1846.000\n",
            "Column: 2385, Selected False, Rank: 1848.000\n",
            "Column: 2386, Selected False, Rank: 1850.000\n",
            "Column: 2387, Selected False, Rank: 1852.000\n",
            "Column: 2388, Selected False, Rank: 1854.000\n",
            "Column: 2389, Selected False, Rank: 1856.000\n",
            "Column: 2390, Selected False, Rank: 1858.000\n",
            "Column: 2391, Selected False, Rank: 1860.000\n",
            "Column: 2392, Selected False, Rank: 1862.000\n",
            "Column: 2393, Selected False, Rank: 1864.000\n",
            "Column: 2394, Selected False, Rank: 1866.000\n",
            "Column: 2395, Selected False, Rank: 1868.000\n",
            "Column: 2396, Selected False, Rank: 1870.000\n",
            "Column: 2397, Selected False, Rank: 1872.000\n",
            "Column: 2398, Selected False, Rank: 1874.000\n",
            "Column: 2399, Selected False, Rank: 1876.000\n",
            "Column: 2400, Selected False, Rank: 1878.000\n",
            "Column: 2401, Selected False, Rank: 1880.000\n",
            "Column: 2402, Selected False, Rank: 1882.000\n",
            "Column: 2403, Selected False, Rank: 1884.000\n",
            "Column: 2404, Selected False, Rank: 1886.000\n",
            "Column: 2405, Selected False, Rank: 1888.000\n",
            "Column: 2406, Selected False, Rank: 1890.000\n",
            "Column: 2407, Selected False, Rank: 1892.000\n",
            "Column: 2408, Selected False, Rank: 1894.000\n",
            "Column: 2409, Selected False, Rank: 1896.000\n",
            "Column: 2410, Selected False, Rank: 1898.000\n",
            "Column: 2411, Selected False, Rank: 1900.000\n",
            "Column: 2412, Selected False, Rank: 1902.000\n",
            "Column: 2413, Selected False, Rank: 1906.000\n",
            "Column: 2414, Selected False, Rank: 1908.000\n",
            "Column: 2415, Selected False, Rank: 1910.000\n",
            "Column: 2416, Selected False, Rank: 1912.000\n",
            "Column: 2417, Selected False, Rank: 1914.000\n",
            "Column: 2418, Selected False, Rank: 1916.000\n",
            "Column: 2419, Selected False, Rank: 1918.000\n",
            "Column: 2420, Selected False, Rank: 1920.000\n",
            "Column: 2421, Selected False, Rank: 1922.000\n",
            "Column: 2422, Selected False, Rank: 82.000\n",
            "Column: 2423, Selected False, Rank: 1924.000\n",
            "Column: 2424, Selected False, Rank: 1926.000\n",
            "Column: 2425, Selected False, Rank: 1928.000\n",
            "Column: 2426, Selected False, Rank: 1930.000\n",
            "Column: 2427, Selected False, Rank: 1932.000\n",
            "Column: 2428, Selected False, Rank: 1934.000\n",
            "Column: 2429, Selected False, Rank: 1936.000\n",
            "Column: 2430, Selected False, Rank: 1938.000\n",
            "Column: 2431, Selected False, Rank: 1940.000\n",
            "Column: 2432, Selected False, Rank: 1942.000\n",
            "Column: 2433, Selected False, Rank: 1944.000\n",
            "Column: 2434, Selected False, Rank: 1946.000\n",
            "Column: 2435, Selected False, Rank: 1950.000\n",
            "Column: 2436, Selected False, Rank: 1954.000\n",
            "Column: 2437, Selected False, Rank: 1956.000\n",
            "Column: 2438, Selected False, Rank: 1958.000\n",
            "Column: 2439, Selected False, Rank: 1960.000\n",
            "Column: 2440, Selected False, Rank: 1962.000\n",
            "Column: 2441, Selected False, Rank: 1964.000\n",
            "Column: 2442, Selected False, Rank: 1966.000\n",
            "Column: 2443, Selected False, Rank: 1968.000\n",
            "Column: 2444, Selected True, Rank: 1.000\n",
            "Column: 2445, Selected False, Rank: 1970.000\n",
            "Column: 2446, Selected False, Rank: 1972.000\n",
            "Column: 2447, Selected False, Rank: 1974.000\n",
            "Column: 2448, Selected False, Rank: 1976.000\n",
            "Column: 2449, Selected False, Rank: 34.000\n",
            "Column: 2450, Selected False, Rank: 1978.000\n",
            "Column: 2451, Selected False, Rank: 1980.000\n",
            "Column: 2452, Selected False, Rank: 1982.000\n",
            "Column: 2453, Selected False, Rank: 1984.000\n",
            "Column: 2454, Selected False, Rank: 1986.000\n",
            "Column: 2455, Selected False, Rank: 1988.000\n",
            "Column: 2456, Selected False, Rank: 1990.000\n",
            "Column: 2457, Selected False, Rank: 1992.000\n",
            "Column: 2458, Selected False, Rank: 1994.000\n",
            "Column: 2459, Selected False, Rank: 1996.000\n",
            "Column: 2460, Selected False, Rank: 1998.000\n",
            "Column: 2461, Selected False, Rank: 2000.000\n",
            "Column: 2462, Selected False, Rank: 2002.000\n",
            "Column: 2463, Selected False, Rank: 2004.000\n",
            "Column: 2464, Selected False, Rank: 2006.000\n",
            "Column: 2465, Selected False, Rank: 2008.000\n",
            "Column: 2466, Selected False, Rank: 2010.000\n",
            "Column: 2467, Selected False, Rank: 2012.000\n",
            "Column: 2468, Selected False, Rank: 2014.000\n",
            "Column: 2469, Selected False, Rank: 2016.000\n",
            "Column: 2470, Selected False, Rank: 2018.000\n",
            "Column: 2471, Selected False, Rank: 45.000\n",
            "Column: 2472, Selected False, Rank: 2020.000\n",
            "Column: 2473, Selected False, Rank: 2022.000\n",
            "Column: 2474, Selected False, Rank: 2024.000\n",
            "Column: 2475, Selected False, Rank: 2026.000\n",
            "Column: 2476, Selected False, Rank: 2028.000\n",
            "Column: 2477, Selected False, Rank: 2030.000\n",
            "Column: 2478, Selected False, Rank: 2032.000\n",
            "Column: 2479, Selected False, Rank: 2034.000\n",
            "Column: 2480, Selected False, Rank: 2036.000\n",
            "Column: 2481, Selected False, Rank: 2038.000\n",
            "Column: 2482, Selected False, Rank: 2040.000\n",
            "Column: 2483, Selected False, Rank: 2042.000\n",
            "Column: 2484, Selected False, Rank: 2044.000\n",
            "Column: 2485, Selected False, Rank: 2046.000\n",
            "Column: 2486, Selected False, Rank: 2048.000\n",
            "Column: 2487, Selected False, Rank: 2050.000\n",
            "Column: 2488, Selected False, Rank: 2052.000\n",
            "Column: 2489, Selected False, Rank: 2054.000\n",
            "Column: 2490, Selected False, Rank: 2056.000\n",
            "Column: 2491, Selected False, Rank: 2058.000\n",
            "Column: 2492, Selected False, Rank: 2060.000\n",
            "Column: 2493, Selected False, Rank: 2062.000\n",
            "Column: 2494, Selected False, Rank: 2064.000\n",
            "Column: 2495, Selected False, Rank: 2066.000\n",
            "Column: 2496, Selected False, Rank: 2068.000\n",
            "Column: 2497, Selected False, Rank: 2070.000\n",
            "Column: 2498, Selected False, Rank: 70.000\n",
            "Column: 2499, Selected False, Rank: 2072.000\n",
            "Column: 2500, Selected False, Rank: 2074.000\n",
            "Column: 2501, Selected False, Rank: 101.000\n",
            "Column: 2502, Selected False, Rank: 2076.000\n",
            "Column: 2503, Selected False, Rank: 2078.000\n",
            "Column: 2504, Selected False, Rank: 2080.000\n",
            "Column: 2505, Selected False, Rank: 2082.000\n",
            "Column: 2506, Selected False, Rank: 2084.000\n",
            "Column: 2507, Selected False, Rank: 2086.000\n",
            "Column: 2508, Selected False, Rank: 2088.000\n",
            "Column: 2509, Selected False, Rank: 2090.000\n",
            "Column: 2510, Selected False, Rank: 2092.000\n",
            "Column: 2511, Selected False, Rank: 2094.000\n",
            "Column: 2512, Selected False, Rank: 2096.000\n",
            "Column: 2513, Selected False, Rank: 2098.000\n",
            "Column: 2514, Selected False, Rank: 2100.000\n",
            "Column: 2515, Selected False, Rank: 2102.000\n",
            "Column: 2516, Selected False, Rank: 2104.000\n",
            "Column: 2517, Selected False, Rank: 2106.000\n",
            "Column: 2518, Selected False, Rank: 2108.000\n",
            "Column: 2519, Selected False, Rank: 2110.000\n",
            "Column: 2520, Selected False, Rank: 2112.000\n",
            "Column: 2521, Selected False, Rank: 2114.000\n",
            "Column: 2522, Selected False, Rank: 2116.000\n",
            "Column: 2523, Selected False, Rank: 2118.000\n",
            "Column: 2524, Selected False, Rank: 2120.000\n",
            "Column: 2525, Selected False, Rank: 2122.000\n",
            "Column: 2526, Selected False, Rank: 2126.000\n",
            "Column: 2527, Selected False, Rank: 2128.000\n",
            "Column: 2528, Selected False, Rank: 2130.000\n",
            "Column: 2529, Selected False, Rank: 2132.000\n",
            "Column: 2530, Selected False, Rank: 2134.000\n",
            "Column: 2531, Selected False, Rank: 2136.000\n",
            "Column: 2532, Selected False, Rank: 2138.000\n",
            "Column: 2533, Selected False, Rank: 2140.000\n",
            "Column: 2534, Selected False, Rank: 2142.000\n",
            "Column: 2535, Selected False, Rank: 2144.000\n",
            "Column: 2536, Selected False, Rank: 2146.000\n",
            "Column: 2537, Selected False, Rank: 2148.000\n",
            "Column: 2538, Selected False, Rank: 2150.000\n",
            "Column: 2539, Selected False, Rank: 2152.000\n",
            "Column: 2540, Selected False, Rank: 2154.000\n",
            "Column: 2541, Selected False, Rank: 2156.000\n",
            "Column: 2542, Selected False, Rank: 2158.000\n",
            "Column: 2543, Selected False, Rank: 2160.000\n",
            "Column: 2544, Selected False, Rank: 2162.000\n",
            "Column: 2545, Selected False, Rank: 2164.000\n",
            "Column: 2546, Selected False, Rank: 2166.000\n",
            "Column: 2547, Selected False, Rank: 2168.000\n",
            "Column: 2548, Selected False, Rank: 2170.000\n",
            "Column: 2549, Selected False, Rank: 2172.000\n",
            "Column: 2550, Selected False, Rank: 2174.000\n",
            "Column: 2551, Selected False, Rank: 2176.000\n",
            "Column: 2552, Selected False, Rank: 2178.000\n",
            "Column: 2553, Selected False, Rank: 2180.000\n",
            "Column: 2554, Selected False, Rank: 2182.000\n",
            "Column: 2555, Selected False, Rank: 12.000\n",
            "Column: 2556, Selected False, Rank: 2184.000\n",
            "Column: 2557, Selected False, Rank: 2186.000\n",
            "Column: 2558, Selected False, Rank: 2188.000\n",
            "Column: 2559, Selected False, Rank: 2190.000\n",
            "Column: 2560, Selected False, Rank: 2192.000\n",
            "Column: 2561, Selected False, Rank: 2194.000\n",
            "Column: 2562, Selected False, Rank: 2196.000\n",
            "Column: 2563, Selected False, Rank: 2198.000\n",
            "Column: 2564, Selected False, Rank: 2200.000\n",
            "Column: 2565, Selected False, Rank: 2202.000\n",
            "Column: 2566, Selected False, Rank: 100.000\n",
            "Column: 2567, Selected False, Rank: 2204.000\n",
            "Column: 2568, Selected False, Rank: 2206.000\n",
            "Column: 2569, Selected False, Rank: 2208.000\n",
            "Column: 2570, Selected False, Rank: 2210.000\n",
            "Column: 2571, Selected False, Rank: 2212.000\n",
            "Column: 2572, Selected False, Rank: 2214.000\n",
            "Column: 2573, Selected False, Rank: 2216.000\n",
            "Column: 2574, Selected False, Rank: 2218.000\n",
            "Column: 2575, Selected False, Rank: 2220.000\n",
            "Column: 2576, Selected False, Rank: 2222.000\n",
            "Column: 2577, Selected False, Rank: 2224.000\n",
            "Column: 2578, Selected False, Rank: 2226.000\n",
            "Column: 2579, Selected False, Rank: 102.000\n",
            "Column: 2580, Selected False, Rank: 64.000\n",
            "Column: 2581, Selected False, Rank: 2228.000\n",
            "Column: 2582, Selected False, Rank: 2230.000\n",
            "Column: 2583, Selected False, Rank: 2232.000\n",
            "Column: 2584, Selected False, Rank: 2234.000\n",
            "Column: 2585, Selected False, Rank: 2236.000\n",
            "Column: 2586, Selected False, Rank: 2238.000\n",
            "Column: 2587, Selected False, Rank: 2240.000\n",
            "Column: 2588, Selected False, Rank: 52.000\n",
            "Column: 2589, Selected False, Rank: 2242.000\n",
            "Column: 2590, Selected False, Rank: 2244.000\n",
            "Column: 2591, Selected False, Rank: 2246.000\n",
            "Column: 2592, Selected False, Rank: 2248.000\n",
            "Column: 2593, Selected False, Rank: 2250.000\n",
            "Column: 2594, Selected False, Rank: 2252.000\n",
            "Column: 2595, Selected False, Rank: 2254.000\n",
            "Column: 2596, Selected False, Rank: 2256.000\n",
            "Column: 2597, Selected False, Rank: 9.000\n",
            "Column: 2598, Selected False, Rank: 110.000\n",
            "Column: 2599, Selected False, Rank: 2258.000\n",
            "Column: 2600, Selected False, Rank: 2260.000\n",
            "Column: 2601, Selected False, Rank: 2262.000\n",
            "Column: 2602, Selected False, Rank: 2264.000\n",
            "Column: 2603, Selected False, Rank: 2266.000\n",
            "Column: 2604, Selected False, Rank: 2268.000\n",
            "Column: 2605, Selected False, Rank: 2270.000\n",
            "Column: 2606, Selected False, Rank: 2272.000\n",
            "Column: 2607, Selected False, Rank: 2274.000\n",
            "Column: 2608, Selected False, Rank: 2276.000\n",
            "Column: 2609, Selected False, Rank: 2278.000\n",
            "Column: 2610, Selected False, Rank: 2280.000\n",
            "Column: 2611, Selected False, Rank: 2282.000\n",
            "Column: 2612, Selected False, Rank: 2284.000\n",
            "Column: 2613, Selected False, Rank: 2286.000\n",
            "Column: 2614, Selected False, Rank: 2288.000\n",
            "Column: 2615, Selected False, Rank: 2290.000\n",
            "Column: 2616, Selected False, Rank: 2292.000\n",
            "Column: 2617, Selected False, Rank: 2294.000\n",
            "Column: 2618, Selected False, Rank: 2296.000\n",
            "Column: 2619, Selected False, Rank: 2298.000\n",
            "Column: 2620, Selected False, Rank: 2300.000\n",
            "Column: 2621, Selected False, Rank: 2302.000\n",
            "Column: 2622, Selected False, Rank: 2304.000\n",
            "Column: 2623, Selected False, Rank: 2306.000\n",
            "Column: 2624, Selected False, Rank: 2308.000\n",
            "Column: 2625, Selected False, Rank: 2310.000\n",
            "Column: 2626, Selected False, Rank: 2312.000\n",
            "Column: 2627, Selected False, Rank: 2314.000\n",
            "Column: 2628, Selected False, Rank: 2316.000\n",
            "Column: 2629, Selected False, Rank: 2318.000\n",
            "Column: 2630, Selected False, Rank: 2320.000\n",
            "Column: 2631, Selected False, Rank: 2322.000\n",
            "Column: 2632, Selected False, Rank: 88.000\n",
            "Column: 2633, Selected False, Rank: 2324.000\n",
            "Column: 2634, Selected False, Rank: 2328.000\n",
            "Column: 2635, Selected False, Rank: 2330.000\n",
            "Column: 2636, Selected False, Rank: 2332.000\n",
            "Column: 2637, Selected False, Rank: 2334.000\n",
            "Column: 2638, Selected False, Rank: 2336.000\n",
            "Column: 2639, Selected False, Rank: 2338.000\n",
            "Column: 2640, Selected False, Rank: 2340.000\n",
            "Column: 2641, Selected False, Rank: 2342.000\n",
            "Column: 2642, Selected False, Rank: 2344.000\n",
            "Column: 2643, Selected False, Rank: 2346.000\n",
            "Column: 2644, Selected False, Rank: 2348.000\n",
            "Column: 2645, Selected False, Rank: 2350.000\n",
            "Column: 2646, Selected False, Rank: 2352.000\n",
            "Column: 2647, Selected False, Rank: 47.000\n",
            "Column: 2648, Selected False, Rank: 2354.000\n",
            "Column: 2649, Selected False, Rank: 2356.000\n",
            "Column: 2650, Selected False, Rank: 2358.000\n",
            "Column: 2651, Selected False, Rank: 2360.000\n",
            "Column: 2652, Selected False, Rank: 2362.000\n",
            "Column: 2653, Selected False, Rank: 120.000\n",
            "Column: 2654, Selected False, Rank: 2364.000\n",
            "Column: 2655, Selected False, Rank: 2366.000\n",
            "Column: 2656, Selected False, Rank: 2368.000\n",
            "Column: 2657, Selected False, Rank: 2370.000\n",
            "Column: 2658, Selected False, Rank: 17.000\n",
            "Column: 2659, Selected False, Rank: 2372.000\n",
            "Column: 2660, Selected False, Rank: 2374.000\n",
            "Column: 2661, Selected False, Rank: 49.000\n",
            "Column: 2662, Selected False, Rank: 2376.000\n",
            "Column: 2663, Selected False, Rank: 2378.000\n",
            "Column: 2664, Selected False, Rank: 2380.000\n",
            "Column: 2665, Selected False, Rank: 2382.000\n",
            "Column: 2666, Selected False, Rank: 2384.000\n",
            "Column: 2667, Selected False, Rank: 2386.000\n",
            "Column: 2668, Selected False, Rank: 2388.000\n",
            "Column: 2669, Selected False, Rank: 2390.000\n",
            "Column: 2670, Selected False, Rank: 2392.000\n",
            "Column: 2671, Selected False, Rank: 2394.000\n",
            "Column: 2672, Selected False, Rank: 2396.000\n",
            "Column: 2673, Selected False, Rank: 2327.000\n",
            "Column: 2674, Selected False, Rank: 2125.000\n",
            "Column: 2675, Selected False, Rank: 1953.000\n",
            "Column: 2676, Selected False, Rank: 1949.000\n",
            "Column: 2677, Selected False, Rank: 1905.000\n",
            "Column: 2678, Selected False, Rank: 1753.000\n",
            "Column: 2679, Selected False, Rank: 1693.000\n",
            "Column: 2680, Selected False, Rank: 1683.000\n",
            "Column: 2681, Selected False, Rank: 1559.000\n",
            "Column: 2682, Selected False, Rank: 1491.000\n",
            "Column: 2683, Selected False, Rank: 2423.000\n",
            "Column: 2684, Selected False, Rank: 2425.000\n",
            "Column: 2685, Selected False, Rank: 2427.000\n",
            "Column: 2686, Selected False, Rank: 2428.000\n",
            "Column: 2687, Selected False, Rank: 2429.000\n",
            "Column: 2688, Selected False, Rank: 123.000\n",
            "Column: 2689, Selected False, Rank: 2539.000\n",
            "Column: 2690, Selected False, Rank: 2541.000\n",
            "Column: 2691, Selected False, Rank: 2543.000\n",
            "Column: 2692, Selected False, Rank: 2545.000\n",
            "Column: 2693, Selected False, Rank: 2547.000\n",
            "Column: 2694, Selected False, Rank: 2549.000\n",
            "Column: 2695, Selected False, Rank: 2551.000\n",
            "Column: 2696, Selected False, Rank: 2553.000\n",
            "Column: 2697, Selected False, Rank: 2555.000\n",
            "Column: 2698, Selected False, Rank: 2557.000\n",
            "Column: 2699, Selected False, Rank: 2559.000\n",
            "Column: 2700, Selected False, Rank: 2561.000\n",
            "Column: 2701, Selected False, Rank: 2565.000\n",
            "Column: 2702, Selected False, Rank: 1443.000\n",
            "Column: 2703, Selected False, Rank: 2567.000\n",
            "Column: 2704, Selected False, Rank: 29.000\n",
            "Column: 2705, Selected False, Rank: 2571.000\n",
            "Column: 2706, Selected False, Rank: 2569.000\n",
            "Column: 2707, Selected False, Rank: 1279.000\n",
            "Column: 2708, Selected False, Rank: 1271.000\n",
            "Column: 2709, Selected False, Rank: 1237.000\n",
            "Column: 2710, Selected False, Rank: 1233.000\n",
            "Column: 2711, Selected False, Rank: 1139.000\n",
            "Column: 2712, Selected False, Rank: 2633.000\n",
            "Column: 2713, Selected False, Rank: 60.000\n",
            "Column: 2714, Selected False, Rank: 2730.000\n",
            "Column: 2715, Selected False, Rank: 2757.000\n",
            "Column: 2716, Selected False, Rank: 1009.000\n",
            "Column: 2717, Selected False, Rank: 979.000\n",
            "Column: 2718, Selected False, Rank: 923.000\n",
            "Column: 2719, Selected False, Rank: 899.000\n",
            "Column: 2720, Selected False, Rank: 855.000\n",
            "Column: 2721, Selected False, Rank: 857.000\n",
            "Column: 2722, Selected False, Rank: 859.000\n",
            "Column: 2723, Selected False, Rank: 861.000\n",
            "Column: 2724, Selected False, Rank: 863.000\n",
            "Column: 2725, Selected False, Rank: 370.000\n",
            "Column: 2726, Selected False, Rank: 887.000\n",
            "Column: 2727, Selected False, Rank: 889.000\n",
            "Column: 2728, Selected False, Rank: 2397.000\n",
            "Column: 2729, Selected False, Rank: 2399.000\n",
            "Column: 2730, Selected False, Rank: 2401.000\n",
            "Column: 2731, Selected False, Rank: 2403.000\n",
            "Column: 2732, Selected False, Rank: 2405.000\n",
            "Column: 2733, Selected False, Rank: 2407.000\n",
            "Column: 2734, Selected False, Rank: 2409.000\n",
            "Column: 2735, Selected False, Rank: 2411.000\n",
            "Column: 2736, Selected False, Rank: 2413.000\n",
            "Column: 2737, Selected False, Rank: 2415.000\n",
            "Column: 2738, Selected False, Rank: 2417.000\n",
            "Column: 2739, Selected False, Rank: 2419.000\n",
            "Column: 2740, Selected False, Rank: 2421.000\n",
            "Column: 2741, Selected False, Rank: 2420.000\n",
            "Column: 2742, Selected False, Rank: 89.000\n",
            "Column: 2743, Selected False, Rank: 2573.000\n",
            "Column: 2744, Selected False, Rank: 2575.000\n",
            "Column: 2745, Selected False, Rank: 2577.000\n",
            "Column: 2746, Selected False, Rank: 2579.000\n",
            "Column: 2747, Selected False, Rank: 2621.000\n",
            "Column: 2748, Selected False, Rank: 2622.000\n",
            "Column: 2749, Selected False, Rank: 2634.000\n",
            "Column: 2750, Selected False, Rank: 2566.000\n",
            "Column: 2751, Selected False, Rank: 2430.000\n",
            "Column: 2752, Selected False, Rank: 875.000\n",
            "Column: 2753, Selected False, Rank: 873.000\n",
            "Column: 2754, Selected False, Rank: 871.000\n",
            "Column: 2755, Selected False, Rank: 343.000\n",
            "Column: 2756, Selected False, Rank: 341.000\n",
            "Column: 2757, Selected False, Rank: 337.000\n",
            "Column: 2758, Selected False, Rank: 309.000\n",
            "Column: 2759, Selected False, Rank: 107.000\n",
            "Column: 2760, Selected False, Rank: 891.000\n",
            "Column: 2761, Selected False, Rank: 881.000\n",
            "Column: 2762, Selected False, Rank: 407.000\n",
            "Column: 2763, Selected False, Rank: 358.000\n",
            "Column: 2764, Selected False, Rank: 268.000\n",
            "Column: 2765, Selected False, Rank: 264.000\n",
            "Column: 2766, Selected False, Rank: 77.000\n",
            "Column: 2767, Selected False, Rank: 322.000\n",
            "Column: 2768, Selected False, Rank: 323.000\n",
            "Column: 2769, Selected False, Rank: 263.000\n",
            "Column: 2770, Selected False, Rank: 261.000\n",
            "Column: 2771, Selected False, Rank: 259.000\n",
            "Column: 2772, Selected False, Rank: 183.000\n",
            "Column: 2773, Selected False, Rank: 185.000\n",
            "Column: 2774, Selected False, Rank: 189.000\n",
            "Column: 2775, Selected False, Rank: 191.000\n",
            "Column: 2776, Selected False, Rank: 177.000\n",
            "Column: 2777, Selected False, Rank: 144.000\n",
            "Column: 2778, Selected False, Rank: 141.000\n",
            "Column: 2779, Selected False, Rank: 142.000\n",
            "Column: 2780, Selected False, Rank: 181.000\n",
            "Column: 2781, Selected False, Rank: 241.000\n",
            "Column: 2782, Selected False, Rank: 38.000\n",
            "Column: 2783, Selected False, Rank: 153.000\n",
            "Column: 2784, Selected False, Rank: 154.000\n",
            "Column: 2785, Selected False, Rank: 156.000\n",
            "Column: 2786, Selected False, Rank: 157.000\n",
            "Column: 2787, Selected False, Rank: 158.000\n",
            "Column: 2788, Selected False, Rank: 161.000\n",
            "Column: 2789, Selected False, Rank: 90.000\n",
            "Column: 2790, Selected False, Rank: 2759.000\n",
            "Column: 2791, Selected False, Rank: 2761.000\n",
            "Column: 2792, Selected False, Rank: 2763.000\n",
            "Column: 2793, Selected False, Rank: 2765.000\n",
            "Column: 2794, Selected False, Rank: 2767.000\n",
            "Column: 2795, Selected False, Rank: 2769.000\n",
            "Column: 2796, Selected False, Rank: 2771.000\n",
            "Column: 2797, Selected False, Rank: 2773.000\n",
            "Column: 2798, Selected False, Rank: 2775.000\n",
            "Column: 2799, Selected False, Rank: 2776.000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NzXjG3gZCLNP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 92
        },
        "outputId": "b261f923-6af6-4a06-8449-52ad42af2233"
      },
      "source": [
        "print(X.columns[rfecv.get_support()]) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Index(['specific_bean_origin_or_bar_name_Malo Island, batch Ma20/19',\n",
            "       'specific_bean_origin_or_bar_name_Venezuela, Trinidad',\n",
            "       'second_taste_sweet'],\n",
            "      dtype='object')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lJr1kQuhCOA0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 318
        },
        "outputId": "61a064d1-2fb6-484c-ab95-f788ac99cc77"
      },
      "source": [
        "print(\"Optimal number of features : %d\" % rfecv.n_features_)\n",
        "\n",
        "# Plot number of features VS. cross-validation scores\n",
        "plt.figure()\n",
        "plt.xlabel(\"Number of features selected\")\n",
        "plt.ylabel(\"Cross validation score (nb of correct classifications)\")\n",
        "plt.plot(range(1, len(rfecv.grid_scores_) + 1), rfecv.grid_scores_)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Optimal number of features : 3\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tPWR3nBnCcyc",
        "colab_type": "text"
      },
      "source": [
        "> > # With Logistic and RFE"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "alUlmKjPCe6l",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "outputId": "20861f20-cdc1-4b17-f099-ba9f4a9ff498"
      },
      "source": [
        "#Logistic Regression:\n",
        "# Feature Extraction with RFE\n",
        "from sklearn.feature_selection import RFE\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "model = LogisticRegression(solver='lbfgs', max_iter=5000)\n",
        "rfe = RFE(model, 3)\n",
        "fit = rfe.fit(X, y)\n",
        "print(\"Num Features: %d\" % fit.n_features_)\n",
        "print(\"Selected Features: %s\" % fit.support_)\n",
        "print(\"Feature Ranking: %s\" % fit.ranking_)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Num Features: 3\n",
            "Selected Features: [False False False ... False False False]\n",
            "Feature Ranking: [  24    6   23 ... 1033  554  623]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uCkVDL2bCh0C",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "d679b8f7-5897-4a04-eb50-d6c78f4df491"
      },
      "source": [
        "for i in range(X.shape[1]):\n",
        "    print ('Column: %d, Selected %s, Rank: %.3f' % (i, rfe.support_[i], rfe.ranking_[i]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Column: 0, Selected False, Rank: 24.000\n",
            "Column: 1, Selected False, Rank: 6.000\n",
            "Column: 2, Selected False, Rank: 23.000\n",
            "Column: 3, Selected False, Rank: 1640.000\n",
            "Column: 4, Selected False, Rank: 80.000\n",
            "Column: 5, Selected False, Rank: 161.000\n",
            "Column: 6, Selected False, Rank: 112.000\n",
            "Column: 7, Selected False, Rank: 2061.000\n",
            "Column: 8, Selected False, Rank: 128.000\n",
            "Column: 9, Selected False, Rank: 38.000\n",
            "Column: 10, Selected False, Rank: 833.000\n",
            "Column: 11, Selected False, Rank: 83.000\n",
            "Column: 12, Selected False, Rank: 288.000\n",
            "Column: 13, Selected False, Rank: 515.000\n",
            "Column: 14, Selected False, Rank: 109.000\n",
            "Column: 15, Selected False, Rank: 240.000\n",
            "Column: 16, Selected False, Rank: 68.000\n",
            "Column: 17, Selected False, Rank: 635.000\n",
            "Column: 18, Selected False, Rank: 338.000\n",
            "Column: 19, Selected False, Rank: 1027.000\n",
            "Column: 20, Selected False, Rank: 34.000\n",
            "Column: 21, Selected False, Rank: 149.000\n",
            "Column: 22, Selected False, Rank: 2643.000\n",
            "Column: 23, Selected False, Rank: 668.000\n",
            "Column: 24, Selected False, Rank: 197.000\n",
            "Column: 25, Selected False, Rank: 752.000\n",
            "Column: 26, Selected False, Rank: 189.000\n",
            "Column: 27, Selected False, Rank: 731.000\n",
            "Column: 28, Selected False, Rank: 436.000\n",
            "Column: 29, Selected False, Rank: 709.000\n",
            "Column: 30, Selected False, Rank: 443.000\n",
            "Column: 31, Selected False, Rank: 51.000\n",
            "Column: 32, Selected False, Rank: 145.000\n",
            "Column: 33, Selected False, Rank: 348.000\n",
            "Column: 34, Selected False, Rank: 428.000\n",
            "Column: 35, Selected False, Rank: 341.000\n",
            "Column: 36, Selected False, Rank: 35.000\n",
            "Column: 37, Selected False, Rank: 301.000\n",
            "Column: 38, Selected False, Rank: 141.000\n",
            "Column: 39, Selected False, Rank: 115.000\n",
            "Column: 40, Selected False, Rank: 239.000\n",
            "Column: 41, Selected False, Rank: 862.000\n",
            "Column: 42, Selected False, Rank: 69.000\n",
            "Column: 43, Selected False, Rank: 387.000\n",
            "Column: 44, Selected False, Rank: 438.000\n",
            "Column: 45, Selected False, Rank: 895.000\n",
            "Column: 46, Selected False, Rank: 605.000\n",
            "Column: 47, Selected False, Rank: 1512.000\n",
            "Column: 48, Selected False, Rank: 764.000\n",
            "Column: 49, Selected False, Rank: 430.000\n",
            "Column: 50, Selected False, Rank: 304.000\n",
            "Column: 51, Selected False, Rank: 216.000\n",
            "Column: 52, Selected False, Rank: 598.000\n",
            "Column: 53, Selected False, Rank: 244.000\n",
            "Column: 54, Selected False, Rank: 150.000\n",
            "Column: 55, Selected False, Rank: 290.000\n",
            "Column: 56, Selected False, Rank: 2509.000\n",
            "Column: 57, Selected False, Rank: 1367.000\n",
            "Column: 58, Selected False, Rank: 361.000\n",
            "Column: 59, Selected False, Rank: 108.000\n",
            "Column: 60, Selected False, Rank: 220.000\n",
            "Column: 61, Selected False, Rank: 627.000\n",
            "Column: 62, Selected False, Rank: 29.000\n",
            "Column: 63, Selected False, Rank: 498.000\n",
            "Column: 64, Selected False, Rank: 43.000\n",
            "Column: 65, Selected False, Rank: 3.000\n",
            "Column: 66, Selected False, Rank: 93.000\n",
            "Column: 67, Selected False, Rank: 250.000\n",
            "Column: 68, Selected False, Rank: 1754.000\n",
            "Column: 69, Selected False, Rank: 44.000\n",
            "Column: 70, Selected False, Rank: 58.000\n",
            "Column: 71, Selected False, Rank: 47.000\n",
            "Column: 72, Selected False, Rank: 32.000\n",
            "Column: 73, Selected False, Rank: 41.000\n",
            "Column: 74, Selected False, Rank: 7.000\n",
            "Column: 75, Selected False, Rank: 27.000\n",
            "Column: 76, Selected False, Rank: 22.000\n",
            "Column: 77, Selected False, Rank: 26.000\n",
            "Column: 78, Selected False, Rank: 18.000\n",
            "Column: 79, Selected False, Rank: 19.000\n",
            "Column: 80, Selected False, Rank: 53.000\n",
            "Column: 81, Selected False, Rank: 28.000\n",
            "Column: 82, Selected False, Rank: 10.000\n",
            "Column: 83, Selected False, Rank: 118.000\n",
            "Column: 84, Selected False, Rank: 790.000\n",
            "Column: 85, Selected False, Rank: 70.000\n",
            "Column: 86, Selected False, Rank: 9.000\n",
            "Column: 87, Selected False, Rank: 56.000\n",
            "Column: 88, Selected False, Rank: 475.000\n",
            "Column: 89, Selected False, Rank: 54.000\n",
            "Column: 90, Selected False, Rank: 2561.000\n",
            "Column: 91, Selected False, Rank: 671.000\n",
            "Column: 92, Selected False, Rank: 77.000\n",
            "Column: 93, Selected False, Rank: 280.000\n",
            "Column: 94, Selected False, Rank: 81.000\n",
            "Column: 95, Selected False, Rank: 518.000\n",
            "Column: 96, Selected False, Rank: 17.000\n",
            "Column: 97, Selected False, Rank: 1670.000\n",
            "Column: 98, Selected False, Rank: 30.000\n",
            "Column: 99, Selected False, Rank: 424.000\n",
            "Column: 100, Selected False, Rank: 132.000\n",
            "Column: 101, Selected False, Rank: 2524.000\n",
            "Column: 102, Selected False, Rank: 111.000\n",
            "Column: 103, Selected False, Rank: 175.000\n",
            "Column: 104, Selected False, Rank: 85.000\n",
            "Column: 105, Selected False, Rank: 135.000\n",
            "Column: 106, Selected False, Rank: 163.000\n",
            "Column: 107, Selected False, Rank: 117.000\n",
            "Column: 108, Selected False, Rank: 187.000\n",
            "Column: 109, Selected False, Rank: 604.000\n",
            "Column: 110, Selected False, Rank: 165.000\n",
            "Column: 111, Selected False, Rank: 609.000\n",
            "Column: 112, Selected False, Rank: 31.000\n",
            "Column: 113, Selected False, Rank: 287.000\n",
            "Column: 114, Selected False, Rank: 37.000\n",
            "Column: 115, Selected False, Rank: 89.000\n",
            "Column: 116, Selected False, Rank: 46.000\n",
            "Column: 117, Selected False, Rank: 1160.000\n",
            "Column: 118, Selected False, Rank: 418.000\n",
            "Column: 119, Selected False, Rank: 90.000\n",
            "Column: 120, Selected False, Rank: 20.000\n",
            "Column: 121, Selected False, Rank: 114.000\n",
            "Column: 122, Selected False, Rank: 1707.000\n",
            "Column: 123, Selected False, Rank: 299.000\n",
            "Column: 124, Selected False, Rank: 1071.000\n",
            "Column: 125, Selected False, Rank: 231.000\n",
            "Column: 126, Selected False, Rank: 2608.000\n",
            "Column: 127, Selected False, Rank: 456.000\n",
            "Column: 128, Selected False, Rank: 404.000\n",
            "Column: 129, Selected False, Rank: 898.000\n",
            "Column: 130, Selected False, Rank: 209.000\n",
            "Column: 131, Selected False, Rank: 2511.000\n",
            "Column: 132, Selected False, Rank: 919.000\n",
            "Column: 133, Selected False, Rank: 751.000\n",
            "Column: 134, Selected False, Rank: 1370.000\n",
            "Column: 135, Selected False, Rank: 660.000\n",
            "Column: 136, Selected False, Rank: 66.000\n",
            "Column: 137, Selected False, Rank: 626.000\n",
            "Column: 138, Selected False, Rank: 1820.000\n",
            "Column: 139, Selected False, Rank: 1668.000\n",
            "Column: 140, Selected False, Rank: 79.000\n",
            "Column: 141, Selected False, Rank: 106.000\n",
            "Column: 142, Selected False, Rank: 205.000\n",
            "Column: 143, Selected False, Rank: 4.000\n",
            "Column: 144, Selected False, Rank: 25.000\n",
            "Column: 145, Selected False, Rank: 87.000\n",
            "Column: 146, Selected False, Rank: 1232.000\n",
            "Column: 147, Selected False, Rank: 2364.000\n",
            "Column: 148, Selected False, Rank: 946.000\n",
            "Column: 149, Selected False, Rank: 2008.000\n",
            "Column: 150, Selected False, Rank: 2715.000\n",
            "Column: 151, Selected False, Rank: 2539.000\n",
            "Column: 152, Selected False, Rank: 2663.000\n",
            "Column: 153, Selected False, Rank: 2508.000\n",
            "Column: 154, Selected False, Rank: 2307.000\n",
            "Column: 155, Selected False, Rank: 816.000\n",
            "Column: 156, Selected False, Rank: 334.000\n",
            "Column: 157, Selected False, Rank: 1595.000\n",
            "Column: 158, Selected False, Rank: 421.000\n",
            "Column: 159, Selected False, Rank: 938.000\n",
            "Column: 160, Selected False, Rank: 1237.000\n",
            "Column: 161, Selected False, Rank: 2753.000\n",
            "Column: 162, Selected False, Rank: 864.000\n",
            "Column: 163, Selected False, Rank: 1693.000\n",
            "Column: 164, Selected False, Rank: 2437.000\n",
            "Column: 165, Selected False, Rank: 2641.000\n",
            "Column: 166, Selected False, Rank: 1770.000\n",
            "Column: 167, Selected False, Rank: 2382.000\n",
            "Column: 168, Selected False, Rank: 1064.000\n",
            "Column: 169, Selected False, Rank: 708.000\n",
            "Column: 170, Selected False, Rank: 1054.000\n",
            "Column: 171, Selected False, Rank: 467.000\n",
            "Column: 172, Selected False, Rank: 2520.000\n",
            "Column: 173, Selected False, Rank: 1614.000\n",
            "Column: 174, Selected False, Rank: 2212.000\n",
            "Column: 175, Selected False, Rank: 2481.000\n",
            "Column: 176, Selected False, Rank: 1524.000\n",
            "Column: 177, Selected False, Rank: 1490.000\n",
            "Column: 178, Selected False, Rank: 2406.000\n",
            "Column: 179, Selected False, Rank: 2193.000\n",
            "Column: 180, Selected False, Rank: 1127.000\n",
            "Column: 181, Selected False, Rank: 1450.000\n",
            "Column: 182, Selected False, Rank: 314.000\n",
            "Column: 183, Selected False, Rank: 1848.000\n",
            "Column: 184, Selected False, Rank: 745.000\n",
            "Column: 185, Selected False, Rank: 2645.000\n",
            "Column: 186, Selected False, Rank: 1781.000\n",
            "Column: 187, Selected False, Rank: 1514.000\n",
            "Column: 188, Selected False, Rank: 1852.000\n",
            "Column: 189, Selected False, Rank: 1382.000\n",
            "Column: 190, Selected False, Rank: 1551.000\n",
            "Column: 191, Selected False, Rank: 1950.000\n",
            "Column: 192, Selected False, Rank: 1349.000\n",
            "Column: 193, Selected False, Rank: 1018.000\n",
            "Column: 194, Selected False, Rank: 1610.000\n",
            "Column: 195, Selected False, Rank: 1639.000\n",
            "Column: 196, Selected False, Rank: 1158.000\n",
            "Column: 197, Selected False, Rank: 1779.000\n",
            "Column: 198, Selected False, Rank: 531.000\n",
            "Column: 199, Selected False, Rank: 704.000\n",
            "Column: 200, Selected False, Rank: 1174.000\n",
            "Column: 201, Selected False, Rank: 2362.000\n",
            "Column: 202, Selected False, Rank: 2129.000\n",
            "Column: 203, Selected False, Rank: 2413.000\n",
            "Column: 204, Selected False, Rank: 986.000\n",
            "Column: 205, Selected False, Rank: 1574.000\n",
            "Column: 206, Selected False, Rank: 1470.000\n",
            "Column: 207, Selected False, Rank: 939.000\n",
            "Column: 208, Selected False, Rank: 1963.000\n",
            "Column: 209, Selected False, Rank: 2591.000\n",
            "Column: 210, Selected False, Rank: 210.000\n",
            "Column: 211, Selected False, Rank: 1846.000\n",
            "Column: 212, Selected False, Rank: 906.000\n",
            "Column: 213, Selected False, Rank: 1376.000\n",
            "Column: 214, Selected False, Rank: 2618.000\n",
            "Column: 215, Selected False, Rank: 756.000\n",
            "Column: 216, Selected False, Rank: 1407.000\n",
            "Column: 217, Selected False, Rank: 1915.000\n",
            "Column: 218, Selected False, Rank: 1119.000\n",
            "Column: 219, Selected False, Rank: 1240.000\n",
            "Column: 220, Selected False, Rank: 1038.000\n",
            "Column: 221, Selected False, Rank: 1812.000\n",
            "Column: 222, Selected False, Rank: 2333.000\n",
            "Column: 223, Selected False, Rank: 1949.000\n",
            "Column: 224, Selected False, Rank: 1260.000\n",
            "Column: 225, Selected False, Rank: 1441.000\n",
            "Column: 226, Selected False, Rank: 1887.000\n",
            "Column: 227, Selected False, Rank: 2674.000\n",
            "Column: 228, Selected False, Rank: 1340.000\n",
            "Column: 229, Selected False, Rank: 1802.000\n",
            "Column: 230, Selected False, Rank: 1170.000\n",
            "Column: 231, Selected False, Rank: 762.000\n",
            "Column: 232, Selected False, Rank: 1499.000\n",
            "Column: 233, Selected False, Rank: 2462.000\n",
            "Column: 234, Selected False, Rank: 317.000\n",
            "Column: 235, Selected False, Rank: 1999.000\n",
            "Column: 236, Selected False, Rank: 1172.000\n",
            "Column: 237, Selected False, Rank: 2071.000\n",
            "Column: 238, Selected False, Rank: 1979.000\n",
            "Column: 239, Selected False, Rank: 2064.000\n",
            "Column: 240, Selected False, Rank: 610.000\n",
            "Column: 241, Selected False, Rank: 958.000\n",
            "Column: 242, Selected False, Rank: 2542.000\n",
            "Column: 243, Selected False, Rank: 2547.000\n",
            "Column: 244, Selected False, Rank: 1845.000\n",
            "Column: 245, Selected False, Rank: 2162.000\n",
            "Column: 246, Selected False, Rank: 2375.000\n",
            "Column: 247, Selected False, Rank: 2401.000\n",
            "Column: 248, Selected False, Rank: 2557.000\n",
            "Column: 249, Selected False, Rank: 2135.000\n",
            "Column: 250, Selected False, Rank: 2288.000\n",
            "Column: 251, Selected False, Rank: 2421.000\n",
            "Column: 252, Selected False, Rank: 1083.000\n",
            "Column: 253, Selected False, Rank: 2277.000\n",
            "Column: 254, Selected False, Rank: 1889.000\n",
            "Column: 255, Selected False, Rank: 307.000\n",
            "Column: 256, Selected False, Rank: 2216.000\n",
            "Column: 257, Selected False, Rank: 2372.000\n",
            "Column: 258, Selected False, Rank: 2637.000\n",
            "Column: 259, Selected False, Rank: 971.000\n",
            "Column: 260, Selected False, Rank: 2744.000\n",
            "Column: 261, Selected False, Rank: 2677.000\n",
            "Column: 262, Selected False, Rank: 1598.000\n",
            "Column: 263, Selected False, Rank: 1936.000\n",
            "Column: 264, Selected False, Rank: 265.000\n",
            "Column: 265, Selected False, Rank: 1193.000\n",
            "Column: 266, Selected False, Rank: 591.000\n",
            "Column: 267, Selected False, Rank: 2227.000\n",
            "Column: 268, Selected False, Rank: 2631.000\n",
            "Column: 269, Selected False, Rank: 973.000\n",
            "Column: 270, Selected False, Rank: 539.000\n",
            "Column: 271, Selected False, Rank: 1140.000\n",
            "Column: 272, Selected False, Rank: 1722.000\n",
            "Column: 273, Selected False, Rank: 1784.000\n",
            "Column: 274, Selected False, Rank: 1531.000\n",
            "Column: 275, Selected False, Rank: 1468.000\n",
            "Column: 276, Selected False, Rank: 2218.000\n",
            "Column: 277, Selected False, Rank: 2013.000\n",
            "Column: 278, Selected False, Rank: 1513.000\n",
            "Column: 279, Selected False, Rank: 2537.000\n",
            "Column: 280, Selected False, Rank: 965.000\n",
            "Column: 281, Selected False, Rank: 755.000\n",
            "Column: 282, Selected False, Rank: 1017.000\n",
            "Column: 283, Selected False, Rank: 2205.000\n",
            "Column: 284, Selected False, Rank: 2457.000\n",
            "Column: 285, Selected False, Rank: 188.000\n",
            "Column: 286, Selected False, Rank: 2439.000\n",
            "Column: 287, Selected False, Rank: 2710.000\n",
            "Column: 288, Selected False, Rank: 1525.000\n",
            "Column: 289, Selected False, Rank: 874.000\n",
            "Column: 290, Selected False, Rank: 1523.000\n",
            "Column: 291, Selected False, Rank: 2424.000\n",
            "Column: 292, Selected False, Rank: 2393.000\n",
            "Column: 293, Selected False, Rank: 2516.000\n",
            "Column: 294, Selected False, Rank: 557.000\n",
            "Column: 295, Selected False, Rank: 847.000\n",
            "Column: 296, Selected False, Rank: 1709.000\n",
            "Column: 297, Selected False, Rank: 1906.000\n",
            "Column: 298, Selected False, Rank: 2656.000\n",
            "Column: 299, Selected False, Rank: 2440.000\n",
            "Column: 300, Selected False, Rank: 1320.000\n",
            "Column: 301, Selected False, Rank: 1361.000\n",
            "Column: 302, Selected False, Rank: 1796.000\n",
            "Column: 303, Selected False, Rank: 1718.000\n",
            "Column: 304, Selected False, Rank: 1326.000\n",
            "Column: 305, Selected False, Rank: 1191.000\n",
            "Column: 306, Selected False, Rank: 2559.000\n",
            "Column: 307, Selected False, Rank: 1619.000\n",
            "Column: 308, Selected False, Rank: 1566.000\n",
            "Column: 309, Selected False, Rank: 1398.000\n",
            "Column: 310, Selected False, Rank: 1917.000\n",
            "Column: 311, Selected False, Rank: 2050.000\n",
            "Column: 312, Selected False, Rank: 2472.000\n",
            "Column: 313, Selected False, Rank: 1993.000\n",
            "Column: 314, Selected False, Rank: 2554.000\n",
            "Column: 315, Selected False, Rank: 1223.000\n",
            "Column: 316, Selected False, Rank: 2765.000\n",
            "Column: 317, Selected False, Rank: 1393.000\n",
            "Column: 318, Selected False, Rank: 2409.000\n",
            "Column: 319, Selected False, Rank: 355.000\n",
            "Column: 320, Selected False, Rank: 1857.000\n",
            "Column: 321, Selected False, Rank: 1243.000\n",
            "Column: 322, Selected False, Rank: 2738.000\n",
            "Column: 323, Selected False, Rank: 566.000\n",
            "Column: 324, Selected False, Rank: 1867.000\n",
            "Column: 325, Selected False, Rank: 1863.000\n",
            "Column: 326, Selected False, Rank: 1258.000\n",
            "Column: 327, Selected False, Rank: 1031.000\n",
            "Column: 328, Selected False, Rank: 2349.000\n",
            "Column: 329, Selected False, Rank: 243.000\n",
            "Column: 330, Selected False, Rank: 601.000\n",
            "Column: 331, Selected False, Rank: 1234.000\n",
            "Column: 332, Selected False, Rank: 2574.000\n",
            "Column: 333, Selected False, Rank: 1476.000\n",
            "Column: 334, Selected False, Rank: 1055.000\n",
            "Column: 335, Selected False, Rank: 643.000\n",
            "Column: 336, Selected False, Rank: 1622.000\n",
            "Column: 337, Selected False, Rank: 1431.000\n",
            "Column: 338, Selected False, Rank: 1000.000\n",
            "Column: 339, Selected False, Rank: 269.000\n",
            "Column: 340, Selected False, Rank: 2224.000\n",
            "Column: 341, Selected False, Rank: 2028.000\n",
            "Column: 342, Selected False, Rank: 1952.000\n",
            "Column: 343, Selected False, Rank: 1446.000\n",
            "Column: 344, Selected False, Rank: 1505.000\n",
            "Column: 345, Selected False, Rank: 1341.000\n",
            "Column: 346, Selected False, Rank: 2010.000\n",
            "Column: 347, Selected False, Rank: 1853.000\n",
            "Column: 348, Selected False, Rank: 1402.000\n",
            "Column: 349, Selected False, Rank: 2262.000\n",
            "Column: 350, Selected False, Rank: 2022.000\n",
            "Column: 351, Selected False, Rank: 677.000\n",
            "Column: 352, Selected False, Rank: 2599.000\n",
            "Column: 353, Selected False, Rank: 1970.000\n",
            "Column: 354, Selected False, Rank: 2312.000\n",
            "Column: 355, Selected False, Rank: 838.000\n",
            "Column: 356, Selected False, Rank: 1910.000\n",
            "Column: 357, Selected False, Rank: 1730.000\n",
            "Column: 358, Selected False, Rank: 2795.000\n",
            "Column: 359, Selected False, Rank: 1509.000\n",
            "Column: 360, Selected False, Rank: 2741.000\n",
            "Column: 361, Selected False, Rank: 1982.000\n",
            "Column: 362, Selected False, Rank: 1413.000\n",
            "Column: 363, Selected False, Rank: 672.000\n",
            "Column: 364, Selected False, Rank: 1689.000\n",
            "Column: 365, Selected False, Rank: 2366.000\n",
            "Column: 366, Selected False, Rank: 2073.000\n",
            "Column: 367, Selected False, Rank: 2397.000\n",
            "Column: 368, Selected False, Rank: 2345.000\n",
            "Column: 369, Selected False, Rank: 1404.000\n",
            "Column: 370, Selected False, Rank: 1515.000\n",
            "Column: 371, Selected False, Rank: 724.000\n",
            "Column: 372, Selected False, Rank: 1254.000\n",
            "Column: 373, Selected False, Rank: 950.000\n",
            "Column: 374, Selected False, Rank: 808.000\n",
            "Column: 375, Selected False, Rank: 1732.000\n",
            "Column: 376, Selected False, Rank: 2580.000\n",
            "Column: 377, Selected False, Rank: 2080.000\n",
            "Column: 378, Selected False, Rank: 1720.000\n",
            "Column: 379, Selected False, Rank: 302.000\n",
            "Column: 380, Selected False, Rank: 1988.000\n",
            "Column: 381, Selected False, Rank: 536.000\n",
            "Column: 382, Selected False, Rank: 1357.000\n",
            "Column: 383, Selected False, Rank: 2453.000\n",
            "Column: 384, Selected False, Rank: 177.000\n",
            "Column: 385, Selected False, Rank: 1116.000\n",
            "Column: 386, Selected False, Rank: 1409.000\n",
            "Column: 387, Selected False, Rank: 1050.000\n",
            "Column: 388, Selected False, Rank: 1795.000\n",
            "Column: 389, Selected False, Rank: 2370.000\n",
            "Column: 390, Selected False, Rank: 2507.000\n",
            "Column: 391, Selected False, Rank: 1929.000\n",
            "Column: 392, Selected False, Rank: 969.000\n",
            "Column: 393, Selected False, Rank: 1968.000\n",
            "Column: 394, Selected False, Rank: 1216.000\n",
            "Column: 395, Selected False, Rank: 227.000\n",
            "Column: 396, Selected False, Rank: 1960.000\n",
            "Column: 397, Selected False, Rank: 1165.000\n",
            "Column: 398, Selected False, Rank: 998.000\n",
            "Column: 399, Selected False, Rank: 2171.000\n",
            "Column: 400, Selected False, Rank: 904.000\n",
            "Column: 401, Selected False, Rank: 1383.000\n",
            "Column: 402, Selected False, Rank: 1244.000\n",
            "Column: 403, Selected False, Rank: 2694.000\n",
            "Column: 404, Selected False, Rank: 2290.000\n",
            "Column: 405, Selected False, Rank: 2192.000\n",
            "Column: 406, Selected False, Rank: 1572.000\n",
            "Column: 407, Selected False, Rank: 2323.000\n",
            "Column: 408, Selected False, Rank: 1735.000\n",
            "Column: 409, Selected False, Rank: 1161.000\n",
            "Column: 410, Selected False, Rank: 1890.000\n",
            "Column: 411, Selected False, Rank: 1366.000\n",
            "Column: 412, Selected False, Rank: 1966.000\n",
            "Column: 413, Selected False, Rank: 957.000\n",
            "Column: 414, Selected False, Rank: 760.000\n",
            "Column: 415, Selected False, Rank: 1414.000\n",
            "Column: 416, Selected False, Rank: 964.000\n",
            "Column: 417, Selected False, Rank: 1248.000\n",
            "Column: 418, Selected False, Rank: 1159.000\n",
            "Column: 419, Selected False, Rank: 1564.000\n",
            "Column: 420, Selected False, Rank: 741.000\n",
            "Column: 421, Selected False, Rank: 1976.000\n",
            "Column: 422, Selected False, Rank: 1543.000\n",
            "Column: 423, Selected False, Rank: 2659.000\n",
            "Column: 424, Selected False, Rank: 458.000\n",
            "Column: 425, Selected False, Rank: 1021.000\n",
            "Column: 426, Selected False, Rank: 2475.000\n",
            "Column: 427, Selected False, Rank: 1577.000\n",
            "Column: 428, Selected False, Rank: 2169.000\n",
            "Column: 429, Selected False, Rank: 219.000\n",
            "Column: 430, Selected False, Rank: 2109.000\n",
            "Column: 431, Selected False, Rank: 1486.000\n",
            "Column: 432, Selected False, Rank: 2238.000\n",
            "Column: 433, Selected False, Rank: 1588.000\n",
            "Column: 434, Selected False, Rank: 1932.000\n",
            "Column: 435, Selected False, Rank: 2512.000\n",
            "Column: 436, Selected False, Rank: 1313.000\n",
            "Column: 437, Selected False, Rank: 728.000\n",
            "Column: 438, Selected False, Rank: 1281.000\n",
            "Column: 439, Selected False, Rank: 1125.000\n",
            "Column: 440, Selected False, Rank: 2130.000\n",
            "Column: 441, Selected False, Rank: 2788.000\n",
            "Column: 442, Selected False, Rank: 1389.000\n",
            "Column: 443, Selected False, Rank: 1184.000\n",
            "Column: 444, Selected False, Rank: 2319.000\n",
            "Column: 445, Selected False, Rank: 2702.000\n",
            "Column: 446, Selected False, Rank: 2025.000\n",
            "Column: 447, Selected False, Rank: 599.000\n",
            "Column: 448, Selected False, Rank: 1007.000\n",
            "Column: 449, Selected False, Rank: 2518.000\n",
            "Column: 450, Selected False, Rank: 1687.000\n",
            "Column: 451, Selected False, Rank: 1777.000\n",
            "Column: 452, Selected False, Rank: 1724.000\n",
            "Column: 453, Selected False, Rank: 802.000\n",
            "Column: 454, Selected False, Rank: 1688.000\n",
            "Column: 455, Selected False, Rank: 1214.000\n",
            "Column: 456, Selected False, Rank: 1759.000\n",
            "Column: 457, Selected False, Rank: 2055.000\n",
            "Column: 458, Selected False, Rank: 2304.000\n",
            "Column: 459, Selected False, Rank: 1175.000\n",
            "Column: 460, Selected False, Rank: 1937.000\n",
            "Column: 461, Selected False, Rank: 1905.000\n",
            "Column: 462, Selected False, Rank: 1897.000\n",
            "Column: 463, Selected False, Rank: 1209.000\n",
            "Column: 464, Selected False, Rank: 2690.000\n",
            "Column: 465, Selected False, Rank: 1540.000\n",
            "Column: 466, Selected False, Rank: 542.000\n",
            "Column: 467, Selected False, Rank: 2617.000\n",
            "Column: 468, Selected False, Rank: 2450.000\n",
            "Column: 469, Selected False, Rank: 839.000\n",
            "Column: 470, Selected False, Rank: 2490.000\n",
            "Column: 471, Selected False, Rank: 2470.000\n",
            "Column: 472, Selected False, Rank: 324.000\n",
            "Column: 473, Selected False, Rank: 2189.000\n",
            "Column: 474, Selected False, Rank: 2014.000\n",
            "Column: 475, Selected False, Rank: 1669.000\n",
            "Column: 476, Selected False, Rank: 512.000\n",
            "Column: 477, Selected False, Rank: 2624.000\n",
            "Column: 478, Selected False, Rank: 1535.000\n",
            "Column: 479, Selected False, Rank: 1434.000\n",
            "Column: 480, Selected False, Rank: 2198.000\n",
            "Column: 481, Selected False, Rank: 2479.000\n",
            "Column: 482, Selected False, Rank: 1902.000\n",
            "Column: 483, Selected False, Rank: 2003.000\n",
            "Column: 484, Selected False, Rank: 675.000\n",
            "Column: 485, Selected False, Rank: 2104.000\n",
            "Column: 486, Selected False, Rank: 1046.000\n",
            "Column: 487, Selected False, Rank: 2447.000\n",
            "Column: 488, Selected False, Rank: 780.000\n",
            "Column: 489, Selected False, Rank: 535.000\n",
            "Column: 490, Selected False, Rank: 1798.000\n",
            "Column: 491, Selected False, Rank: 2676.000\n",
            "Column: 492, Selected False, Rank: 1901.000\n",
            "Column: 493, Selected False, Rank: 1272.000\n",
            "Column: 494, Selected False, Rank: 2459.000\n",
            "Column: 495, Selected False, Rank: 2221.000\n",
            "Column: 496, Selected False, Rank: 446.000\n",
            "Column: 497, Selected False, Rank: 2433.000\n",
            "Column: 498, Selected False, Rank: 1286.000\n",
            "Column: 499, Selected False, Rank: 2328.000\n",
            "Column: 500, Selected False, Rank: 916.000\n",
            "Column: 501, Selected False, Rank: 2772.000\n",
            "Column: 502, Selected False, Rank: 1011.000\n",
            "Column: 503, Selected False, Rank: 884.000\n",
            "Column: 504, Selected False, Rank: 221.000\n",
            "Column: 505, Selected False, Rank: 420.000\n",
            "Column: 506, Selected False, Rank: 1048.000\n",
            "Column: 507, Selected False, Rank: 2419.000\n",
            "Column: 508, Selected False, Rank: 892.000\n",
            "Column: 509, Selected False, Rank: 2298.000\n",
            "Column: 510, Selected False, Rank: 1771.000\n",
            "Column: 511, Selected False, Rank: 860.000\n",
            "Column: 512, Selected False, Rank: 2076.000\n",
            "Column: 513, Selected False, Rank: 1307.000\n",
            "Column: 514, Selected False, Rank: 2778.000\n",
            "Column: 515, Selected False, Rank: 1958.000\n",
            "Column: 516, Selected False, Rank: 1327.000\n",
            "Column: 517, Selected False, Rank: 1051.000\n",
            "Column: 518, Selected False, Rank: 2573.000\n",
            "Column: 519, Selected False, Rank: 2471.000\n",
            "Column: 520, Selected False, Rank: 640.000\n",
            "Column: 521, Selected False, Rank: 2722.000\n",
            "Column: 522, Selected False, Rank: 2648.000\n",
            "Column: 523, Selected False, Rank: 714.000\n",
            "Column: 524, Selected False, Rank: 1797.000\n",
            "Column: 525, Selected False, Rank: 2138.000\n",
            "Column: 526, Selected False, Rank: 592.000\n",
            "Column: 527, Selected False, Rank: 2555.000\n",
            "Column: 528, Selected False, Rank: 1675.000\n",
            "Column: 529, Selected False, Rank: 1883.000\n",
            "Column: 530, Selected False, Rank: 1643.000\n",
            "Column: 531, Selected False, Rank: 840.000\n",
            "Column: 532, Selected False, Rank: 1533.000\n",
            "Column: 533, Selected False, Rank: 1654.000\n",
            "Column: 534, Selected False, Rank: 471.000\n",
            "Column: 535, Selected False, Rank: 2178.000\n",
            "Column: 536, Selected False, Rank: 2536.000\n",
            "Column: 537, Selected False, Rank: 1520.000\n",
            "Column: 538, Selected False, Rank: 1814.000\n",
            "Column: 539, Selected False, Rank: 499.000\n",
            "Column: 540, Selected False, Rank: 786.000\n",
            "Column: 541, Selected False, Rank: 1623.000\n",
            "Column: 542, Selected False, Rank: 2775.000\n",
            "Column: 543, Selected False, Rank: 1808.000\n",
            "Column: 544, Selected False, Rank: 612.000\n",
            "Column: 545, Selected False, Rank: 547.000\n",
            "Column: 546, Selected False, Rank: 2671.000\n",
            "Column: 547, Selected False, Rank: 2688.000\n",
            "Column: 548, Selected False, Rank: 2610.000\n",
            "Column: 549, Selected False, Rank: 2261.000\n",
            "Column: 550, Selected False, Rank: 1632.000\n",
            "Column: 551, Selected False, Rank: 281.000\n",
            "Column: 552, Selected False, Rank: 2326.000\n",
            "Column: 553, Selected False, Rank: 74.000\n",
            "Column: 554, Selected False, Rank: 1935.000\n",
            "Column: 555, Selected False, Rank: 1696.000\n",
            "Column: 556, Selected False, Rank: 1526.000\n",
            "Column: 557, Selected False, Rank: 637.000\n",
            "Column: 558, Selected False, Rank: 783.000\n",
            "Column: 559, Selected False, Rank: 2015.000\n",
            "Column: 560, Selected False, Rank: 1390.000\n",
            "Column: 561, Selected False, Rank: 1469.000\n",
            "Column: 562, Selected False, Rank: 1691.000\n",
            "Column: 563, Selected False, Rank: 2350.000\n",
            "Column: 564, Selected False, Rank: 1278.000\n",
            "Column: 565, Selected False, Rank: 1204.000\n",
            "Column: 566, Selected False, Rank: 2388.000\n",
            "Column: 567, Selected False, Rank: 2215.000\n",
            "Column: 568, Selected False, Rank: 520.000\n",
            "Column: 569, Selected False, Rank: 2606.000\n",
            "Column: 570, Selected False, Rank: 371.000\n",
            "Column: 571, Selected False, Rank: 770.000\n",
            "Column: 572, Selected False, Rank: 2300.000\n",
            "Column: 573, Selected False, Rank: 1630.000\n",
            "Column: 574, Selected False, Rank: 303.000\n",
            "Column: 575, Selected False, Rank: 1094.000\n",
            "Column: 576, Selected False, Rank: 1817.000\n",
            "Column: 577, Selected False, Rank: 687.000\n",
            "Column: 578, Selected False, Rank: 2232.000\n",
            "Column: 579, Selected False, Rank: 1555.000\n",
            "Column: 580, Selected False, Rank: 1219.000\n",
            "Column: 581, Selected False, Rank: 284.000\n",
            "Column: 582, Selected False, Rank: 1457.000\n",
            "Column: 583, Selected False, Rank: 126.000\n",
            "Column: 584, Selected False, Rank: 1047.000\n",
            "Column: 585, Selected False, Rank: 1567.000\n",
            "Column: 586, Selected False, Rank: 1621.000\n",
            "Column: 587, Selected False, Rank: 575.000\n",
            "Column: 588, Selected False, Rank: 1440.000\n",
            "Column: 589, Selected False, Rank: 2759.000\n",
            "Column: 590, Selected False, Rank: 2337.000\n",
            "Column: 591, Selected False, Rank: 2046.000\n",
            "Column: 592, Selected False, Rank: 747.000\n",
            "Column: 593, Selected False, Rank: 1396.000\n",
            "Column: 594, Selected False, Rank: 2242.000\n",
            "Column: 595, Selected False, Rank: 2325.000\n",
            "Column: 596, Selected False, Rank: 785.000\n",
            "Column: 597, Selected False, Rank: 2789.000\n",
            "Column: 598, Selected False, Rank: 1385.000\n",
            "Column: 599, Selected False, Rank: 538.000\n",
            "Column: 600, Selected False, Rank: 2530.000\n",
            "Column: 601, Selected False, Rank: 1014.000\n",
            "Column: 602, Selected False, Rank: 2794.000\n",
            "Column: 603, Selected False, Rank: 2394.000\n",
            "Column: 604, Selected False, Rank: 1428.000\n",
            "Column: 605, Selected False, Rank: 2147.000\n",
            "Column: 606, Selected False, Rank: 2353.000\n",
            "Column: 607, Selected False, Rank: 2418.000\n",
            "Column: 608, Selected False, Rank: 1455.000\n",
            "Column: 609, Selected False, Rank: 2244.000\n",
            "Column: 610, Selected False, Rank: 450.000\n",
            "Column: 611, Selected False, Rank: 264.000\n",
            "Column: 612, Selected False, Rank: 1135.000\n",
            "Column: 613, Selected False, Rank: 1620.000\n",
            "Column: 614, Selected False, Rank: 1672.000\n",
            "Column: 615, Selected False, Rank: 396.000\n",
            "Column: 616, Selected False, Rank: 1904.000\n",
            "Column: 617, Selected False, Rank: 1124.000\n",
            "Column: 618, Selected False, Rank: 1430.000\n",
            "Column: 619, Selected False, Rank: 372.000\n",
            "Column: 620, Selected False, Rank: 2225.000\n",
            "Column: 621, Selected False, Rank: 979.000\n",
            "Column: 622, Selected False, Rank: 1545.000\n",
            "Column: 623, Selected False, Rank: 2371.000\n",
            "Column: 624, Selected False, Rank: 2429.000\n",
            "Column: 625, Selected False, Rank: 2284.000\n",
            "Column: 626, Selected False, Rank: 2098.000\n",
            "Column: 627, Selected False, Rank: 944.000\n",
            "Column: 628, Selected False, Rank: 1635.000\n",
            "Column: 629, Selected False, Rank: 1092.000\n",
            "Column: 630, Selected False, Rank: 897.000\n",
            "Column: 631, Selected False, Rank: 2170.000\n",
            "Column: 632, Selected False, Rank: 1833.000\n",
            "Column: 633, Selected False, Rank: 1423.000\n",
            "Column: 634, Selected False, Rank: 1775.000\n",
            "Column: 635, Selected False, Rank: 2111.000\n",
            "Column: 636, Selected False, Rank: 1464.000\n",
            "Column: 637, Selected False, Rank: 359.000\n",
            "Column: 638, Selected False, Rank: 1122.000\n",
            "Column: 639, Selected False, Rank: 1638.000\n",
            "Column: 640, Selected False, Rank: 769.000\n",
            "Column: 641, Selected False, Rank: 1593.000\n",
            "Column: 642, Selected False, Rank: 2746.000\n",
            "Column: 643, Selected False, Rank: 2790.000\n",
            "Column: 644, Selected False, Rank: 1561.000\n",
            "Column: 645, Selected False, Rank: 1763.000\n",
            "Column: 646, Selected False, Rank: 2522.000\n",
            "Column: 647, Selected False, Rank: 2616.000\n",
            "Column: 648, Selected False, Rank: 813.000\n",
            "Column: 649, Selected False, Rank: 160.000\n",
            "Column: 650, Selected False, Rank: 2766.000\n",
            "Column: 651, Selected False, Rank: 1188.000\n",
            "Column: 652, Selected False, Rank: 1239.000\n",
            "Column: 653, Selected False, Rank: 2534.000\n",
            "Column: 654, Selected False, Rank: 1606.000\n",
            "Column: 655, Selected False, Rank: 2604.000\n",
            "Column: 656, Selected False, Rank: 729.000\n",
            "Column: 657, Selected False, Rank: 2667.000\n",
            "Column: 658, Selected False, Rank: 1865.000\n",
            "Column: 659, Selected False, Rank: 476.000\n",
            "Column: 660, Selected False, Rank: 1744.000\n",
            "Column: 661, Selected False, Rank: 578.000\n",
            "Column: 662, Selected False, Rank: 1056.000\n",
            "Column: 663, Selected False, Rank: 1747.000\n",
            "Column: 664, Selected False, Rank: 1657.000\n",
            "Column: 665, Selected False, Rank: 466.000\n",
            "Column: 666, Selected False, Rank: 1107.000\n",
            "Column: 667, Selected False, Rank: 2059.000\n",
            "Column: 668, Selected False, Rank: 1587.000\n",
            "Column: 669, Selected False, Rank: 540.000\n",
            "Column: 670, Selected False, Rank: 2077.000\n",
            "Column: 671, Selected False, Rank: 1453.000\n",
            "Column: 672, Selected False, Rank: 1406.000\n",
            "Column: 673, Selected False, Rank: 1507.000\n",
            "Column: 674, Selected False, Rank: 563.000\n",
            "Column: 675, Selected False, Rank: 235.000\n",
            "Column: 676, Selected False, Rank: 926.000\n",
            "Column: 677, Selected False, Rank: 721.000\n",
            "Column: 678, Selected False, Rank: 1143.000\n",
            "Column: 679, Selected False, Rank: 2120.000\n",
            "Column: 680, Selected False, Rank: 39.000\n",
            "Column: 681, Selected False, Rank: 1964.000\n",
            "Column: 682, Selected False, Rank: 1412.000\n",
            "Column: 683, Selected False, Rank: 2033.000\n",
            "Column: 684, Selected False, Rank: 2179.000\n",
            "Column: 685, Selected False, Rank: 478.000\n",
            "Column: 686, Selected False, Rank: 1877.000\n",
            "Column: 687, Selected False, Rank: 1736.000\n",
            "Column: 688, Selected False, Rank: 2087.000\n",
            "Column: 689, Selected False, Rank: 2285.000\n",
            "Column: 690, Selected False, Rank: 333.000\n",
            "Column: 691, Selected False, Rank: 1753.000\n",
            "Column: 692, Selected False, Rank: 2385.000\n",
            "Column: 693, Selected False, Rank: 732.000\n",
            "Column: 694, Selected False, Rank: 1923.000\n",
            "Column: 695, Selected False, Rank: 1148.000\n",
            "Column: 696, Selected False, Rank: 1478.000\n",
            "Column: 697, Selected False, Rank: 2562.000\n",
            "Column: 698, Selected False, Rank: 1070.000\n",
            "Column: 699, Selected False, Rank: 1103.000\n",
            "Column: 700, Selected False, Rank: 1750.000\n",
            "Column: 701, Selected False, Rank: 636.000\n",
            "Column: 702, Selected False, Rank: 1072.000\n",
            "Column: 703, Selected False, Rank: 2066.000\n",
            "Column: 704, Selected False, Rank: 384.000\n",
            "Column: 705, Selected False, Rank: 2658.000\n",
            "Column: 706, Selected False, Rank: 1881.000\n",
            "Column: 707, Selected False, Rank: 2301.000\n",
            "Column: 708, Selected False, Rank: 1433.000\n",
            "Column: 709, Selected False, Rank: 1542.000\n",
            "Column: 710, Selected False, Rank: 1108.000\n",
            "Column: 711, Selected False, Rank: 1374.000\n",
            "Column: 712, Selected False, Rank: 1757.000\n",
            "Column: 713, Selected False, Rank: 1633.000\n",
            "Column: 714, Selected False, Rank: 607.000\n",
            "Column: 715, Selected False, Rank: 1238.000\n",
            "Column: 716, Selected False, Rank: 722.000\n",
            "Column: 717, Selected False, Rank: 845.000\n",
            "Column: 718, Selected False, Rank: 868.000\n",
            "Column: 719, Selected False, Rank: 1465.000\n",
            "Column: 720, Selected False, Rank: 257.000\n",
            "Column: 721, Selected False, Rank: 2378.000\n",
            "Column: 722, Selected False, Rank: 1058.000\n",
            "Column: 723, Selected False, Rank: 1649.000\n",
            "Column: 724, Selected False, Rank: 908.000\n",
            "Column: 725, Selected False, Rank: 1518.000\n",
            "Column: 726, Selected False, Rank: 2351.000\n",
            "Column: 727, Selected False, Rank: 815.000\n",
            "Column: 728, Selected False, Rank: 431.000\n",
            "Column: 729, Selected False, Rank: 322.000\n",
            "Column: 730, Selected False, Rank: 2186.000\n",
            "Column: 731, Selected False, Rank: 1451.000\n",
            "Column: 732, Selected False, Rank: 2564.000\n",
            "Column: 733, Selected False, Rank: 541.000\n",
            "Column: 734, Selected False, Rank: 1042.000\n",
            "Column: 735, Selected False, Rank: 1019.000\n",
            "Column: 736, Selected False, Rank: 717.000\n",
            "Column: 737, Selected False, Rank: 506.000\n",
            "Column: 738, Selected False, Rank: 666.000\n",
            "Column: 739, Selected False, Rank: 1698.000\n",
            "Column: 740, Selected False, Rank: 2334.000\n",
            "Column: 741, Selected False, Rank: 1766.000\n",
            "Column: 742, Selected False, Rank: 1022.000\n",
            "Column: 743, Selected False, Rank: 1280.000\n",
            "Column: 744, Selected False, Rank: 1530.000\n",
            "Column: 745, Selected False, Rank: 622.000\n",
            "Column: 746, Selected False, Rank: 2731.000\n",
            "Column: 747, Selected False, Rank: 2018.000\n",
            "Column: 748, Selected False, Rank: 336.000\n",
            "Column: 749, Selected False, Rank: 1306.000\n",
            "Column: 750, Selected False, Rank: 2526.000\n",
            "Column: 751, Selected False, Rank: 1809.000\n",
            "Column: 752, Selected False, Rank: 1647.000\n",
            "Column: 753, Selected False, Rank: 1032.000\n",
            "Column: 754, Selected False, Rank: 1167.000\n",
            "Column: 755, Selected False, Rank: 1694.000\n",
            "Column: 756, Selected False, Rank: 1059.000\n",
            "Column: 757, Selected False, Rank: 723.000\n",
            "Column: 758, Selected False, Rank: 1236.000\n",
            "Column: 759, Selected False, Rank: 1651.000\n",
            "Column: 760, Selected False, Rank: 1990.000\n",
            "Column: 761, Selected False, Rank: 799.000\n",
            "Column: 762, Selected False, Rank: 1211.000\n",
            "Column: 763, Selected False, Rank: 2043.000\n",
            "Column: 764, Selected False, Rank: 2621.000\n",
            "Column: 765, Selected False, Rank: 1343.000\n",
            "Column: 766, Selected False, Rank: 1947.000\n",
            "Column: 767, Selected False, Rank: 577.000\n",
            "Column: 768, Selected False, Rank: 887.000\n",
            "Column: 769, Selected False, Rank: 2556.000\n",
            "Column: 770, Selected False, Rank: 1554.000\n",
            "Column: 771, Selected False, Rank: 1379.000\n",
            "Column: 772, Selected False, Rank: 2045.000\n",
            "Column: 773, Selected False, Rank: 2681.000\n",
            "Column: 774, Selected False, Rank: 2441.000\n",
            "Column: 775, Selected False, Rank: 1445.000\n",
            "Column: 776, Selected False, Rank: 1697.000\n",
            "Column: 777, Selected False, Rank: 902.000\n",
            "Column: 778, Selected False, Rank: 2342.000\n",
            "Column: 779, Selected False, Rank: 511.000\n",
            "Column: 780, Selected False, Rank: 556.000\n",
            "Column: 781, Selected False, Rank: 323.000\n",
            "Column: 782, Selected False, Rank: 1667.000\n",
            "Column: 783, Selected False, Rank: 1741.000\n",
            "Column: 784, Selected False, Rank: 1226.000\n",
            "Column: 785, Selected False, Rank: 841.000\n",
            "Column: 786, Selected False, Rank: 1277.000\n",
            "Column: 787, Selected False, Rank: 2020.000\n",
            "Column: 788, Selected False, Rank: 173.000\n",
            "Column: 789, Selected False, Rank: 2011.000\n",
            "Column: 790, Selected False, Rank: 1318.000\n",
            "Column: 791, Selected False, Rank: 700.000\n",
            "Column: 792, Selected False, Rank: 2084.000\n",
            "Column: 793, Selected False, Rank: 615.000\n",
            "Column: 794, Selected False, Rank: 1942.000\n",
            "Column: 795, Selected False, Rank: 1571.000\n",
            "Column: 796, Selected False, Rank: 1912.000\n",
            "Column: 797, Selected False, Rank: 2381.000\n",
            "Column: 798, Selected False, Rank: 1862.000\n",
            "Column: 799, Selected False, Rank: 1275.000\n",
            "Column: 800, Selected False, Rank: 1855.000\n",
            "Column: 801, Selected False, Rank: 896.000\n",
            "Column: 802, Selected False, Rank: 2742.000\n",
            "Column: 803, Selected False, Rank: 901.000\n",
            "Column: 804, Selected False, Rank: 2126.000\n",
            "Column: 805, Selected False, Rank: 825.000\n",
            "Column: 806, Selected False, Rank: 2485.000\n",
            "Column: 807, Selected False, Rank: 2191.000\n",
            "Column: 808, Selected False, Rank: 2647.000\n",
            "Column: 809, Selected False, Rank: 738.000\n",
            "Column: 810, Selected False, Rank: 707.000\n",
            "Column: 811, Selected False, Rank: 236.000\n",
            "Column: 812, Selected False, Rank: 869.000\n",
            "Column: 813, Selected False, Rank: 1891.000\n",
            "Column: 814, Selected False, Rank: 866.000\n",
            "Column: 815, Selected False, Rank: 273.000\n",
            "Column: 816, Selected False, Rank: 646.000\n",
            "Column: 817, Selected False, Rank: 948.000\n",
            "Column: 818, Selected False, Rank: 1780.000\n",
            "Column: 819, Selected False, Rank: 1381.000\n",
            "Column: 820, Selected False, Rank: 978.000\n",
            "Column: 821, Selected False, Rank: 2256.000\n",
            "Column: 822, Selected False, Rank: 1298.000\n",
            "Column: 823, Selected False, Rank: 1462.000\n",
            "Column: 824, Selected False, Rank: 1224.000\n",
            "Column: 825, Selected False, Rank: 252.000\n",
            "Column: 826, Selected False, Rank: 936.000\n",
            "Column: 827, Selected False, Rank: 2220.000\n",
            "Column: 828, Selected False, Rank: 1386.000\n",
            "Column: 829, Selected False, Rank: 328.000\n",
            "Column: 830, Selected False, Rank: 2316.000\n",
            "Column: 831, Selected False, Rank: 1415.000\n",
            "Column: 832, Selected False, Rank: 1168.000\n",
            "Column: 833, Selected False, Rank: 638.000\n",
            "Column: 834, Selected False, Rank: 1040.000\n",
            "Column: 835, Selected False, Rank: 2024.000\n",
            "Column: 836, Selected False, Rank: 1262.000\n",
            "Column: 837, Selected False, Rank: 1482.000\n",
            "Column: 838, Selected False, Rank: 2594.000\n",
            "Column: 839, Selected False, Rank: 942.000\n",
            "Column: 840, Selected False, Rank: 647.000\n",
            "Column: 841, Selected False, Rank: 1422.000\n",
            "Column: 842, Selected False, Rank: 1733.000\n",
            "Column: 843, Selected False, Rank: 2769.000\n",
            "Column: 844, Selected False, Rank: 2377.000\n",
            "Column: 845, Selected False, Rank: 1484.000\n",
            "Column: 846, Selected False, Rank: 1739.000\n",
            "Column: 847, Selected False, Rank: 434.000\n",
            "Column: 848, Selected False, Rank: 1547.000\n",
            "Column: 849, Selected False, Rank: 2650.000\n",
            "Column: 850, Selected False, Rank: 1425.000\n",
            "Column: 851, Selected False, Rank: 2465.000\n",
            "Column: 852, Selected False, Rank: 423.000\n",
            "Column: 853, Selected False, Rank: 2143.000\n",
            "Column: 854, Selected False, Rank: 1273.000\n",
            "Column: 855, Selected False, Rank: 2051.000\n",
            "Column: 856, Selected False, Rank: 2257.000\n",
            "Column: 857, Selected False, Rank: 1290.000\n",
            "Column: 858, Selected False, Rank: 1789.000\n",
            "Column: 859, Selected False, Rank: 2533.000\n",
            "Column: 860, Selected False, Rank: 1954.000\n",
            "Column: 861, Selected False, Rank: 1497.000\n",
            "Column: 862, Selected False, Rank: 1832.000\n",
            "Column: 863, Selected False, Rank: 2540.000\n",
            "Column: 864, Selected False, Rank: 2264.000\n",
            "Column: 865, Selected False, Rank: 352.000\n",
            "Column: 866, Selected False, Rank: 1213.000\n",
            "Column: 867, Selected False, Rank: 1860.000\n",
            "Column: 868, Selected False, Rank: 1600.000\n",
            "Column: 869, Selected False, Rank: 2708.000\n",
            "Column: 870, Selected False, Rank: 2792.000\n",
            "Column: 871, Selected False, Rank: 2707.000\n",
            "Column: 872, Selected False, Rank: 2664.000\n",
            "Column: 873, Selected False, Rank: 1793.000\n",
            "Column: 874, Selected False, Rank: 2049.000\n",
            "Column: 875, Selected False, Rank: 2633.000\n",
            "Column: 876, Selected False, Rank: 1772.000\n",
            "Column: 877, Selected False, Rank: 137.000\n",
            "Column: 878, Selected False, Rank: 1074.000\n",
            "Column: 879, Selected False, Rank: 2642.000\n",
            "Column: 880, Selected False, Rank: 342.000\n",
            "Column: 881, Selected False, Rank: 1955.000\n",
            "Column: 882, Selected False, Rank: 1562.000\n",
            "Column: 883, Selected False, Rank: 2360.000\n",
            "Column: 884, Selected False, Rank: 365.000\n",
            "Column: 885, Selected False, Rank: 2017.000\n",
            "Column: 886, Selected False, Rank: 931.000\n",
            "Column: 887, Selected False, Rank: 88.000\n",
            "Column: 888, Selected False, Rank: 2519.000\n",
            "Column: 889, Selected False, Rank: 2376.000\n",
            "Column: 890, Selected False, Rank: 2666.000\n",
            "Column: 891, Selected False, Rank: 2007.000\n",
            "Column: 892, Selected False, Rank: 2718.000\n",
            "Column: 893, Selected False, Rank: 2491.000\n",
            "Column: 894, Selected False, Rank: 2622.000\n",
            "Column: 895, Selected False, Rank: 1352.000\n",
            "Column: 896, Selected False, Rank: 1539.000\n",
            "Column: 897, Selected False, Rank: 1792.000\n",
            "Column: 898, Selected False, Rank: 1317.000\n",
            "Column: 899, Selected False, Rank: 2145.000\n",
            "Column: 900, Selected False, Rank: 2137.000\n",
            "Column: 901, Selected False, Rank: 2329.000\n",
            "Column: 902, Selected False, Rank: 321.000\n",
            "Column: 903, Selected False, Rank: 2684.000\n",
            "Column: 904, Selected False, Rank: 2634.000\n",
            "Column: 905, Selected False, Rank: 1483.000\n",
            "Column: 906, Selected False, Rank: 2122.000\n",
            "Column: 907, Selected False, Rank: 1417.000\n",
            "Column: 908, Selected False, Rank: 849.000\n",
            "Column: 909, Selected False, Rank: 96.000\n",
            "Column: 910, Selected False, Rank: 1636.000\n",
            "Column: 911, Selected True, Rank: 1.000\n",
            "Column: 912, Selected False, Rank: 416.000\n",
            "Column: 913, Selected False, Rank: 1099.000\n",
            "Column: 914, Selected False, Rank: 2153.000\n",
            "Column: 915, Selected False, Rank: 2140.000\n",
            "Column: 916, Selected False, Rank: 1005.000\n",
            "Column: 917, Selected False, Rank: 1608.000\n",
            "Column: 918, Selected False, Rank: 2672.000\n",
            "Column: 919, Selected False, Rank: 2213.000\n",
            "Column: 920, Selected False, Rank: 2734.000\n",
            "Column: 921, Selected False, Rank: 1616.000\n",
            "Column: 922, Selected False, Rank: 2685.000\n",
            "Column: 923, Selected False, Rank: 1920.000\n",
            "Column: 924, Selected False, Rank: 1977.000\n",
            "Column: 925, Selected False, Rank: 2590.000\n",
            "Column: 926, Selected False, Rank: 954.000\n",
            "Column: 927, Selected False, Rank: 373.000\n",
            "Column: 928, Selected False, Rank: 1163.000\n",
            "Column: 929, Selected False, Rank: 870.000\n",
            "Column: 930, Selected False, Rank: 2041.000\n",
            "Column: 931, Selected False, Rank: 1726.000\n",
            "Column: 932, Selected False, Rank: 2086.000\n",
            "Column: 933, Selected False, Rank: 2088.000\n",
            "Column: 934, Selected False, Rank: 1078.000\n",
            "Column: 935, Selected False, Rank: 1997.000\n",
            "Column: 936, Selected False, Rank: 1337.000\n",
            "Column: 937, Selected False, Rank: 1992.000\n",
            "Column: 938, Selected False, Rank: 1387.000\n",
            "Column: 939, Selected False, Rank: 911.000\n",
            "Column: 940, Selected False, Rank: 1818.000\n",
            "Column: 941, Selected False, Rank: 2200.000\n",
            "Column: 942, Selected False, Rank: 981.000\n",
            "Column: 943, Selected False, Rank: 1519.000\n",
            "Column: 944, Selected False, Rank: 1008.000\n",
            "Column: 945, Selected False, Rank: 941.000\n",
            "Column: 946, Selected False, Rank: 1896.000\n",
            "Column: 947, Selected False, Rank: 1085.000\n",
            "Column: 948, Selected False, Rank: 1269.000\n",
            "Column: 949, Selected False, Rank: 1609.000\n",
            "Column: 950, Selected False, Rank: 1336.000\n",
            "Column: 951, Selected False, Rank: 1093.000\n",
            "Column: 952, Selected False, Rank: 1338.000\n",
            "Column: 953, Selected False, Rank: 425.000\n",
            "Column: 954, Selected False, Rank: 1663.000\n",
            "Column: 955, Selected False, Rank: 395.000\n",
            "Column: 956, Selected False, Rank: 1984.000\n",
            "Column: 957, Selected False, Rank: 461.000\n",
            "Column: 958, Selected False, Rank: 1302.000\n",
            "Column: 959, Selected False, Rank: 1592.000\n",
            "Column: 960, Selected False, Rank: 1292.000\n",
            "Column: 961, Selected False, Rank: 994.000\n",
            "Column: 962, Selected False, Rank: 375.000\n",
            "Column: 963, Selected False, Rank: 1831.000\n",
            "Column: 964, Selected False, Rank: 913.000\n",
            "Column: 965, Selected False, Rank: 1859.000\n",
            "Column: 966, Selected False, Rank: 1488.000\n",
            "Column: 967, Selected False, Rank: 2436.000\n",
            "Column: 968, Selected False, Rank: 412.000\n",
            "Column: 969, Selected False, Rank: 1617.000\n",
            "Column: 970, Selected False, Rank: 1187.000\n",
            "Column: 971, Selected False, Rank: 2486.000\n",
            "Column: 972, Selected False, Rank: 2239.000\n",
            "Column: 973, Selected False, Rank: 1807.000\n",
            "Column: 974, Selected False, Rank: 1118.000\n",
            "Column: 975, Selected False, Rank: 1602.000\n",
            "Column: 976, Selected False, Rank: 2085.000\n",
            "Column: 977, Selected False, Rank: 1207.000\n",
            "Column: 978, Selected False, Rank: 2780.000\n",
            "Column: 979, Selected False, Rank: 2219.000\n",
            "Column: 980, Selected False, Rank: 2124.000\n",
            "Column: 981, Selected False, Rank: 1534.000\n",
            "Column: 982, Selected False, Rank: 2075.000\n",
            "Column: 983, Selected False, Rank: 2785.000\n",
            "Column: 984, Selected False, Rank: 1090.000\n",
            "Column: 985, Selected False, Rank: 2132.000\n",
            "Column: 986, Selected False, Rank: 2112.000\n",
            "Column: 987, Selected False, Rank: 589.000\n",
            "Column: 988, Selected False, Rank: 988.000\n",
            "Column: 989, Selected False, Rank: 927.000\n",
            "Column: 990, Selected False, Rank: 2235.000\n",
            "Column: 991, Selected False, Rank: 2165.000\n",
            "Column: 992, Selected False, Rank: 1927.000\n",
            "Column: 993, Selected False, Rank: 2463.000\n",
            "Column: 994, Selected False, Rank: 900.000\n",
            "Column: 995, Selected False, Rank: 2266.000\n",
            "Column: 996, Selected False, Rank: 496.000\n",
            "Column: 997, Selected False, Rank: 339.000\n",
            "Column: 998, Selected False, Rank: 2047.000\n",
            "Column: 999, Selected False, Rank: 1646.000\n",
            "Column: 1000, Selected False, Rank: 550.000\n",
            "Column: 1001, Selected False, Rank: 282.000\n",
            "Column: 1002, Selected False, Rank: 1805.000\n",
            "Column: 1003, Selected False, Rank: 1199.000\n",
            "Column: 1004, Selected False, Rank: 2730.000\n",
            "Column: 1005, Selected False, Rank: 390.000\n",
            "Column: 1006, Selected False, Rank: 1581.000\n",
            "Column: 1007, Selected False, Rank: 2669.000\n",
            "Column: 1008, Selected False, Rank: 2748.000\n",
            "Column: 1009, Selected False, Rank: 1752.000\n",
            "Column: 1010, Selected False, Rank: 929.000\n",
            "Column: 1011, Selected False, Rank: 1585.000\n",
            "Column: 1012, Selected False, Rank: 1972.000\n",
            "Column: 1013, Selected False, Rank: 2503.000\n",
            "Column: 1014, Selected False, Rank: 2713.000\n",
            "Column: 1015, Selected False, Rank: 2726.000\n",
            "Column: 1016, Selected False, Rank: 1010.000\n",
            "Column: 1017, Selected False, Rank: 1613.000\n",
            "Column: 1018, Selected False, Rank: 1840.000\n",
            "Column: 1019, Selected False, Rank: 1241.000\n",
            "Column: 1020, Selected False, Rank: 2096.000\n",
            "Column: 1021, Selected False, Rank: 925.000\n",
            "Column: 1022, Selected False, Rank: 1871.000\n",
            "Column: 1023, Selected False, Rank: 2128.000\n",
            "Column: 1024, Selected False, Rank: 980.000\n",
            "Column: 1025, Selected False, Rank: 1147.000\n",
            "Column: 1026, Selected False, Rank: 631.000\n",
            "Column: 1027, Selected False, Rank: 835.000\n",
            "Column: 1028, Selected False, Rank: 2332.000\n",
            "Column: 1029, Selected False, Rank: 246.000\n",
            "Column: 1030, Selected False, Rank: 1427.000\n",
            "Column: 1031, Selected False, Rank: 664.000\n",
            "Column: 1032, Selected False, Rank: 2204.000\n",
            "Column: 1033, Selected False, Rank: 2435.000\n",
            "Column: 1034, Selected False, Rank: 817.000\n",
            "Column: 1035, Selected False, Rank: 2577.000\n",
            "Column: 1036, Selected False, Rank: 378.000\n",
            "Column: 1037, Selected False, Rank: 1625.000\n",
            "Column: 1038, Selected False, Rank: 2265.000\n",
            "Column: 1039, Selected False, Rank: 1957.000\n",
            "Column: 1040, Selected False, Rank: 1173.000\n",
            "Column: 1041, Selected False, Rank: 2019.000\n",
            "Column: 1042, Selected False, Rank: 1629.000\n",
            "Column: 1043, Selected False, Rank: 2777.000\n",
            "Column: 1044, Selected False, Rank: 719.000\n",
            "Column: 1045, Selected False, Rank: 2762.000\n",
            "Column: 1046, Selected False, Rank: 2410.000\n",
            "Column: 1047, Selected False, Rank: 1448.000\n",
            "Column: 1048, Selected False, Rank: 1086.000\n",
            "Column: 1049, Selected False, Rank: 2531.000\n",
            "Column: 1050, Selected False, Rank: 1951.000\n",
            "Column: 1051, Selected False, Rank: 2281.000\n",
            "Column: 1052, Selected False, Rank: 1257.000\n",
            "Column: 1053, Selected False, Rank: 1967.000\n",
            "Column: 1054, Selected False, Rank: 2182.000\n",
            "Column: 1055, Selected False, Rank: 2099.000\n",
            "Column: 1056, Selected False, Rank: 1794.000\n",
            "Column: 1057, Selected False, Rank: 2311.000\n",
            "Column: 1058, Selected False, Rank: 1360.000\n",
            "Column: 1059, Selected False, Rank: 1788.000\n",
            "Column: 1060, Selected False, Rank: 2283.000\n",
            "Column: 1061, Selected False, Rank: 761.000\n",
            "Column: 1062, Selected False, Rank: 1582.000\n",
            "Column: 1063, Selected False, Rank: 1721.000\n",
            "Column: 1064, Selected False, Rank: 2209.000\n",
            "Column: 1065, Selected False, Rank: 568.000\n",
            "Column: 1066, Selected False, Rank: 527.000\n",
            "Column: 1067, Selected False, Rank: 691.000\n",
            "Column: 1068, Selected False, Rank: 1460.000\n",
            "Column: 1069, Selected False, Rank: 1330.000\n",
            "Column: 1070, Selected False, Rank: 2398.000\n",
            "Column: 1071, Selected False, Rank: 581.000\n",
            "Column: 1072, Selected False, Rank: 2148.000\n",
            "Column: 1073, Selected False, Rank: 286.000\n",
            "Column: 1074, Selected False, Rank: 2185.000\n",
            "Column: 1075, Selected False, Rank: 2081.000\n",
            "Column: 1076, Selected False, Rank: 1928.000\n",
            "Column: 1077, Selected False, Rank: 1850.000\n",
            "Column: 1078, Selected False, Rank: 1834.000\n",
            "Column: 1079, Selected False, Rank: 2167.000\n",
            "Column: 1080, Selected False, Rank: 2231.000\n",
            "Column: 1081, Selected False, Rank: 1202.000\n",
            "Column: 1082, Selected False, Rank: 1728.000\n",
            "Column: 1083, Selected False, Rank: 2313.000\n",
            "Column: 1084, Selected False, Rank: 2655.000\n",
            "Column: 1085, Selected False, Rank: 2605.000\n",
            "Column: 1086, Selected False, Rank: 2203.000\n",
            "Column: 1087, Selected False, Rank: 2296.000\n",
            "Column: 1088, Selected False, Rank: 2184.000\n",
            "Column: 1089, Selected False, Rank: 237.000\n",
            "Column: 1090, Selected False, Rank: 2082.000\n",
            "Column: 1091, Selected False, Rank: 1549.000\n",
            "Column: 1092, Selected False, Rank: 549.000\n",
            "Column: 1093, Selected False, Rank: 1711.000\n",
            "Column: 1094, Selected False, Rank: 842.000\n",
            "Column: 1095, Selected False, Rank: 2168.000\n",
            "Column: 1096, Selected False, Rank: 1603.000\n",
            "Column: 1097, Selected False, Rank: 1823.000\n",
            "Column: 1098, Selected False, Rank: 351.000\n",
            "Column: 1099, Selected False, Rank: 1527.000\n",
            "Column: 1100, Selected False, Rank: 1866.000\n",
            "Column: 1101, Selected False, Rank: 1087.000\n",
            "Column: 1102, Selected False, Rank: 830.000\n",
            "Column: 1103, Selected False, Rank: 519.000\n",
            "Column: 1104, Selected False, Rank: 1309.000\n",
            "Column: 1105, Selected False, Rank: 2229.000\n",
            "Column: 1106, Selected False, Rank: 2625.000\n",
            "Column: 1107, Selected False, Rank: 2587.000\n",
            "Column: 1108, Selected False, Rank: 1444.000\n",
            "Column: 1109, Selected False, Rank: 1365.000\n",
            "Column: 1110, Selected False, Rank: 1101.000\n",
            "Column: 1111, Selected False, Rank: 921.000\n",
            "Column: 1112, Selected False, Rank: 2584.000\n",
            "Column: 1113, Selected False, Rank: 766.000\n",
            "Column: 1114, Selected False, Rank: 2062.000\n",
            "Column: 1115, Selected False, Rank: 1208.000\n",
            "Column: 1116, Selected False, Rank: 1664.000\n",
            "Column: 1117, Selected False, Rank: 2754.000\n",
            "Column: 1118, Selected False, Rank: 2752.000\n",
            "Column: 1119, Selected False, Rank: 1289.000\n",
            "Column: 1120, Selected False, Rank: 2210.000\n",
            "Column: 1121, Selected False, Rank: 1110.000\n",
            "Column: 1122, Selected False, Rank: 1186.000\n",
            "Column: 1123, Selected False, Rank: 716.000\n",
            "Column: 1124, Selected False, Rank: 1296.000\n",
            "Column: 1125, Selected False, Rank: 1575.000\n",
            "Column: 1126, Selected False, Rank: 655.000\n",
            "Column: 1127, Selected False, Rank: 2166.000\n",
            "Column: 1128, Selected False, Rank: 1035.000\n",
            "Column: 1129, Selected False, Rank: 1885.000\n",
            "Column: 1130, Selected False, Rank: 1925.000\n",
            "Column: 1131, Selected False, Rank: 1130.000\n",
            "Column: 1132, Selected False, Rank: 1347.000\n",
            "Column: 1133, Selected False, Rank: 159.000\n",
            "Column: 1134, Selected False, Rank: 1641.000\n",
            "Column: 1135, Selected False, Rank: 894.000\n",
            "Column: 1136, Selected False, Rank: 1502.000\n",
            "Column: 1137, Selected False, Rank: 1686.000\n",
            "Column: 1138, Selected False, Rank: 1369.000\n",
            "Column: 1139, Selected False, Rank: 588.000\n",
            "Column: 1140, Selected False, Rank: 2352.000\n",
            "Column: 1141, Selected False, Rank: 2602.000\n",
            "Column: 1142, Selected False, Rank: 1438.000\n",
            "Column: 1143, Selected False, Rank: 1329.000\n",
            "Column: 1144, Selected False, Rank: 2102.000\n",
            "Column: 1145, Selected False, Rank: 1128.000\n",
            "Column: 1146, Selected False, Rank: 624.000\n",
            "Column: 1147, Selected False, Rank: 2543.000\n",
            "Column: 1148, Selected False, Rank: 2506.000\n",
            "Column: 1149, Selected False, Rank: 42.000\n",
            "Column: 1150, Selected False, Rank: 801.000\n",
            "Column: 1151, Selected False, Rank: 2756.000\n",
            "Column: 1152, Selected False, Rank: 2745.000\n",
            "Column: 1153, Selected False, Rank: 2079.000\n",
            "Column: 1154, Selected False, Rank: 2761.000\n",
            "Column: 1155, Selected False, Rank: 1695.000\n",
            "Column: 1156, Selected False, Rank: 2740.000\n",
            "Column: 1157, Selected False, Rank: 57.000\n",
            "Column: 1158, Selected False, Rank: 2679.000\n",
            "Column: 1159, Selected False, Rank: 991.000\n",
            "Column: 1160, Selected False, Rank: 1013.000\n",
            "Column: 1161, Selected False, Rank: 1325.000\n",
            "Column: 1162, Selected False, Rank: 712.000\n",
            "Column: 1163, Selected False, Rank: 2070.000\n",
            "Column: 1164, Selected False, Rank: 1028.000\n",
            "Column: 1165, Selected False, Rank: 1933.000\n",
            "Column: 1166, Selected False, Rank: 2383.000\n",
            "Column: 1167, Selected False, Rank: 1773.000\n",
            "Column: 1168, Selected False, Rank: 2368.000\n",
            "Column: 1169, Selected False, Rank: 2784.000\n",
            "Column: 1170, Selected False, Rank: 2615.000\n",
            "Column: 1171, Selected False, Rank: 903.000\n",
            "Column: 1172, Selected False, Rank: 464.000\n",
            "Column: 1173, Selected False, Rank: 1560.000\n",
            "Column: 1174, Selected False, Rank: 1684.000\n",
            "Column: 1175, Selected False, Rank: 1764.000\n",
            "Column: 1176, Selected False, Rank: 1605.000\n",
            "Column: 1177, Selected False, Rank: 2016.000\n",
            "Column: 1178, Selected False, Rank: 2344.000\n",
            "Column: 1179, Selected False, Rank: 1825.000\n",
            "Column: 1180, Selected False, Rank: 1660.000\n",
            "Column: 1181, Selected False, Rank: 455.000\n",
            "Column: 1182, Selected False, Rank: 1112.000\n",
            "Column: 1183, Selected False, Rank: 1354.000\n",
            "Column: 1184, Selected False, Rank: 1847.000\n",
            "Column: 1185, Selected False, Rank: 1762.000\n",
            "Column: 1186, Selected False, Rank: 1500.000\n",
            "Column: 1187, Selected False, Rank: 2444.000\n",
            "Column: 1188, Selected False, Rank: 1930.000\n",
            "Column: 1189, Selected False, Rank: 2160.000\n",
            "Column: 1190, Selected False, Rank: 2252.000\n",
            "Column: 1191, Selected False, Rank: 2161.000\n",
            "Column: 1192, Selected False, Rank: 2527.000\n",
            "Column: 1193, Selected False, Rank: 2005.000\n",
            "Column: 1194, Selected False, Rank: 2678.000\n",
            "Column: 1195, Selected False, Rank: 1851.000\n",
            "Column: 1196, Selected False, Rank: 1875.000\n",
            "Column: 1197, Selected False, Rank: 2058.000\n",
            "Column: 1198, Selected False, Rank: 1225.000\n",
            "Column: 1199, Selected False, Rank: 251.000\n",
            "Column: 1200, Selected False, Rank: 749.000\n",
            "Column: 1201, Selected False, Rank: 1738.000\n",
            "Column: 1202, Selected False, Rank: 1044.000\n",
            "Column: 1203, Selected False, Rank: 2548.000\n",
            "Column: 1204, Selected False, Rank: 453.000\n",
            "Column: 1205, Selected False, Rank: 993.000\n",
            "Column: 1206, Selected False, Rank: 878.000\n",
            "Column: 1207, Selected False, Rank: 1665.000\n",
            "Column: 1208, Selected False, Rank: 2719.000\n",
            "Column: 1209, Selected False, Rank: 2649.000\n",
            "Column: 1210, Selected False, Rank: 1463.000\n",
            "Column: 1211, Selected False, Rank: 2404.000\n",
            "Column: 1212, Selected False, Rank: 2568.000\n",
            "Column: 1213, Selected False, Rank: 2414.000\n",
            "Column: 1214, Selected False, Rank: 1151.000\n",
            "Column: 1215, Selected False, Rank: 2335.000\n",
            "Column: 1216, Selected False, Rank: 2697.000\n",
            "Column: 1217, Selected False, Rank: 2619.000\n",
            "Column: 1218, Selected False, Rank: 2374.000\n",
            "Column: 1219, Selected False, Rank: 1940.000\n",
            "Column: 1220, Selected False, Rank: 1749.000\n",
            "Column: 1221, Selected False, Rank: 2292.000\n",
            "Column: 1222, Selected False, Rank: 2127.000\n",
            "Column: 1223, Selected False, Rank: 1599.000\n",
            "Column: 1224, Selected False, Rank: 1705.000\n",
            "Column: 1225, Selected False, Rank: 2764.000\n",
            "Column: 1226, Selected False, Rank: 2728.000\n",
            "Column: 1227, Selected False, Rank: 2321.000\n",
            "Column: 1228, Selected False, Rank: 585.000\n",
            "Column: 1229, Selected False, Rank: 1703.000\n",
            "Column: 1230, Selected False, Rank: 332.000\n",
            "Column: 1231, Selected False, Rank: 1025.000\n",
            "Column: 1232, Selected False, Rank: 1716.000\n",
            "Column: 1233, Selected False, Rank: 2570.000\n",
            "Column: 1234, Selected False, Rank: 1002.000\n",
            "Column: 1235, Selected False, Rank: 2274.000\n",
            "Column: 1236, Selected False, Rank: 1939.000\n",
            "Column: 1237, Selected False, Rank: 2703.000\n",
            "Column: 1238, Selected False, Rank: 2343.000\n",
            "Column: 1239, Selected False, Rank: 1016.000\n",
            "Column: 1240, Selected False, Rank: 1399.000\n",
            "Column: 1241, Selected False, Rank: 2586.000\n",
            "Column: 1242, Selected False, Rank: 2500.000\n",
            "Column: 1243, Selected False, Rank: 1100.000\n",
            "Column: 1244, Selected False, Rank: 2141.000\n",
            "Column: 1245, Selected False, Rank: 1229.000\n",
            "Column: 1246, Selected False, Rank: 204.000\n",
            "Column: 1247, Selected False, Rank: 871.000\n",
            "Column: 1248, Selected False, Rank: 2767.000\n",
            "Column: 1249, Selected False, Rank: 1249.000\n",
            "Column: 1250, Selected False, Rank: 2628.000\n",
            "Column: 1251, Selected False, Rank: 335.000\n",
            "Column: 1252, Selected False, Rank: 2154.000\n",
            "Column: 1253, Selected False, Rank: 1590.000\n",
            "Column: 1254, Selected False, Rank: 928.000\n",
            "Column: 1255, Selected False, Rank: 2324.000\n",
            "Column: 1256, Selected False, Rank: 2044.000\n",
            "Column: 1257, Selected False, Rank: 2114.000\n",
            "Column: 1258, Selected False, Rank: 2736.000\n",
            "Column: 1259, Selected False, Rank: 2151.000\n",
            "Column: 1260, Selected False, Rank: 2597.000\n",
            "Column: 1261, Selected False, Rank: 2544.000\n",
            "Column: 1262, Selected False, Rank: 1356.000\n",
            "Column: 1263, Selected False, Rank: 2493.000\n",
            "Column: 1264, Selected False, Rank: 590.000\n",
            "Column: 1265, Selected False, Rank: 2720.000\n",
            "Column: 1266, Selected False, Rank: 1854.000\n",
            "Column: 1267, Selected False, Rank: 1822.000\n",
            "Column: 1268, Selected False, Rank: 867.000\n",
            "Column: 1269, Selected False, Rank: 962.000\n",
            "Column: 1270, Selected False, Rank: 2255.000\n",
            "Column: 1271, Selected False, Rank: 725.000\n",
            "Column: 1272, Selected False, Rank: 2037.000\n",
            "Column: 1273, Selected False, Rank: 2035.000\n",
            "Column: 1274, Selected False, Rank: 176.000\n",
            "Column: 1275, Selected False, Rank: 223.000\n",
            "Column: 1276, Selected False, Rank: 2657.000\n",
            "Column: 1277, Selected False, Rank: 697.000\n",
            "Column: 1278, Selected False, Rank: 1321.000\n",
            "Column: 1279, Selected False, Rank: 1601.000\n",
            "Column: 1280, Selected False, Rank: 2571.000\n",
            "Column: 1281, Selected False, Rank: 1529.000\n",
            "Column: 1282, Selected False, Rank: 2069.000\n",
            "Column: 1283, Selected False, Rank: 2175.000\n",
            "Column: 1284, Selected False, Rank: 2798.000\n",
            "Column: 1285, Selected False, Rank: 1727.000\n",
            "Column: 1286, Selected False, Rank: 1803.000\n",
            "Column: 1287, Selected False, Rank: 1131.000\n",
            "Column: 1288, Selected False, Rank: 1134.000\n",
            "Column: 1289, Selected False, Rank: 2396.000\n",
            "Column: 1290, Selected False, Rank: 1714.000\n",
            "Column: 1291, Selected False, Rank: 1443.000\n",
            "Column: 1292, Selected False, Rank: 776.000\n",
            "Column: 1293, Selected False, Rank: 2654.000\n",
            "Column: 1294, Selected False, Rank: 1760.000\n",
            "Column: 1295, Selected False, Rank: 1333.000\n",
            "Column: 1296, Selected False, Rank: 2550.000\n",
            "Column: 1297, Selected False, Rank: 1811.000\n",
            "Column: 1298, Selected False, Rank: 989.000\n",
            "Column: 1299, Selected False, Rank: 2038.000\n",
            "Column: 1300, Selected False, Rank: 947.000\n",
            "Column: 1301, Selected False, Rank: 1644.000\n",
            "Column: 1302, Selected False, Rank: 1931.000\n",
            "Column: 1303, Selected False, Rank: 1261.000\n",
            "Column: 1304, Selected False, Rank: 1371.000\n",
            "Column: 1305, Selected False, Rank: 1648.000\n",
            "Column: 1306, Selected False, Rank: 1220.000\n",
            "Column: 1307, Selected False, Rank: 2553.000\n",
            "Column: 1308, Selected False, Rank: 502.000\n",
            "Column: 1309, Selected False, Rank: 695.000\n",
            "Column: 1310, Selected False, Rank: 2068.000\n",
            "Column: 1311, Selected False, Rank: 1452.000\n",
            "Column: 1312, Selected False, Rank: 1673.000\n",
            "Column: 1313, Selected False, Rank: 1288.000\n",
            "Column: 1314, Selected False, Rank: 1503.000\n",
            "Column: 1315, Selected False, Rank: 552.000\n",
            "Column: 1316, Selected False, Rank: 2782.000\n",
            "Column: 1317, Selected False, Rank: 358.000\n",
            "Column: 1318, Selected False, Rank: 670.000\n",
            "Column: 1319, Selected False, Rank: 976.000\n",
            "Column: 1320, Selected False, Rank: 2259.000\n",
            "Column: 1321, Selected False, Rank: 2705.000\n",
            "Column: 1322, Selected False, Rank: 1628.000\n",
            "Column: 1323, Selected False, Rank: 2021.000\n",
            "Column: 1324, Selected False, Rank: 1550.000\n",
            "Column: 1325, Selected False, Rank: 2390.000\n",
            "Column: 1326, Selected False, Rank: 1756.000\n",
            "Column: 1327, Selected False, Rank: 1012.000\n",
            "Column: 1328, Selected False, Rank: 247.000\n",
            "Column: 1329, Selected False, Rank: 652.000\n",
            "Column: 1330, Selected False, Rank: 2609.000\n",
            "Column: 1331, Selected False, Rank: 2750.000\n",
            "Column: 1332, Selected False, Rank: 2207.000\n",
            "Column: 1333, Selected False, Rank: 546.000\n",
            "Column: 1334, Selected False, Rank: 2448.000\n",
            "Column: 1335, Selected False, Rank: 1734.000\n",
            "Column: 1336, Selected False, Rank: 2272.000\n",
            "Column: 1337, Selected False, Rank: 2482.000\n",
            "Column: 1338, Selected False, Rank: 1844.000\n",
            "Column: 1339, Selected False, Rank: 2560.000\n",
            "Column: 1340, Selected False, Rank: 151.000\n",
            "Column: 1341, Selected False, Rank: 1435.000\n",
            "Column: 1342, Selected False, Rank: 234.000\n",
            "Column: 1343, Selected False, Rank: 852.000\n",
            "Column: 1344, Selected False, Rank: 2094.000\n",
            "Column: 1345, Selected False, Rank: 774.000\n",
            "Column: 1346, Selected False, Rank: 2303.000\n",
            "Column: 1347, Selected False, Rank: 2695.000\n",
            "Column: 1348, Selected False, Rank: 1919.000\n",
            "Column: 1349, Selected False, Rank: 2197.000\n",
            "Column: 1350, Selected False, Rank: 1308.000\n",
            "Column: 1351, Selected False, Rank: 379.000\n",
            "Column: 1352, Selected False, Rank: 1081.000\n",
            "Column: 1353, Selected False, Rank: 2417.000\n",
            "Column: 1354, Selected False, Rank: 632.000\n",
            "Column: 1355, Selected False, Rank: 1295.000\n",
            "Column: 1356, Selected False, Rank: 1591.000\n",
            "Column: 1357, Selected False, Rank: 1873.000\n",
            "Column: 1358, Selected False, Rank: 1504.000\n",
            "Column: 1359, Selected False, Rank: 2027.000\n",
            "Column: 1360, Selected False, Rank: 1892.000\n",
            "Column: 1361, Selected False, Rank: 2125.000\n",
            "Column: 1362, Selected False, Rank: 1528.000\n",
            "Column: 1363, Selected False, Rank: 2660.000\n",
            "Column: 1364, Selected False, Rank: 1790.000\n",
            "Column: 1365, Selected False, Rank: 2289.000\n",
            "Column: 1366, Selected False, Rank: 315.000\n",
            "Column: 1367, Selected False, Rank: 795.000\n",
            "Column: 1368, Selected False, Rank: 788.000\n",
            "Column: 1369, Selected False, Rank: 2158.000\n",
            "Column: 1370, Selected False, Rank: 1060.000\n",
            "Column: 1371, Selected False, Rank: 494.000\n",
            "Column: 1372, Selected False, Rank: 1456.000\n",
            "Column: 1373, Selected False, Rank: 2280.000\n",
            "Column: 1374, Selected False, Rank: 1898.000\n",
            "Column: 1375, Selected False, Rank: 918.000\n",
            "Column: 1376, Selected False, Rank: 750.000\n",
            "Column: 1377, Selected False, Rank: 2589.000\n",
            "Column: 1378, Selected False, Rank: 452.000\n",
            "Column: 1379, Selected False, Rank: 500.000\n",
            "Column: 1380, Selected False, Rank: 1267.000\n",
            "Column: 1381, Selected False, Rank: 1861.000\n",
            "Column: 1382, Selected False, Rank: 2072.000\n",
            "Column: 1383, Selected False, Rank: 2687.000\n",
            "Column: 1384, Selected False, Rank: 961.000\n",
            "Column: 1385, Selected False, Rank: 1804.000\n",
            "Column: 1386, Selected False, Rank: 990.000\n",
            "Column: 1387, Selected False, Rank: 877.000\n",
            "Column: 1388, Selected False, Rank: 217.000\n",
            "Column: 1389, Selected False, Rank: 1115.000\n",
            "Column: 1390, Selected False, Rank: 2768.000\n",
            "Column: 1391, Selected False, Rank: 201.000\n",
            "Column: 1392, Selected False, Rank: 2113.000\n",
            "Column: 1393, Selected False, Rank: 1918.000\n",
            "Column: 1394, Selected False, Rank: 2009.000\n",
            "Column: 1395, Selected False, Rank: 1348.000\n",
            "Column: 1396, Selected False, Rank: 1679.000\n",
            "Column: 1397, Selected False, Rank: 1279.000\n",
            "Column: 1398, Selected False, Rank: 2716.000\n",
            "Column: 1399, Selected False, Rank: 2565.000\n",
            "Column: 1400, Selected False, Rank: 2541.000\n",
            "Column: 1401, Selected False, Rank: 203.000\n",
            "Column: 1402, Selected False, Rank: 735.000\n",
            "Column: 1403, Selected False, Rank: 2469.000\n",
            "Column: 1404, Selected False, Rank: 2638.000\n",
            "Column: 1405, Selected False, Rank: 1418.000\n",
            "Column: 1406, Selected False, Rank: 2549.000\n",
            "Column: 1407, Selected False, Rank: 1179.000\n",
            "Column: 1408, Selected False, Rank: 1506.000\n",
            "Column: 1409, Selected False, Rank: 1666.000\n",
            "Column: 1410, Selected False, Rank: 1785.000\n",
            "Column: 1411, Selected False, Rank: 734.000\n",
            "Column: 1412, Selected False, Rank: 684.000\n",
            "Column: 1413, Selected False, Rank: 2317.000\n",
            "Column: 1414, Selected False, Rank: 856.000\n",
            "Column: 1415, Selected False, Rank: 1287.000\n",
            "Column: 1416, Selected False, Rank: 1114.000\n",
            "Column: 1417, Selected False, Rank: 1073.000\n",
            "Column: 1418, Selected False, Rank: 608.000\n",
            "Column: 1419, Selected False, Rank: 2056.000\n",
            "Column: 1420, Selected False, Rank: 2446.000\n",
            "Column: 1421, Selected False, Rank: 2048.000\n",
            "Column: 1422, Selected False, Rank: 2279.000\n",
            "Column: 1423, Selected False, Rank: 1843.000\n",
            "Column: 1424, Selected False, Rank: 1416.000\n",
            "Column: 1425, Selected False, Rank: 1791.000\n",
            "Column: 1426, Selected False, Rank: 1685.000\n",
            "Column: 1427, Selected False, Rank: 1944.000\n",
            "Column: 1428, Selected False, Rank: 1487.000\n",
            "Column: 1429, Selected False, Rank: 2269.000\n",
            "Column: 1430, Selected False, Rank: 2223.000\n",
            "Column: 1431, Selected False, Rank: 2271.000\n",
            "Column: 1432, Selected False, Rank: 2596.000\n",
            "Column: 1433, Selected False, Rank: 292.000\n",
            "Column: 1434, Selected False, Rank: 2029.000\n",
            "Column: 1435, Selected False, Rank: 2497.000\n",
            "Column: 1436, Selected False, Rank: 2451.000\n",
            "Column: 1437, Selected False, Rank: 472.000\n",
            "Column: 1438, Selected False, Rank: 2517.000\n",
            "Column: 1439, Selected False, Rank: 917.000\n",
            "Column: 1440, Selected False, Rank: 2456.000\n",
            "Column: 1441, Selected False, Rank: 120.000\n",
            "Column: 1442, Selected False, Rank: 1283.000\n",
            "Column: 1443, Selected False, Rank: 1230.000\n",
            "Column: 1444, Selected False, Rank: 1634.000\n",
            "Column: 1445, Selected False, Rank: 2065.000\n",
            "Column: 1446, Selected False, Rank: 1659.000\n",
            "Column: 1447, Selected False, Rank: 680.000\n",
            "Column: 1448, Selected False, Rank: 875.000\n",
            "Column: 1449, Selected False, Rank: 773.000\n",
            "Column: 1450, Selected False, Rank: 392.000\n",
            "Column: 1451, Selected False, Rank: 758.000\n",
            "Column: 1452, Selected False, Rank: 1880.000\n",
            "Column: 1453, Selected False, Rank: 2146.000\n",
            "Column: 1454, Selected False, Rank: 1767.000\n",
            "Column: 1455, Selected False, Rank: 681.000\n",
            "Column: 1456, Selected False, Rank: 953.000\n",
            "Column: 1457, Selected False, Rank: 2757.000\n",
            "Column: 1458, Selected False, Rank: 1965.000\n",
            "Column: 1459, Selected False, Rank: 1142.000\n",
            "Column: 1460, Selected False, Rank: 1778.000\n",
            "Column: 1461, Selected False, Rank: 1708.000\n",
            "Column: 1462, Selected False, Rank: 1626.000\n",
            "Column: 1463, Selected False, Rank: 843.000\n",
            "Column: 1464, Selected False, Rank: 1676.000\n",
            "Column: 1465, Selected False, Rank: 2579.000\n",
            "Column: 1466, Selected False, Rank: 1210.000\n",
            "Column: 1467, Selected False, Rank: 266.000\n",
            "Column: 1468, Selected False, Rank: 1256.000\n",
            "Column: 1469, Selected False, Rank: 2002.000\n",
            "Column: 1470, Selected False, Rank: 1066.000\n",
            "Column: 1471, Selected False, Rank: 1285.000\n",
            "Column: 1472, Selected False, Rank: 1878.000\n",
            "Column: 1473, Selected False, Rank: 2246.000\n",
            "Column: 1474, Selected False, Rank: 272.000\n",
            "Column: 1475, Selected False, Rank: 2001.000\n",
            "Column: 1476, Selected False, Rank: 468.000\n",
            "Column: 1477, Selected False, Rank: 401.000\n",
            "Column: 1478, Selected False, Rank: 819.000\n",
            "Column: 1479, Selected False, Rank: 2651.000\n",
            "Column: 1480, Selected False, Rank: 659.000\n",
            "Column: 1481, Selected False, Rank: 1493.000\n",
            "Column: 1482, Selected False, Rank: 2287.000\n",
            "Column: 1483, Selected False, Rank: 2425.000\n",
            "Column: 1484, Selected False, Rank: 2755.000\n",
            "Column: 1485, Selected False, Rank: 377.000\n",
            "Column: 1486, Selected False, Rank: 1496.000\n",
            "Column: 1487, Selected False, Rank: 775.000\n",
            "Column: 1488, Selected False, Rank: 2359.000\n",
            "Column: 1489, Selected False, Rank: 2426.000\n",
            "Column: 1490, Selected False, Rank: 318.000\n",
            "Column: 1491, Selected False, Rank: 1388.000\n",
            "Column: 1492, Selected False, Rank: 144.000\n",
            "Column: 1493, Selected True, Rank: 1.000\n",
            "Column: 1494, Selected False, Rank: 1034.000\n",
            "Column: 1495, Selected False, Rank: 1335.000\n",
            "Column: 1496, Selected False, Rank: 2699.000\n",
            "Column: 1497, Selected False, Rank: 2248.000\n",
            "Column: 1498, Selected False, Rank: 2454.000\n",
            "Column: 1499, Selected False, Rank: 183.000\n",
            "Column: 1500, Selected False, Rank: 2513.000\n",
            "Column: 1501, Selected False, Rank: 1215.000\n",
            "Column: 1502, Selected False, Rank: 1190.000\n",
            "Column: 1503, Selected False, Rank: 297.000\n",
            "Column: 1504, Selected False, Rank: 1472.000\n",
            "Column: 1505, Selected False, Rank: 2611.000\n",
            "Column: 1506, Selected False, Rank: 1252.000\n",
            "Column: 1507, Selected False, Rank: 999.000\n",
            "Column: 1508, Selected False, Rank: 2431.000\n",
            "Column: 1509, Selected False, Rank: 1909.000\n",
            "Column: 1510, Selected False, Rank: 1312.000\n",
            "Column: 1511, Selected False, Rank: 883.000\n",
            "Column: 1512, Selected False, Rank: 164.000\n",
            "Column: 1513, Selected False, Rank: 1293.000\n",
            "Column: 1514, Selected False, Rank: 2466.000\n",
            "Column: 1515, Selected False, Rank: 2551.000\n",
            "Column: 1516, Selected False, Rank: 2053.000\n",
            "Column: 1517, Selected False, Rank: 2263.000\n",
            "Column: 1518, Selected False, Rank: 1291.000\n",
            "Column: 1519, Selected False, Rank: 619.000\n",
            "Column: 1520, Selected False, Rank: 2150.000\n",
            "Column: 1521, Selected False, Rank: 1473.000\n",
            "Column: 1522, Selected False, Rank: 759.000\n",
            "Column: 1523, Selected False, Rank: 2159.000\n",
            "Column: 1524, Selected False, Rank: 2295.000\n",
            "Column: 1525, Selected False, Rank: 474.000\n",
            "Column: 1526, Selected False, Rank: 1250.000\n",
            "Column: 1527, Selected False, Rank: 2732.000\n",
            "Column: 1528, Selected False, Rank: 2430.000\n",
            "Column: 1529, Selected False, Rank: 1410.000\n",
            "Column: 1530, Selected False, Rank: 1662.000\n",
            "Column: 1531, Selected False, Rank: 1106.000\n",
            "Column: 1532, Selected False, Rank: 694.000\n",
            "Column: 1533, Selected False, Rank: 920.000\n",
            "Column: 1534, Selected False, Rank: 1926.000\n",
            "Column: 1535, Selected False, Rank: 2249.000\n",
            "Column: 1536, Selected False, Rank: 1706.000\n",
            "Column: 1537, Selected False, Rank: 2299.000\n",
            "Column: 1538, Selected False, Rank: 2110.000\n",
            "Column: 1539, Selected False, Rank: 1310.000\n",
            "Column: 1540, Selected False, Rank: 2725.000\n",
            "Column: 1541, Selected False, Rank: 1921.000\n",
            "Column: 1542, Selected False, Rank: 1751.000\n",
            "Column: 1543, Selected False, Rank: 2251.000\n",
            "Column: 1544, Selected False, Rank: 2797.000\n",
            "Column: 1545, Selected False, Rank: 15.000\n",
            "Column: 1546, Selected False, Rank: 16.000\n",
            "Column: 1547, Selected False, Rank: 11.000\n",
            "Column: 1548, Selected False, Rank: 13.000\n",
            "Column: 1549, Selected False, Rank: 12.000\n",
            "Column: 1550, Selected False, Rank: 14.000\n",
            "Column: 1551, Selected False, Rank: 95.000\n",
            "Column: 1552, Selected False, Rank: 100.000\n",
            "Column: 1553, Selected False, Rank: 48.000\n",
            "Column: 1554, Selected False, Rank: 45.000\n",
            "Column: 1555, Selected False, Rank: 50.000\n",
            "Column: 1556, Selected False, Rank: 55.000\n",
            "Column: 1557, Selected False, Rank: 1900.000\n",
            "Column: 1558, Selected False, Rank: 1597.000\n",
            "Column: 1559, Selected False, Rank: 1522.000\n",
            "Column: 1560, Selected False, Rank: 688.000\n",
            "Column: 1561, Selected False, Rank: 516.000\n",
            "Column: 1562, Selected False, Rank: 259.000\n",
            "Column: 1563, Selected False, Rank: 2680.000\n",
            "Column: 1564, Selected False, Rank: 1328.000\n",
            "Column: 1565, Selected False, Rank: 1255.000\n",
            "Column: 1566, Selected False, Rank: 1631.000\n",
            "Column: 1567, Selected False, Rank: 2245.000\n",
            "Column: 1568, Selected False, Rank: 2478.000\n",
            "Column: 1569, Selected False, Rank: 2464.000\n",
            "Column: 1570, Selected False, Rank: 551.000\n",
            "Column: 1571, Selected False, Rank: 1508.000\n",
            "Column: 1572, Selected False, Rank: 2119.000\n",
            "Column: 1573, Selected False, Rank: 561.000\n",
            "Column: 1574, Selected False, Rank: 394.000\n",
            "Column: 1575, Selected False, Rank: 2412.000\n",
            "Column: 1576, Selected False, Rank: 642.000\n",
            "Column: 1577, Selected False, Rank: 982.000\n",
            "Column: 1578, Selected False, Rank: 2.000\n",
            "Column: 1579, Selected False, Rank: 2106.000\n",
            "Column: 1580, Selected False, Rank: 485.000\n",
            "Column: 1581, Selected False, Rank: 1020.000\n",
            "Column: 1582, Selected False, Rank: 1146.000\n",
            "Column: 1583, Selected False, Rank: 2593.000\n",
            "Column: 1584, Selected False, Rank: 662.000\n",
            "Column: 1585, Selected False, Rank: 1978.000\n",
            "Column: 1586, Selected False, Rank: 2733.000\n",
            "Column: 1587, Selected False, Rank: 2514.000\n",
            "Column: 1588, Selected False, Rank: 490.000\n",
            "Column: 1589, Selected False, Rank: 2228.000\n",
            "Column: 1590, Selected False, Rank: 2308.000\n",
            "Column: 1591, Selected False, Rank: 2480.000\n",
            "Column: 1592, Selected False, Rank: 968.000\n",
            "Column: 1593, Selected False, Rank: 2327.000\n",
            "Column: 1594, Selected False, Rank: 1084.000\n",
            "Column: 1595, Selected False, Rank: 385.000\n",
            "Column: 1596, Selected False, Rank: 513.000\n",
            "Column: 1597, Selected False, Rank: 1872.000\n",
            "Column: 1598, Selected False, Rank: 736.000\n",
            "Column: 1599, Selected False, Rank: 2504.000\n",
            "Column: 1600, Selected False, Rank: 889.000\n",
            "Column: 1601, Selected False, Rank: 2653.000\n",
            "Column: 1602, Selected False, Rank: 350.000\n",
            "Column: 1603, Selected False, Rank: 2712.000\n",
            "Column: 1604, Selected False, Rank: 949.000\n",
            "Column: 1605, Selected False, Rank: 1700.000\n",
            "Column: 1606, Selected False, Rank: 1266.000\n",
            "Column: 1607, Selected False, Rank: 596.000\n",
            "Column: 1608, Selected False, Rank: 1082.000\n",
            "Column: 1609, Selected False, Rank: 2566.000\n",
            "Column: 1610, Selected False, Rank: 805.000\n",
            "Column: 1611, Selected False, Rank: 1029.000\n",
            "Column: 1612, Selected False, Rank: 2487.000\n",
            "Column: 1613, Selected False, Rank: 984.000\n",
            "Column: 1614, Selected False, Rank: 2181.000\n",
            "Column: 1615, Selected False, Rank: 656.000\n",
            "Column: 1616, Selected False, Rank: 1467.000\n",
            "Column: 1617, Selected False, Rank: 933.000\n",
            "Column: 1618, Selected False, Rank: 2369.000\n",
            "Column: 1619, Selected False, Rank: 824.000\n",
            "Column: 1620, Selected False, Rank: 1437.000\n",
            "Column: 1621, Selected False, Rank: 501.000\n",
            "Column: 1622, Selected False, Rank: 1975.000\n",
            "Column: 1623, Selected False, Rank: 1893.000\n",
            "Column: 1624, Selected False, Rank: 1466.000\n",
            "Column: 1625, Selected False, Rank: 1911.000\n",
            "Column: 1626, Selected False, Rank: 2357.000\n",
            "Column: 1627, Selected False, Rank: 248.000\n",
            "Column: 1628, Selected False, Rank: 1344.000\n",
            "Column: 1629, Selected False, Rank: 463.000\n",
            "Column: 1630, Selected False, Rank: 444.000\n",
            "Column: 1631, Selected False, Rank: 407.000\n",
            "Column: 1632, Selected False, Rank: 562.000\n",
            "Column: 1633, Selected False, Rank: 2389.000\n",
            "Column: 1634, Selected False, Rank: 893.000\n",
            "Column: 1635, Selected False, Rank: 439.000\n",
            "Column: 1636, Selected False, Rank: 2243.000\n",
            "Column: 1637, Selected False, Rank: 1065.000\n",
            "Column: 1638, Selected False, Rank: 2598.000\n",
            "Column: 1639, Selected False, Rank: 190.000\n",
            "Column: 1640, Selected False, Rank: 1842.000\n",
            "Column: 1641, Selected False, Rank: 2763.000\n",
            "Column: 1642, Selected False, Rank: 110.000\n",
            "Column: 1643, Selected False, Rank: 124.000\n",
            "Column: 1644, Selected False, Rank: 2721.000\n",
            "Column: 1645, Selected False, Rank: 2258.000\n",
            "Column: 1646, Selected False, Rank: 1495.000\n",
            "Column: 1647, Selected False, Rank: 2348.000\n",
            "Column: 1648, Selected False, Rank: 2034.000\n",
            "Column: 1649, Selected False, Rank: 746.000\n",
            "Column: 1650, Selected False, Rank: 678.000\n",
            "Column: 1651, Selected False, Rank: 1324.000\n",
            "Column: 1652, Selected False, Rank: 491.000\n",
            "Column: 1653, Selected False, Rank: 2054.000\n",
            "Column: 1654, Selected False, Rank: 158.000\n",
            "Column: 1655, Selected False, Rank: 2282.000\n",
            "Column: 1656, Selected False, Rank: 40.000\n",
            "Column: 1657, Selected False, Rank: 2386.000\n",
            "Column: 1658, Selected False, Rank: 1245.000\n",
            "Column: 1659, Selected False, Rank: 320.000\n",
            "Column: 1660, Selected False, Rank: 380.000\n",
            "Column: 1661, Selected False, Rank: 2310.000\n",
            "Column: 1662, Selected False, Rank: 649.000\n",
            "Column: 1663, Selected False, Rank: 2157.000\n",
            "Column: 1664, Selected False, Rank: 2276.000\n",
            "Column: 1665, Selected False, Rank: 1719.000\n",
            "Column: 1666, Selected False, Rank: 1838.000\n",
            "Column: 1667, Selected False, Rank: 1913.000\n",
            "Column: 1668, Selected False, Rank: 1717.000\n",
            "Column: 1669, Selected False, Rank: 1311.000\n",
            "Column: 1670, Selected False, Rank: 2117.000\n",
            "Column: 1671, Selected False, Rank: 462.000\n",
            "Column: 1672, Selected False, Rank: 1712.000\n",
            "Column: 1673, Selected False, Rank: 730.000\n",
            "Column: 1674, Selected False, Rank: 357.000\n",
            "Column: 1675, Selected False, Rank: 2361.000\n",
            "Column: 1676, Selected False, Rank: 2696.000\n",
            "Column: 1677, Selected False, Rank: 2115.000\n",
            "Column: 1678, Selected False, Rank: 2395.000\n",
            "Column: 1679, Selected False, Rank: 1392.000\n",
            "Column: 1680, Selected False, Rank: 2234.000\n",
            "Column: 1681, Selected False, Rank: 211.000\n",
            "Column: 1682, Selected False, Rank: 73.000\n",
            "Column: 1683, Selected False, Rank: 963.000\n",
            "Column: 1684, Selected False, Rank: 859.000\n",
            "Column: 1685, Selected False, Rank: 129.000\n",
            "Column: 1686, Selected False, Rank: 2306.000\n",
            "Column: 1687, Selected False, Rank: 60.000\n",
            "Column: 1688, Selected False, Rank: 254.000\n",
            "Column: 1689, Selected False, Rank: 650.000\n",
            "Column: 1690, Selected False, Rank: 311.000\n",
            "Column: 1691, Selected False, Rank: 125.000\n",
            "Column: 1692, Selected False, Rank: 1301.000\n",
            "Column: 1693, Selected False, Rank: 178.000\n",
            "Column: 1694, Selected False, Rank: 230.000\n",
            "Column: 1695, Selected False, Rank: 1474.000\n",
            "Column: 1696, Selected False, Rank: 661.000\n",
            "Column: 1697, Selected False, Rank: 1589.000\n",
            "Column: 1698, Selected False, Rank: 2771.000\n",
            "Column: 1699, Selected False, Rank: 1222.000\n",
            "Column: 1700, Selected False, Rank: 1556.000\n",
            "Column: 1701, Selected False, Rank: 2578.000\n",
            "Column: 1702, Selected False, Rank: 905.000\n",
            "Column: 1703, Selected False, Rank: 1162.000\n",
            "Column: 1704, Selected False, Rank: 690.000\n",
            "Column: 1705, Selected False, Rank: 1097.000\n",
            "Column: 1706, Selected False, Rank: 579.000\n",
            "Column: 1707, Selected False, Rank: 820.000\n",
            "Column: 1708, Selected False, Rank: 146.000\n",
            "Column: 1709, Selected False, Rank: 629.000\n",
            "Column: 1710, Selected False, Rank: 422.000\n",
            "Column: 1711, Selected False, Rank: 530.000\n",
            "Column: 1712, Selected False, Rank: 130.000\n",
            "Column: 1713, Selected False, Rank: 5.000\n",
            "Column: 1714, Selected False, Rank: 410.000\n",
            "Column: 1715, Selected False, Rank: 1062.000\n",
            "Column: 1716, Selected False, Rank: 1228.000\n",
            "Column: 1717, Selected False, Rank: 570.000\n",
            "Column: 1718, Selected False, Rank: 564.000\n",
            "Column: 1719, Selected False, Rank: 1681.000\n",
            "Column: 1720, Selected False, Rank: 2415.000\n",
            "Column: 1721, Selected False, Rank: 1401.000\n",
            "Column: 1722, Selected False, Rank: 2626.000\n",
            "Column: 1723, Selected False, Rank: 2614.000\n",
            "Column: 1724, Selected False, Rank: 411.000\n",
            "Column: 1725, Selected False, Rank: 1645.000\n",
            "Column: 1726, Selected False, Rank: 1113.000\n",
            "Column: 1727, Selected False, Rank: 1061.000\n",
            "Column: 1728, Selected False, Rank: 454.000\n",
            "Column: 1729, Selected False, Rank: 872.000\n",
            "Column: 1730, Selected False, Rank: 779.000\n",
            "Column: 1731, Selected False, Rank: 492.000\n",
            "Column: 1732, Selected False, Rank: 2563.000\n",
            "Column: 1733, Selected False, Rank: 523.000\n",
            "Column: 1734, Selected False, Rank: 966.000\n",
            "Column: 1735, Selected False, Rank: 1203.000\n",
            "Column: 1736, Selected False, Rank: 1362.000\n",
            "Column: 1737, Selected False, Rank: 72.000\n",
            "Column: 1738, Selected False, Rank: 945.000\n",
            "Column: 1739, Selected False, Rank: 1868.000\n",
            "Column: 1740, Selected False, Rank: 1485.000\n",
            "Column: 1741, Selected False, Rank: 2174.000\n",
            "Column: 1742, Selected False, Rank: 2521.000\n",
            "Column: 1743, Selected False, Rank: 1039.000\n",
            "Column: 1744, Selected False, Rank: 940.000\n",
            "Column: 1745, Selected False, Rank: 2445.000\n",
            "Column: 1746, Selected False, Rank: 1903.000\n",
            "Column: 1747, Selected False, Rank: 1884.000\n",
            "Column: 1748, Selected False, Rank: 2095.000\n",
            "Column: 1749, Selected False, Rank: 2498.000\n",
            "Column: 1750, Selected False, Rank: 1049.000\n",
            "Column: 1751, Selected False, Rank: 2093.000\n",
            "Column: 1752, Selected False, Rank: 1006.000\n",
            "Column: 1753, Selected False, Rank: 300.000\n",
            "Column: 1754, Selected False, Rank: 1026.000\n",
            "Column: 1755, Selected False, Rank: 1692.000\n",
            "Column: 1756, Selected False, Rank: 2781.000\n",
            "Column: 1757, Selected False, Rank: 363.000\n",
            "Column: 1758, Selected False, Rank: 2686.000\n",
            "Column: 1759, Selected False, Rank: 2194.000\n",
            "Column: 1760, Selected False, Rank: 922.000\n",
            "Column: 1761, Selected False, Rank: 600.000\n",
            "Column: 1762, Selected False, Rank: 526.000\n",
            "Column: 1763, Selected False, Rank: 1517.000\n",
            "Column: 1764, Selected False, Rank: 295.000\n",
            "Column: 1765, Selected False, Rank: 1231.000\n",
            "Column: 1766, Selected False, Rank: 1461.000\n",
            "Column: 1767, Selected False, Rank: 2416.000\n",
            "Column: 1768, Selected False, Rank: 1282.000\n",
            "Column: 1769, Selected False, Rank: 698.000\n",
            "Column: 1770, Selected False, Rank: 447.000\n",
            "Column: 1771, Selected False, Rank: 449.000\n",
            "Column: 1772, Selected False, Rank: 992.000\n",
            "Column: 1773, Selected False, Rank: 909.000\n",
            "Column: 1774, Selected False, Rank: 2233.000\n",
            "Column: 1775, Selected False, Rank: 1303.000\n",
            "Column: 1776, Selected False, Rank: 1475.000\n",
            "Column: 1777, Selected False, Rank: 2776.000\n",
            "Column: 1778, Selected False, Rank: 705.000\n",
            "Column: 1779, Selected False, Rank: 2139.000\n",
            "Column: 1780, Selected False, Rank: 486.000\n",
            "Column: 1781, Selected False, Rank: 408.000\n",
            "Column: 1782, Selected False, Rank: 544.000\n",
            "Column: 1783, Selected False, Rank: 2318.000\n",
            "Column: 1784, Selected False, Rank: 1656.000\n",
            "Column: 1785, Selected False, Rank: 1618.000\n",
            "Column: 1786, Selected False, Rank: 1154.000\n",
            "Column: 1787, Selected False, Rank: 1678.000\n",
            "Column: 1788, Selected False, Rank: 2118.000\n",
            "Column: 1789, Selected False, Rank: 587.000\n",
            "Column: 1790, Selected False, Rank: 2060.000\n",
            "Column: 1791, Selected False, Rank: 1251.000\n",
            "Column: 1792, Selected False, Rank: 1041.000\n",
            "Column: 1793, Selected False, Rank: 2030.000\n",
            "Column: 1794, Selected False, Rank: 710.000\n",
            "Column: 1795, Selected False, Rank: 2528.000\n",
            "Column: 1796, Selected False, Rank: 356.000\n",
            "Column: 1797, Selected False, Rank: 2774.000\n",
            "Column: 1798, Selected False, Rank: 2644.000\n",
            "Column: 1799, Selected False, Rank: 545.000\n",
            "Column: 1800, Selected False, Rank: 1270.000\n",
            "Column: 1801, Selected False, Rank: 2392.000\n",
            "Column: 1802, Selected False, Rank: 484.000\n",
            "Column: 1803, Selected False, Rank: 1491.000\n",
            "Column: 1804, Selected False, Rank: 1837.000\n",
            "Column: 1805, Selected False, Rank: 2630.000\n",
            "Column: 1806, Selected False, Rank: 1776.000\n",
            "Column: 1807, Selected False, Rank: 811.000\n",
            "Column: 1808, Selected False, Rank: 2201.000\n",
            "Column: 1809, Selected False, Rank: 1156.000\n",
            "Column: 1810, Selected False, Rank: 1674.000\n",
            "Column: 1811, Selected False, Rank: 628.000\n",
            "Column: 1812, Selected False, Rank: 2546.000\n",
            "Column: 1813, Selected False, Rank: 880.000\n",
            "Column: 1814, Selected False, Rank: 94.000\n",
            "Column: 1815, Selected False, Rank: 1948.000\n",
            "Column: 1816, Selected False, Rank: 1758.000\n",
            "Column: 1817, Selected False, Rank: 1355.000\n",
            "Column: 1818, Selected False, Rank: 2420.000\n",
            "Column: 1819, Selected False, Rank: 574.000\n",
            "Column: 1820, Selected False, Rank: 1171.000\n",
            "Column: 1821, Selected False, Rank: 1403.000\n",
            "Column: 1822, Selected False, Rank: 330.000\n",
            "Column: 1823, Selected False, Rank: 2452.000\n",
            "Column: 1824, Selected False, Rank: 739.000\n",
            "Column: 1825, Selected False, Rank: 1180.000\n",
            "Column: 1826, Selected False, Rank: 1351.000\n",
            "Column: 1827, Selected False, Rank: 441.000\n",
            "Column: 1828, Selected False, Rank: 1037.000\n",
            "Column: 1829, Selected False, Rank: 331.000\n",
            "Column: 1830, Selected False, Rank: 78.000\n",
            "Column: 1831, Selected False, Rank: 1432.000\n",
            "Column: 1832, Selected False, Rank: 245.000\n",
            "Column: 1833, Selected False, Rank: 1144.000\n",
            "Column: 1834, Selected False, Rank: 555.000\n",
            "Column: 1835, Selected False, Rank: 386.000\n",
            "Column: 1836, Selected False, Rank: 1969.000\n",
            "Column: 1837, Selected False, Rank: 98.000\n",
            "Column: 1838, Selected False, Rank: 797.000\n",
            "Column: 1839, Selected False, Rank: 1183.000\n",
            "Column: 1840, Selected False, Rank: 1439.000\n",
            "Column: 1841, Selected False, Rank: 543.000\n",
            "Column: 1842, Selected False, Rank: 2670.000\n",
            "Column: 1843, Selected False, Rank: 1331.000\n",
            "Column: 1844, Selected False, Rank: 1259.000\n",
            "Column: 1845, Selected False, Rank: 763.000\n",
            "Column: 1846, Selected False, Rank: 827.000\n",
            "Column: 1847, Selected False, Rank: 1637.000\n",
            "Column: 1848, Selected False, Rank: 360.000\n",
            "Column: 1849, Selected False, Rank: 1024.000\n",
            "Column: 1850, Selected False, Rank: 429.000\n",
            "Column: 1851, Selected False, Rank: 194.000\n",
            "Column: 1852, Selected False, Rank: 2133.000\n",
            "Column: 1853, Selected False, Rank: 1888.000\n",
            "Column: 1854, Selected False, Rank: 1218.000\n",
            "Column: 1855, Selected False, Rank: 1536.000\n",
            "Column: 1856, Selected False, Rank: 202.000\n",
            "Column: 1857, Selected False, Rank: 2692.000\n",
            "Column: 1858, Selected False, Rank: 2779.000\n",
            "Column: 1859, Selected False, Rank: 1544.000\n",
            "Column: 1860, Selected False, Rank: 305.000\n",
            "Column: 1861, Selected False, Rank: 1380.000\n",
            "Column: 1862, Selected False, Rank: 1810.000\n",
            "Column: 1863, Selected False, Rank: 882.000\n",
            "Column: 1864, Selected False, Rank: 504.000\n",
            "Column: 1865, Selected False, Rank: 1157.000\n",
            "Column: 1866, Selected False, Rank: 648.000\n",
            "Column: 1867, Selected False, Rank: 548.000\n",
            "Column: 1868, Selected False, Rank: 448.000\n",
            "Column: 1869, Selected False, Rank: 641.000\n",
            "Column: 1870, Selected False, Rank: 748.000\n",
            "Column: 1871, Selected False, Rank: 2107.000\n",
            "Column: 1872, Selected False, Rank: 166.000\n",
            "Column: 1873, Selected False, Rank: 873.000\n",
            "Column: 1874, Selected False, Rank: 863.000\n",
            "Column: 1875, Selected False, Rank: 1956.000\n",
            "Column: 1876, Selected False, Rank: 186.000\n",
            "Column: 1877, Selected False, Rank: 803.000\n",
            "Column: 1878, Selected False, Rank: 1377.000\n",
            "Column: 1879, Selected False, Rank: 559.000\n",
            "Column: 1880, Selected False, Rank: 2438.000\n",
            "Column: 1881, Selected False, Rank: 97.000\n",
            "Column: 1882, Selected False, Rank: 1740.000\n",
            "Column: 1883, Selected False, Rank: 2183.000\n",
            "Column: 1884, Selected False, Rank: 2097.000\n",
            "Column: 1885, Selected False, Rank: 796.000\n",
            "Column: 1886, Selected False, Rank: 2176.000\n",
            "Column: 1887, Selected False, Rank: 465.000\n",
            "Column: 1888, Selected False, Rank: 787.000\n",
            "Column: 1889, Selected False, Rank: 1548.000\n",
            "Column: 1890, Selected False, Rank: 1983.000\n",
            "Column: 1891, Selected False, Rank: 170.000\n",
            "Column: 1892, Selected False, Rank: 2496.000\n",
            "Column: 1893, Selected False, Rank: 2188.000\n",
            "Column: 1894, Selected False, Rank: 21.000\n",
            "Column: 1895, Selected False, Rank: 2652.000\n",
            "Column: 1896, Selected False, Rank: 2222.000\n",
            "Column: 1897, Selected False, Rank: 617.000\n",
            "Column: 1898, Selected False, Rank: 1378.000\n",
            "Column: 1899, Selected False, Rank: 2461.000\n",
            "Column: 1900, Selected False, Rank: 603.000\n",
            "Column: 1901, Selected False, Rank: 2623.000\n",
            "Column: 1902, Selected False, Rank: 2529.000\n",
            "Column: 1903, Selected False, Rank: 2662.000\n",
            "Column: 1904, Selected False, Rank: 1557.000\n",
            "Column: 1905, Selected False, Rank: 2698.000\n",
            "Column: 1906, Selected False, Rank: 1998.000\n",
            "Column: 1907, Selected False, Rank: 1004.000\n",
            "Column: 1908, Selected False, Rank: 2724.000\n",
            "Column: 1909, Selected False, Rank: 1442.000\n",
            "Column: 1910, Selected False, Rank: 914.000\n",
            "Column: 1911, Selected False, Rank: 1319.000\n",
            "Column: 1912, Selected False, Rank: 2525.000\n",
            "Column: 1913, Selected False, Rank: 1624.000\n",
            "Column: 1914, Selected False, Rank: 1841.000\n",
            "Column: 1915, Selected False, Rank: 2635.000\n",
            "Column: 1916, Selected False, Rank: 477.000\n",
            "Column: 1917, Selected False, Rank: 1971.000\n",
            "Column: 1918, Selected False, Rank: 1895.000\n",
            "Column: 1919, Selected False, Rank: 274.000\n",
            "Column: 1920, Selected False, Rank: 2423.000\n",
            "Column: 1921, Selected False, Rank: 1974.000\n",
            "Column: 1922, Selected False, Rank: 155.000\n",
            "Column: 1923, Selected False, Rank: 140.000\n",
            "Column: 1924, Selected False, Rank: 2673.000\n",
            "Column: 1925, Selected False, Rank: 2339.000\n",
            "Column: 1926, Selected False, Rank: 1615.000\n",
            "Column: 1927, Selected False, Rank: 1395.000\n",
            "Column: 1928, Selected False, Rank: 312.000\n",
            "Column: 1929, Selected False, Rank: 1959.000\n",
            "Column: 1930, Selected False, Rank: 1907.000\n",
            "Column: 1931, Selected False, Rank: 834.000\n",
            "Column: 1932, Selected False, Rank: 606.000\n",
            "Column: 1933, Selected False, Rank: 2408.000\n",
            "Column: 1934, Selected False, Rank: 1962.000\n",
            "Column: 1935, Selected False, Rank: 2083.000\n",
            "Column: 1936, Selected False, Rank: 2217.000\n",
            "Column: 1937, Selected False, Rank: 907.000\n",
            "Column: 1938, Selected False, Rank: 344.000\n",
            "Column: 1939, Selected False, Rank: 792.000\n",
            "Column: 1940, Selected False, Rank: 127.000\n",
            "Column: 1941, Selected False, Rank: 2356.000\n",
            "Column: 1942, Selected False, Rank: 1652.000\n",
            "Column: 1943, Selected False, Rank: 473.000\n",
            "Column: 1944, Selected False, Rank: 62.000\n",
            "Column: 1945, Selected False, Rank: 1782.000\n",
            "Column: 1946, Selected False, Rank: 2400.000\n",
            "Column: 1947, Selected False, Rank: 369.000\n",
            "Column: 1948, Selected False, Rank: 571.000\n",
            "Column: 1949, Selected False, Rank: 1314.000\n",
            "Column: 1950, Selected False, Rank: 2196.000\n",
            "Column: 1951, Selected False, Rank: 2612.000\n",
            "Column: 1952, Selected False, Rank: 1489.000\n",
            "Column: 1953, Selected False, Rank: 2535.000\n",
            "Column: 1954, Selected False, Rank: 2538.000\n",
            "Column: 1955, Selected False, Rank: 1737.000\n",
            "Column: 1956, Selected False, Rank: 2665.000\n",
            "Column: 1957, Selected False, Rank: 1299.000\n",
            "Column: 1958, Selected False, Rank: 2640.000\n",
            "Column: 1959, Selected False, Rank: 1552.000\n",
            "Column: 1960, Selected False, Rank: 1195.000\n",
            "Column: 1961, Selected False, Rank: 2737.000\n",
            "Column: 1962, Selected False, Rank: 143.000\n",
            "Column: 1963, Selected False, Rank: 2576.000\n",
            "Column: 1964, Selected False, Rank: 560.000\n",
            "Column: 1965, Selected False, Rank: 2403.000\n",
            "Column: 1966, Selected False, Rank: 2302.000\n",
            "Column: 1967, Selected False, Rank: 1105.000\n",
            "Column: 1968, Selected False, Rank: 932.000\n",
            "Column: 1969, Selected False, Rank: 36.000\n",
            "Column: 1970, Selected False, Rank: 580.000\n",
            "Column: 1971, Selected False, Rank: 1481.000\n",
            "Column: 1972, Selected False, Rank: 1824.000\n",
            "Column: 1973, Selected False, Rank: 1521.000\n",
            "Column: 1974, Selected False, Rank: 702.000\n",
            "Column: 1975, Selected False, Rank: 2474.000\n",
            "Column: 1976, Selected False, Rank: 192.000\n",
            "Column: 1977, Selected False, Rank: 199.000\n",
            "Column: 1978, Selected False, Rank: 2331.000\n",
            "Column: 1979, Selected False, Rank: 2270.000\n",
            "Column: 1980, Selected False, Rank: 238.000\n",
            "Column: 1981, Selected False, Rank: 1680.000\n",
            "Column: 1982, Selected False, Rank: 180.000\n",
            "Column: 1983, Selected False, Rank: 2422.000\n",
            "Column: 1984, Selected False, Rank: 956.000\n",
            "Column: 1985, Selected False, Rank: 850.000\n",
            "Column: 1986, Selected False, Rank: 2142.000\n",
            "Column: 1987, Selected False, Rank: 2709.000\n",
            "Column: 1988, Selected False, Rank: 1569.000\n",
            "Column: 1989, Selected False, Rank: 1346.000\n",
            "Column: 1990, Selected False, Rank: 1786.000\n",
            "Column: 1991, Selected False, Rank: 65.000\n",
            "Column: 1992, Selected False, Rank: 134.000\n",
            "Column: 1993, Selected False, Rank: 1642.000\n",
            "Column: 1994, Selected False, Rank: 594.000\n",
            "Column: 1995, Selected False, Rank: 2751.000\n",
            "Column: 1996, Selected False, Rank: 912.000\n",
            "Column: 1997, Selected False, Rank: 1858.000\n",
            "Column: 1998, Selected False, Rank: 1870.000\n",
            "Column: 1999, Selected False, Rank: 104.000\n",
            "Column: 2000, Selected False, Rank: 1384.000\n",
            "Column: 2001, Selected False, Rank: 2155.000\n",
            "Column: 2002, Selected False, Rank: 493.000\n",
            "Column: 2003, Selected False, Rank: 283.000\n",
            "Column: 2004, Selected False, Rank: 1104.000\n",
            "Column: 2005, Selected False, Rank: 2449.000\n",
            "Column: 2006, Selected False, Rank: 1869.000\n",
            "Column: 2007, Selected False, Rank: 1511.000\n",
            "Column: 2008, Selected False, Rank: 534.000\n",
            "Column: 2009, Selected False, Rank: 983.000\n",
            "Column: 2010, Selected False, Rank: 172.000\n",
            "Column: 2011, Selected False, Rank: 1690.000\n",
            "Column: 2012, Selected False, Rank: 1916.000\n",
            "Column: 2013, Selected False, Rank: 2581.000\n",
            "Column: 2014, Selected False, Rank: 2545.000\n",
            "Column: 2015, Selected False, Rank: 1596.000\n",
            "Column: 2016, Selected False, Rank: 2105.000\n",
            "Column: 2017, Selected False, Rank: 524.000\n",
            "Column: 2018, Selected False, Rank: 2494.000\n",
            "Column: 2019, Selected False, Rank: 959.000\n",
            "Column: 2020, Selected False, Rank: 2123.000\n",
            "Column: 2021, Selected False, Rank: 1584.000\n",
            "Column: 2022, Selected False, Rank: 2347.000\n",
            "Column: 2023, Selected False, Rank: 1661.000\n",
            "Column: 2024, Selected False, Rank: 1067.000\n",
            "Column: 2025, Selected False, Rank: 645.000\n",
            "Column: 2026, Selected False, Rank: 214.000\n",
            "Column: 2027, Selected False, Rank: 614.000\n",
            "Column: 2028, Selected False, Rank: 258.000\n",
            "Column: 2029, Selected False, Rank: 1501.000\n",
            "Column: 2030, Selected False, Rank: 665.000\n",
            "Column: 2031, Selected False, Rank: 996.000\n",
            "Column: 2032, Selected False, Rank: 195.000\n",
            "Column: 2033, Selected False, Rank: 644.000\n",
            "Column: 2034, Selected False, Rank: 393.000\n",
            "Column: 2035, Selected False, Rank: 2747.000\n",
            "Column: 2036, Selected False, Rank: 2163.000\n",
            "Column: 2037, Selected False, Rank: 347.000\n",
            "Column: 2038, Selected False, Rank: 337.000\n",
            "Column: 2039, Selected False, Rank: 2247.000\n",
            "Column: 2040, Selected False, Rank: 573.000\n",
            "Column: 2041, Selected False, Rank: 367.000\n",
            "Column: 2042, Selected False, Rank: 2700.000\n",
            "Column: 2043, Selected False, Rank: 488.000\n",
            "Column: 2044, Selected False, Rank: 409.000\n",
            "Column: 2045, Selected False, Rank: 639.000\n",
            "Column: 2046, Selected False, Rank: 1458.000\n",
            "Column: 2047, Selected False, Rank: 1109.000\n",
            "Column: 2048, Selected False, Rank: 1612.000\n",
            "Column: 2049, Selected False, Rank: 679.000\n",
            "Column: 2050, Selected False, Rank: 433.000\n",
            "Column: 2051, Selected False, Rank: 890.000\n",
            "Column: 2052, Selected False, Rank: 256.000\n",
            "Column: 2053, Selected False, Rank: 1510.000\n",
            "Column: 2054, Selected False, Rank: 1454.000\n",
            "Column: 2055, Selected False, Rank: 2391.000\n",
            "Column: 2056, Selected False, Rank: 1816.000\n",
            "Column: 2057, Selected False, Rank: 2727.000\n",
            "Column: 2058, Selected False, Rank: 2476.000\n",
            "Column: 2059, Selected False, Rank: 406.000\n",
            "Column: 2060, Selected False, Rank: 2012.000\n",
            "Column: 2061, Selected False, Rank: 1429.000\n",
            "Column: 2062, Selected False, Rank: 1076.000\n",
            "Column: 2063, Selected False, Rank: 2717.000\n",
            "Column: 2064, Selected False, Rank: 630.000\n",
            "Column: 2065, Selected False, Rank: 1924.000\n",
            "Column: 2066, Selected False, Rank: 1699.000\n",
            "Column: 2067, Selected False, Rank: 1075.000\n",
            "Column: 2068, Selected False, Rank: 487.000\n",
            "Column: 2069, Selected False, Rank: 789.000\n",
            "Column: 2070, Selected False, Rank: 651.000\n",
            "Column: 2071, Selected False, Rank: 2136.000\n",
            "Column: 2072, Selected False, Rank: 1748.000\n",
            "Column: 2073, Selected False, Rank: 242.000\n",
            "Column: 2074, Selected False, Rank: 107.000\n",
            "Column: 2075, Selected False, Rank: 658.000\n",
            "Column: 2076, Selected False, Rank: 654.000\n",
            "Column: 2077, Selected False, Rank: 1068.000\n",
            "Column: 2078, Selected False, Rank: 427.000\n",
            "Column: 2079, Selected False, Rank: 437.000\n",
            "Column: 2080, Selected False, Rank: 975.000\n",
            "Column: 2081, Selected False, Rank: 325.000\n",
            "Column: 2082, Selected False, Rank: 726.000\n",
            "Column: 2083, Selected False, Rank: 2706.000\n",
            "Column: 2084, Selected False, Rank: 2489.000\n",
            "Column: 2085, Selected False, Rank: 1332.000\n",
            "Column: 2086, Selected False, Rank: 261.000\n",
            "Column: 2087, Selected False, Rank: 442.000\n",
            "Column: 2088, Selected False, Rank: 2532.000\n",
            "Column: 2089, Selected False, Rank: 1447.000\n",
            "Column: 2090, Selected False, Rank: 1305.000\n",
            "Column: 2091, Selected False, Rank: 2407.000\n",
            "Column: 2092, Selected False, Rank: 828.000\n",
            "Column: 2093, Selected False, Rank: 2646.000\n",
            "Column: 2094, Selected False, Rank: 1149.000\n",
            "Column: 2095, Selected False, Rank: 1009.000\n",
            "Column: 2096, Selected False, Rank: 313.000\n",
            "Column: 2097, Selected False, Rank: 653.000\n",
            "Column: 2098, Selected False, Rank: 576.000\n",
            "Column: 2099, Selected False, Rank: 64.000\n",
            "Column: 2100, Selected False, Rank: 836.000\n",
            "Column: 2101, Selected False, Rank: 270.000\n",
            "Column: 2102, Selected False, Rank: 162.000\n",
            "Column: 2103, Selected False, Rank: 2387.000\n",
            "Column: 2104, Selected False, Rank: 398.000\n",
            "Column: 2105, Selected False, Rank: 2796.000\n",
            "Column: 2106, Selected False, Rank: 2786.000\n",
            "Column: 2107, Selected False, Rank: 2237.000\n",
            "Column: 2108, Selected False, Rank: 951.000\n",
            "Column: 2109, Selected False, Rank: 1532.000\n",
            "Column: 2110, Selected False, Rank: 215.000\n",
            "Column: 2111, Selected False, Rank: 225.000\n",
            "Column: 2112, Selected False, Rank: 693.000\n",
            "Column: 2113, Selected False, Rank: 277.000\n",
            "Column: 2114, Selected False, Rank: 930.000\n",
            "Column: 2115, Selected False, Rank: 2760.000\n",
            "Column: 2116, Selected False, Rank: 1345.000\n",
            "Column: 2117, Selected False, Rank: 1559.000\n",
            "Column: 2118, Selected False, Rank: 1836.000\n",
            "Column: 2119, Selected False, Rank: 1102.000\n",
            "Column: 2120, Selected False, Rank: 1994.000\n",
            "Column: 2121, Selected False, Rank: 2338.000\n",
            "Column: 2122, Selected False, Rank: 1943.000\n",
            "Column: 2123, Selected False, Rank: 718.000\n",
            "Column: 2124, Selected False, Rank: 995.000\n",
            "Column: 2125, Selected False, Rank: 174.000\n",
            "Column: 2126, Selected False, Rank: 1829.000\n",
            "Column: 2127, Selected False, Rank: 2134.000\n",
            "Column: 2128, Selected False, Rank: 1702.000\n",
            "Column: 2129, Selected False, Rank: 2322.000\n",
            "Column: 2130, Selected False, Rank: 1233.000\n",
            "Column: 2131, Selected False, Rank: 154.000\n",
            "Column: 2132, Selected False, Rank: 771.000\n",
            "Column: 2133, Selected False, Rank: 1373.000\n",
            "Column: 2134, Selected False, Rank: 61.000\n",
            "Column: 2135, Selected False, Rank: 2434.000\n",
            "Column: 2136, Selected False, Rank: 2739.000\n",
            "Column: 2137, Selected False, Rank: 2355.000\n",
            "Column: 2138, Selected False, Rank: 2501.000\n",
            "Column: 2139, Selected False, Rank: 123.000\n",
            "Column: 2140, Selected False, Rank: 715.000\n",
            "Column: 2141, Selected False, Rank: 663.000\n",
            "Column: 2142, Selected False, Rank: 1227.000\n",
            "Column: 2143, Selected False, Rank: 525.000\n",
            "Column: 2144, Selected False, Rank: 2202.000\n",
            "Column: 2145, Selected False, Rank: 105.000\n",
            "Column: 2146, Selected False, Rank: 1886.000\n",
            "Column: 2147, Selected False, Rank: 1787.000\n",
            "Column: 2148, Selected False, Rank: 483.000\n",
            "Column: 2149, Selected False, Rank: 131.000\n",
            "Column: 2150, Selected False, Rank: 1653.000\n",
            "Column: 2151, Selected False, Rank: 2267.000\n",
            "Column: 2152, Selected False, Rank: 271.000\n",
            "Column: 2153, Selected False, Rank: 943.000\n",
            "Column: 2154, Selected False, Rank: 814.000\n",
            "Column: 2155, Selected False, Rank: 1671.000\n",
            "Column: 2156, Selected False, Rank: 848.000\n",
            "Column: 2157, Selected False, Rank: 2683.000\n",
            "Column: 2158, Selected False, Rank: 1323.000\n",
            "Column: 2159, Selected False, Rank: 1096.000\n",
            "Column: 2160, Selected False, Rank: 1153.000\n",
            "Column: 2161, Selected False, Rank: 1856.000\n",
            "Column: 2162, Selected False, Rank: 1264.000\n",
            "Column: 2163, Selected False, Rank: 388.000\n",
            "Column: 2164, Selected False, Rank: 255.000\n",
            "Column: 2165, Selected False, Rank: 399.000\n",
            "Column: 2166, Selected False, Rank: 2714.000\n",
            "Column: 2167, Selected False, Rank: 1421.000\n",
            "Column: 2168, Selected False, Rank: 2254.000\n",
            "Column: 2169, Selected False, Rank: 676.000\n",
            "Column: 2170, Selected False, Rank: 298.000\n",
            "Column: 2171, Selected False, Rank: 754.000\n",
            "Column: 2172, Selected False, Rank: 459.000\n",
            "Column: 2173, Selected False, Rank: 682.000\n",
            "Column: 2174, Selected False, Rank: 2101.000\n",
            "Column: 2175, Selected False, Rank: 517.000\n",
            "Column: 2176, Selected False, Rank: 451.000\n",
            "Column: 2177, Selected False, Rank: 291.000\n",
            "Column: 2178, Selected False, Rank: 2091.000\n",
            "Column: 2179, Selected False, Rank: 1045.000\n",
            "Column: 2180, Selected False, Rank: 1043.000\n",
            "Column: 2181, Selected False, Rank: 997.000\n",
            "Column: 2182, Selected False, Rank: 885.000\n",
            "Column: 2183, Selected False, Rank: 1129.000\n",
            "Column: 2184, Selected False, Rank: 2226.000\n",
            "Column: 2185, Selected False, Rank: 1077.000\n",
            "Column: 2186, Selected False, Rank: 2783.000\n",
            "Column: 2187, Selected False, Rank: 2758.000\n",
            "Column: 2188, Selected False, Rank: 537.000\n",
            "Column: 2189, Selected False, Rank: 2682.000\n",
            "Column: 2190, Selected False, Rank: 241.000\n",
            "Column: 2191, Selected False, Rank: 1953.000\n",
            "Column: 2192, Selected False, Rank: 2190.000\n",
            "Column: 2193, Selected False, Rank: 1247.000\n",
            "Column: 2194, Selected False, Rank: 157.000\n",
            "Column: 2195, Selected False, Rank: 674.000\n",
            "Column: 2196, Selected False, Rank: 2793.000\n",
            "Column: 2197, Selected False, Rank: 2367.000\n",
            "Column: 2198, Selected False, Rank: 2632.000\n",
            "Column: 2199, Selected False, Rank: 1459.000\n",
            "Column: 2200, Selected False, Rank: 1746.000\n",
            "Column: 2201, Selected False, Rank: 1368.000\n",
            "Column: 2202, Selected False, Rank: 977.000\n",
            "Column: 2203, Selected False, Rank: 1057.000\n",
            "Column: 2204, Selected False, Rank: 2523.000\n",
            "Column: 2205, Selected False, Rank: 1991.000\n",
            "Column: 2206, Selected False, Rank: 1683.000\n",
            "Column: 2207, Selected False, Rank: 1342.000\n",
            "Column: 2208, Selected False, Rank: 1322.000\n",
            "Column: 2209, Selected False, Rank: 1276.000\n",
            "Column: 2210, Selected False, Rank: 2260.000\n",
            "Column: 2211, Selected False, Rank: 2354.000\n",
            "Column: 2212, Selected False, Rank: 1922.000\n",
            "Column: 2213, Selected False, Rank: 810.000\n",
            "Column: 2214, Selected False, Rank: 481.000\n",
            "Column: 2215, Selected False, Rank: 1725.000\n",
            "Column: 2216, Selected False, Rank: 497.000\n",
            "Column: 2217, Selected False, Rank: 2108.000\n",
            "Column: 2218, Selected False, Rank: 294.000\n",
            "Column: 2219, Selected False, Rank: 1565.000\n",
            "Column: 2220, Selected False, Rank: 2309.000\n",
            "Column: 2221, Selected False, Rank: 2402.000\n",
            "Column: 2222, Selected False, Rank: 2230.000\n",
            "Column: 2223, Selected False, Rank: 2620.000\n",
            "Column: 2224, Selected False, Rank: 1989.000\n",
            "Column: 2225, Selected False, Rank: 910.000\n",
            "Column: 2226, Selected False, Rank: 713.000\n",
            "Column: 2227, Selected False, Rank: 222.000\n",
            "Column: 2228, Selected False, Rank: 1145.000\n",
            "Column: 2229, Selected False, Rank: 2505.000\n",
            "Column: 2230, Selected False, Rank: 432.000\n",
            "Column: 2231, Selected False, Rank: 1835.000\n",
            "Column: 2232, Selected False, Rank: 952.000\n",
            "Column: 2233, Selected False, Rank: 2040.000\n",
            "Column: 2234, Selected False, Rank: 2164.000\n",
            "Column: 2235, Selected False, Rank: 306.000\n",
            "Column: 2236, Selected False, Rank: 1682.000\n",
            "Column: 2237, Selected False, Rank: 1941.000\n",
            "Column: 2238, Selected False, Rank: 2004.000\n",
            "Column: 2239, Selected False, Rank: 260.000\n",
            "Column: 2240, Selected False, Rank: 1806.000\n",
            "Column: 2241, Selected False, Rank: 794.000\n",
            "Column: 2242, Selected False, Rank: 1069.000\n",
            "Column: 2243, Selected False, Rank: 1185.000\n",
            "Column: 2244, Selected False, Rank: 482.000\n",
            "Column: 2245, Selected False, Rank: 2241.000\n",
            "Column: 2246, Selected False, Rank: 2689.000\n",
            "Column: 2247, Selected False, Rank: 1830.000\n",
            "Column: 2248, Selected False, Rank: 853.000\n",
            "Column: 2249, Selected False, Rank: 505.000\n",
            "Column: 2250, Selected False, Rank: 1169.000\n",
            "Column: 2251, Selected False, Rank: 2240.000\n",
            "Column: 2252, Selected False, Rank: 2515.000\n",
            "Column: 2253, Selected False, Rank: 1217.000\n",
            "Column: 2254, Selected False, Rank: 2131.000\n",
            "Column: 2255, Selected False, Rank: 2675.000\n",
            "Column: 2256, Selected False, Rank: 529.000\n",
            "Column: 2257, Selected False, Rank: 354.000\n",
            "Column: 2258, Selected False, Rank: 1494.000\n",
            "Column: 2259, Selected False, Rank: 1164.000\n",
            "Column: 2260, Selected False, Rank: 1783.000\n",
            "Column: 2261, Selected False, Rank: 673.000\n",
            "Column: 2262, Selected False, Rank: 2103.000\n",
            "Column: 2263, Selected False, Rank: 569.000\n",
            "Column: 2264, Selected False, Rank: 1359.000\n",
            "Column: 2265, Selected False, Rank: 1300.000\n",
            "Column: 2266, Selected False, Rank: 1723.000\n",
            "Column: 2267, Selected False, Rank: 1117.000\n",
            "Column: 2268, Selected False, Rank: 1874.000\n",
            "Column: 2269, Selected False, Rank: 1945.000\n",
            "Column: 2270, Selected False, Rank: 2499.000\n",
            "Column: 2271, Selected False, Rank: 1578.000\n",
            "Column: 2272, Selected False, Rank: 858.000\n",
            "Column: 2273, Selected False, Rank: 507.000\n",
            "Column: 2274, Selected False, Rank: 565.000\n",
            "Column: 2275, Selected False, Rank: 934.000\n",
            "Column: 2276, Selected False, Rank: 1742.000\n",
            "Column: 2277, Selected False, Rank: 1353.000\n",
            "Column: 2278, Selected False, Rank: 2180.000\n",
            "Column: 2279, Selected False, Rank: 1411.000\n",
            "Column: 2280, Selected False, Rank: 1394.000\n",
            "Column: 2281, Selected False, Rank: 1030.000\n",
            "Column: 2282, Selected False, Rank: 602.000\n",
            "Column: 2283, Selected False, Rank: 2195.000\n",
            "Column: 2284, Selected False, Rank: 733.000\n",
            "Column: 2285, Selected False, Rank: 1253.000\n",
            "Column: 2286, Selected False, Rank: 133.000\n",
            "Column: 2287, Selected False, Rank: 1246.000\n",
            "Column: 2288, Selected False, Rank: 1894.000\n",
            "Column: 2289, Selected False, Rank: 2787.000\n",
            "Column: 2290, Selected False, Rank: 765.000\n",
            "Column: 2291, Selected False, Rank: 1546.000\n",
            "Column: 2292, Selected False, Rank: 1212.000\n",
            "Column: 2293, Selected False, Rank: 1479.000\n",
            "Column: 2294, Selected False, Rank: 2473.000\n",
            "Column: 2295, Selected False, Rank: 1436.000\n",
            "Column: 2296, Selected False, Rank: 2601.000\n",
            "Column: 2297, Selected False, Rank: 1297.000\n",
            "Column: 2298, Selected False, Rank: 185.000\n",
            "Column: 2299, Selected False, Rank: 696.000\n",
            "Column: 2300, Selected False, Rank: 621.000\n",
            "Column: 2301, Selected False, Rank: 71.000\n",
            "Column: 2302, Selected False, Rank: 2346.000\n",
            "Column: 2303, Selected False, Rank: 740.000\n",
            "Column: 2304, Selected False, Rank: 2668.000\n",
            "Column: 2305, Selected False, Rank: 381.000\n",
            "Column: 2306, Selected False, Rank: 2639.000\n",
            "Column: 2307, Selected False, Rank: 1879.000\n",
            "Column: 2308, Selected False, Rank: 1987.000\n",
            "Column: 2309, Selected False, Rank: 349.000\n",
            "Column: 2310, Selected False, Rank: 1677.000\n",
            "Column: 2311, Selected False, Rank: 1139.000\n",
            "Column: 2312, Selected False, Rank: 616.000\n",
            "Column: 2313, Selected False, Rank: 742.000\n",
            "Column: 2314, Selected False, Rank: 876.000\n",
            "Column: 2315, Selected False, Rank: 413.000\n",
            "Column: 2316, Selected False, Rank: 2199.000\n",
            "Column: 2317, Selected False, Rank: 1136.000\n",
            "Column: 2318, Selected False, Rank: 1607.000\n",
            "Column: 2319, Selected False, Rank: 1080.000\n",
            "Column: 2320, Selected False, Rank: 329.000\n",
            "Column: 2321, Selected False, Rank: 469.000\n",
            "Column: 2322, Selected False, Rank: 52.000\n",
            "Column: 2323, Selected False, Rank: 613.000\n",
            "Column: 2324, Selected False, Rank: 2636.000\n",
            "Column: 2325, Selected False, Rank: 846.000\n",
            "Column: 2326, Selected False, Rank: 2711.000\n",
            "Column: 2327, Selected False, Rank: 2341.000\n",
            "Column: 2328, Selected False, Rank: 586.000\n",
            "Column: 2329, Selected False, Rank: 2483.000\n",
            "Column: 2330, Selected False, Rank: 1316.000\n",
            "Column: 2331, Selected False, Rank: 683.000\n",
            "Column: 2332, Selected False, Rank: 1268.000\n",
            "Column: 2333, Selected False, Rank: 1839.000\n",
            "Column: 2334, Selected False, Rank: 1899.000\n",
            "Column: 2335, Selected False, Rank: 1176.000\n",
            "Column: 2336, Selected False, Rank: 784.000\n",
            "Column: 2337, Selected False, Rank: 1492.000\n",
            "Column: 2338, Selected False, Rank: 2492.000\n",
            "Column: 2339, Selected False, Rank: 2214.000\n",
            "Column: 2340, Selected False, Rank: 293.000\n",
            "Column: 2341, Selected False, Rank: 2250.000\n",
            "Column: 2342, Selected False, Rank: 1477.000\n",
            "Column: 2343, Selected False, Rank: 1205.000\n",
            "Column: 2344, Selected False, Rank: 711.000\n",
            "Column: 2345, Selected False, Rank: 1480.000\n",
            "Column: 2346, Selected False, Rank: 2320.000\n",
            "Column: 2347, Selected False, Rank: 1141.000\n",
            "Column: 2348, Selected False, Rank: 400.000\n",
            "Column: 2349, Selected False, Rank: 508.000\n",
            "Column: 2350, Selected False, Rank: 196.000\n",
            "Column: 2351, Selected False, Rank: 826.000\n",
            "Column: 2352, Selected False, Rank: 153.000\n",
            "Column: 2353, Selected False, Rank: 2743.000\n",
            "Column: 2354, Selected False, Rank: 1755.000\n",
            "Column: 2355, Selected False, Rank: 2365.000\n",
            "Column: 2356, Selected False, Rank: 753.000\n",
            "Column: 2357, Selected False, Rank: 233.000\n",
            "Column: 2358, Selected False, Rank: 2330.000\n",
            "Column: 2359, Selected False, Rank: 1864.000\n",
            "Column: 2360, Selected False, Rank: 2661.000\n",
            "Column: 2361, Selected False, Rank: 2286.000\n",
            "Column: 2362, Selected False, Rank: 1408.000\n",
            "Column: 2363, Selected False, Rank: 832.000\n",
            "Column: 2364, Selected False, Rank: 1981.000\n",
            "Column: 2365, Selected False, Rank: 1604.000\n",
            "Column: 2366, Selected False, Rank: 2411.000\n",
            "Column: 2367, Selected False, Rank: 1586.000\n",
            "Column: 2368, Selected False, Rank: 781.000\n",
            "Column: 2369, Selected False, Rank: 2455.000\n",
            "Column: 2370, Selected False, Rank: 102.000\n",
            "Column: 2371, Selected False, Rank: 2172.000\n",
            "Column: 2372, Selected False, Rank: 2291.000\n",
            "Column: 2373, Selected False, Rank: 1908.000\n",
            "Column: 2374, Selected False, Rank: 435.000\n",
            "Column: 2375, Selected False, Rank: 182.000\n",
            "Column: 2376, Selected False, Rank: 460.000\n",
            "Column: 2377, Selected False, Rank: 343.000\n",
            "Column: 2378, Selected False, Rank: 593.000\n",
            "Column: 2379, Selected False, Rank: 179.000\n",
            "Column: 2380, Selected False, Rank: 2428.000\n",
            "Column: 2381, Selected False, Rank: 364.000\n",
            "Column: 2382, Selected False, Rank: 2363.000\n",
            "Column: 2383, Selected False, Rank: 1350.000\n",
            "Column: 2384, Selected False, Rank: 278.000\n",
            "Column: 2385, Selected False, Rank: 1182.000\n",
            "Column: 2386, Selected False, Rank: 686.000\n",
            "Column: 2387, Selected False, Rank: 1375.000\n",
            "Column: 2388, Selected False, Rank: 2090.000\n",
            "Column: 2389, Selected False, Rank: 480.000\n",
            "Column: 2390, Selected False, Rank: 1558.000\n",
            "Column: 2391, Selected False, Rank: 1152.000\n",
            "Column: 2392, Selected False, Rank: 2603.000\n",
            "Column: 2393, Selected False, Rank: 1200.000\n",
            "Column: 2394, Selected False, Rank: 1177.000\n",
            "Column: 2395, Selected False, Rank: 2268.000\n",
            "Column: 2396, Selected False, Rank: 327.000\n",
            "Column: 2397, Selected False, Rank: 171.000\n",
            "Column: 2398, Selected False, Rank: 812.000\n",
            "Column: 2399, Selected False, Rank: 1206.000\n",
            "Column: 2400, Selected False, Rank: 955.000\n",
            "Column: 2401, Selected False, Rank: 2187.000\n",
            "Column: 2402, Selected False, Rank: 1538.000\n",
            "Column: 2403, Selected False, Rank: 2063.000\n",
            "Column: 2404, Selected False, Rank: 99.000\n",
            "Column: 2405, Selected False, Rank: 1405.000\n",
            "Column: 2406, Selected False, Rank: 582.000\n",
            "Column: 2407, Selected False, Rank: 1985.000\n",
            "Column: 2408, Selected False, Rank: 445.000\n",
            "Column: 2409, Selected False, Rank: 346.000\n",
            "Column: 2410, Selected False, Rank: 727.000\n",
            "Column: 2411, Selected False, Rank: 2399.000\n",
            "Column: 2412, Selected False, Rank: 1715.000\n",
            "Column: 2413, Selected False, Rank: 2495.000\n",
            "Column: 2414, Selected False, Rank: 296.000\n",
            "Column: 2415, Selected False, Rank: 851.000\n",
            "Column: 2416, Selected False, Rank: 1123.000\n",
            "Column: 2417, Selected False, Rank: 113.000\n",
            "Column: 2418, Selected False, Rank: 2294.000\n",
            "Column: 2419, Selected False, Rank: 1419.000\n",
            "Column: 2420, Selected False, Rank: 2031.000\n",
            "Column: 2421, Selected False, Rank: 2315.000\n",
            "Column: 2422, Selected False, Rank: 206.000\n",
            "Column: 2423, Selected False, Rank: 2569.000\n",
            "Column: 2424, Selected False, Rank: 249.000\n",
            "Column: 2425, Selected False, Rank: 1813.000\n",
            "Column: 2426, Selected False, Rank: 1973.000\n",
            "Column: 2427, Selected False, Rank: 376.000\n",
            "Column: 2428, Selected False, Rank: 1731.000\n",
            "Column: 2429, Selected False, Rank: 1745.000\n",
            "Column: 2430, Selected False, Rank: 777.000\n",
            "Column: 2431, Selected False, Rank: 2629.000\n",
            "Column: 2432, Selected False, Rank: 1819.000\n",
            "Column: 2433, Selected False, Rank: 595.000\n",
            "Column: 2434, Selected False, Rank: 1132.000\n",
            "Column: 2435, Selected False, Rank: 778.000\n",
            "Column: 2436, Selected False, Rank: 2729.000\n",
            "Column: 2437, Selected False, Rank: 383.000\n",
            "Column: 2438, Selected False, Rank: 1627.000\n",
            "Column: 2439, Selected False, Rank: 2336.000\n",
            "Column: 2440, Selected False, Rank: 2567.000\n",
            "Column: 2441, Selected False, Rank: 1053.000\n",
            "Column: 2442, Selected False, Rank: 1196.000\n",
            "Column: 2443, Selected False, Rank: 1961.000\n",
            "Column: 2444, Selected True, Rank: 1.000\n",
            "Column: 2445, Selected False, Rank: 1036.000\n",
            "Column: 2446, Selected False, Rank: 861.000\n",
            "Column: 2447, Selected False, Rank: 1471.000\n",
            "Column: 2448, Selected False, Rank: 1023.000\n",
            "Column: 2449, Selected False, Rank: 218.000\n",
            "Column: 2450, Selected False, Rank: 532.000\n",
            "Column: 2451, Selected False, Rank: 156.000\n",
            "Column: 2452, Selected False, Rank: 2036.000\n",
            "Column: 2453, Selected False, Rank: 1541.000\n",
            "Column: 2454, Selected False, Rank: 572.000\n",
            "Column: 2455, Selected False, Rank: 1658.000\n",
            "Column: 2456, Selected False, Rank: 1761.000\n",
            "Column: 2457, Selected False, Rank: 2273.000\n",
            "Column: 2458, Selected False, Rank: 191.000\n",
            "Column: 2459, Selected False, Rank: 782.000\n",
            "Column: 2460, Selected False, Rank: 262.000\n",
            "Column: 2461, Selected False, Rank: 597.000\n",
            "Column: 2462, Selected False, Rank: 2000.000\n",
            "Column: 2463, Selected False, Rank: 2152.000\n",
            "Column: 2464, Selected False, Rank: 2467.000\n",
            "Column: 2465, Selected False, Rank: 2791.000\n",
            "Column: 2466, Selected False, Rank: 2443.000\n",
            "Column: 2467, Selected False, Rank: 2275.000\n",
            "Column: 2468, Selected False, Rank: 1826.000\n",
            "Column: 2469, Selected False, Rank: 915.000\n",
            "Column: 2470, Selected False, Rank: 2595.000\n",
            "Column: 2471, Selected False, Rank: 63.000\n",
            "Column: 2472, Selected False, Rank: 1801.000\n",
            "Column: 2473, Selected False, Rank: 319.000\n",
            "Column: 2474, Selected False, Rank: 804.000\n",
            "Column: 2475, Selected False, Rank: 2701.000\n",
            "Column: 2476, Selected False, Rank: 2149.000\n",
            "Column: 2477, Selected False, Rank: 1876.000\n",
            "Column: 2478, Selected False, Rank: 1003.000\n",
            "Column: 2479, Selected False, Rank: 1235.000\n",
            "Column: 2480, Selected False, Rank: 415.000\n",
            "Column: 2481, Selected False, Rank: 148.000\n",
            "Column: 2482, Selected False, Rank: 1120.000\n",
            "Column: 2483, Selected False, Rank: 1420.000\n",
            "Column: 2484, Selected False, Rank: 985.000\n",
            "Column: 2485, Selected False, Rank: 1799.000\n",
            "Column: 2486, Selected False, Rank: 1397.000\n",
            "Column: 2487, Selected False, Rank: 1088.000\n",
            "Column: 2488, Selected False, Rank: 2236.000\n",
            "Column: 2489, Selected False, Rank: 633.000\n",
            "Column: 2490, Selected False, Rank: 103.000\n",
            "Column: 2491, Selected False, Rank: 1201.000\n",
            "Column: 2492, Selected False, Rank: 2297.000\n",
            "Column: 2493, Selected False, Rank: 168.000\n",
            "Column: 2494, Selected False, Rank: 2502.000\n",
            "Column: 2495, Selected False, Rank: 1980.000\n",
            "Column: 2496, Selected False, Rank: 703.000\n",
            "Column: 2497, Selected False, Rank: 402.000\n",
            "Column: 2498, Selected False, Rank: 136.000\n",
            "Column: 2499, Selected False, Rank: 757.000\n",
            "Column: 2500, Selected False, Rank: 1079.000\n",
            "Column: 2501, Selected False, Rank: 84.000\n",
            "Column: 2502, Selected False, Rank: 142.000\n",
            "Column: 2503, Selected False, Rank: 806.000\n",
            "Column: 2504, Selected False, Rank: 268.000\n",
            "Column: 2505, Selected False, Rank: 767.000\n",
            "Column: 2506, Selected False, Rank: 345.000\n",
            "Column: 2507, Selected False, Rank: 2510.000\n",
            "Column: 2508, Selected False, Rank: 391.000\n",
            "Column: 2509, Selected False, Rank: 353.000\n",
            "Column: 2510, Selected False, Rank: 2442.000\n",
            "Column: 2511, Selected False, Rank: 1537.000\n",
            "Column: 2512, Selected False, Rank: 382.000\n",
            "Column: 2513, Selected False, Rank: 2092.000\n",
            "Column: 2514, Selected False, Rank: 987.000\n",
            "Column: 2515, Selected False, Rank: 1938.000\n",
            "Column: 2516, Selected False, Rank: 657.000\n",
            "Column: 2517, Selected False, Rank: 2314.000\n",
            "Column: 2518, Selected False, Rank: 1583.000\n",
            "Column: 2519, Selected False, Rank: 2572.000\n",
            "Column: 2520, Selected False, Rank: 2477.000\n",
            "Column: 2521, Selected False, Rank: 139.000\n",
            "Column: 2522, Selected False, Rank: 923.000\n",
            "Column: 2523, Selected False, Rank: 2340.000\n",
            "Column: 2524, Selected False, Rank: 267.000\n",
            "Column: 2525, Selected False, Rank: 2078.000\n",
            "Column: 2526, Selected False, Rank: 1052.000\n",
            "Column: 2527, Selected False, Rank: 618.000\n",
            "Column: 2528, Selected False, Rank: 1611.000\n",
            "Column: 2529, Selected False, Rank: 1995.000\n",
            "Column: 2530, Selected False, Rank: 865.000\n",
            "Column: 2531, Selected False, Rank: 2211.000\n",
            "Column: 2532, Selected False, Rank: 405.000\n",
            "Column: 2533, Selected False, Rank: 147.000\n",
            "Column: 2534, Selected False, Rank: 1265.000\n",
            "Column: 2535, Selected False, Rank: 1137.000\n",
            "Column: 2536, Selected False, Rank: 1111.000\n",
            "Column: 2537, Selected False, Rank: 121.000\n",
            "Column: 2538, Selected False, Rank: 509.000\n",
            "Column: 2539, Selected False, Rank: 1934.000\n",
            "Column: 2540, Selected False, Rank: 1769.000\n",
            "Column: 2541, Selected False, Rank: 937.000\n",
            "Column: 2542, Selected False, Rank: 309.000\n",
            "Column: 2543, Selected False, Rank: 821.000\n",
            "Column: 2544, Selected False, Rank: 414.000\n",
            "Column: 2545, Selected False, Rank: 1768.000\n",
            "Column: 2546, Selected False, Rank: 1516.000\n",
            "Column: 2547, Selected False, Rank: 253.000\n",
            "Column: 2548, Selected False, Rank: 1996.000\n",
            "Column: 2549, Selected False, Rank: 2723.000\n",
            "Column: 2550, Selected False, Rank: 2358.000\n",
            "Column: 2551, Selected False, Rank: 2032.000\n",
            "Column: 2552, Selected False, Rank: 200.000\n",
            "Column: 2553, Selected False, Rank: 1138.000\n",
            "Column: 2554, Selected False, Rank: 2427.000\n",
            "Column: 2555, Selected False, Rank: 8.000\n",
            "Column: 2556, Selected False, Rank: 935.000\n",
            "Column: 2557, Selected False, Rank: 768.000\n",
            "Column: 2558, Selected False, Rank: 138.000\n",
            "Column: 2559, Selected False, Rank: 1098.000\n",
            "Column: 2560, Selected False, Rank: 1424.000\n",
            "Column: 2561, Selected False, Rank: 417.000\n",
            "Column: 2562, Selected False, Rank: 2691.000\n",
            "Column: 2563, Selected False, Rank: 553.000\n",
            "Column: 2564, Selected False, Rank: 308.000\n",
            "Column: 2565, Selected False, Rank: 634.000\n",
            "Column: 2566, Selected False, Rank: 119.000\n",
            "Column: 2567, Selected False, Rank: 1580.000\n",
            "Column: 2568, Selected False, Rank: 2693.000\n",
            "Column: 2569, Selected False, Rank: 479.000\n",
            "Column: 2570, Selected False, Rank: 831.000\n",
            "Column: 2571, Selected False, Rank: 1498.000\n",
            "Column: 2572, Selected False, Rank: 2293.000\n",
            "Column: 2573, Selected False, Rank: 967.000\n",
            "Column: 2574, Selected False, Rank: 397.000\n",
            "Column: 2575, Selected False, Rank: 207.000\n",
            "Column: 2576, Selected False, Rank: 1155.000\n",
            "Column: 2577, Selected False, Rank: 2042.000\n",
            "Column: 2578, Selected False, Rank: 1568.000\n",
            "Column: 2579, Selected False, Rank: 92.000\n",
            "Column: 2580, Selected False, Rank: 419.000\n",
            "Column: 2581, Selected False, Rank: 528.000\n",
            "Column: 2582, Selected False, Rank: 2156.000\n",
            "Column: 2583, Selected False, Rank: 1553.000\n",
            "Column: 2584, Selected False, Rank: 2177.000\n",
            "Column: 2585, Selected False, Rank: 1710.000\n",
            "Column: 2586, Selected False, Rank: 2749.000\n",
            "Column: 2587, Selected False, Rank: 1704.000\n",
            "Column: 2588, Selected False, Rank: 116.000\n",
            "Column: 2589, Selected False, Rank: 669.000\n",
            "Column: 2590, Selected False, Rank: 855.000\n",
            "Column: 2591, Selected False, Rank: 1091.000\n",
            "Column: 2592, Selected False, Rank: 1194.000\n",
            "Column: 2593, Selected False, Rank: 122.000\n",
            "Column: 2594, Selected False, Rank: 970.000\n",
            "Column: 2595, Selected False, Rank: 2026.000\n",
            "Column: 2596, Selected False, Rank: 198.000\n",
            "Column: 2597, Selected False, Rank: 59.000\n",
            "Column: 2598, Selected False, Rank: 232.000\n",
            "Column: 2599, Selected False, Rank: 891.000\n",
            "Column: 2600, Selected False, Rank: 1192.000\n",
            "Column: 2601, Selected False, Rank: 567.000\n",
            "Column: 2602, Selected False, Rank: 1181.000\n",
            "Column: 2603, Selected False, Rank: 2206.000\n",
            "Column: 2604, Selected False, Rank: 720.000\n",
            "Column: 2605, Selected False, Rank: 2379.000\n",
            "Column: 2606, Selected False, Rank: 699.000\n",
            "Column: 2607, Selected False, Rank: 1449.000\n",
            "Column: 2608, Selected False, Rank: 743.000\n",
            "Column: 2609, Selected False, Rank: 791.000\n",
            "Column: 2610, Selected False, Rank: 184.000\n",
            "Column: 2611, Selected False, Rank: 620.000\n",
            "Column: 2612, Selected False, Rank: 1263.000\n",
            "Column: 2613, Selected False, Rank: 879.000\n",
            "Column: 2614, Selected False, Rank: 366.000\n",
            "Column: 2615, Selected False, Rank: 228.000\n",
            "Column: 2616, Selected False, Rank: 521.000\n",
            "Column: 2617, Selected False, Rank: 2074.000\n",
            "Column: 2618, Selected False, Rank: 1815.000\n",
            "Column: 2619, Selected False, Rank: 1339.000\n",
            "Column: 2620, Selected False, Rank: 1701.000\n",
            "Column: 2621, Selected False, Rank: 625.000\n",
            "Column: 2622, Selected False, Rank: 1274.000\n",
            "Column: 2623, Selected False, Rank: 974.000\n",
            "Column: 2624, Selected False, Rank: 2253.000\n",
            "Column: 2625, Selected False, Rank: 924.000\n",
            "Column: 2626, Selected False, Rank: 706.000\n",
            "Column: 2627, Selected False, Rank: 1655.000\n",
            "Column: 2628, Selected False, Rank: 1391.000\n",
            "Column: 2629, Selected False, Rank: 1743.000\n",
            "Column: 2630, Selected False, Rank: 2582.000\n",
            "Column: 2631, Selected False, Rank: 1271.000\n",
            "Column: 2632, Selected False, Rank: 33.000\n",
            "Column: 2633, Selected False, Rank: 229.000\n",
            "Column: 2634, Selected False, Rank: 2770.000\n",
            "Column: 2635, Selected False, Rank: 2116.000\n",
            "Column: 2636, Selected False, Rank: 2704.000\n",
            "Column: 2637, Selected False, Rank: 1198.000\n",
            "Column: 2638, Selected False, Rank: 1315.000\n",
            "Column: 2639, Selected False, Rank: 389.000\n",
            "Column: 2640, Selected False, Rank: 1304.000\n",
            "Column: 2641, Selected False, Rank: 470.000\n",
            "Column: 2642, Selected False, Rank: 667.000\n",
            "Column: 2643, Selected False, Rank: 279.000\n",
            "Column: 2644, Selected False, Rank: 800.000\n",
            "Column: 2645, Selected False, Rank: 1986.000\n",
            "Column: 2646, Selected False, Rank: 2006.000\n",
            "Column: 2647, Selected False, Rank: 213.000\n",
            "Column: 2648, Selected False, Rank: 2173.000\n",
            "Column: 2649, Selected False, Rank: 2583.000\n",
            "Column: 2650, Selected False, Rank: 2380.000\n",
            "Column: 2651, Selected False, Rank: 558.000\n",
            "Column: 2652, Selected False, Rank: 818.000\n",
            "Column: 2653, Selected False, Rank: 208.000\n",
            "Column: 2654, Selected False, Rank: 2488.000\n",
            "Column: 2655, Selected False, Rank: 522.000\n",
            "Column: 2656, Selected False, Rank: 1242.000\n",
            "Column: 2657, Selected False, Rank: 685.000\n",
            "Column: 2658, Selected False, Rank: 67.000\n",
            "Column: 2659, Selected False, Rank: 1828.000\n",
            "Column: 2660, Selected False, Rank: 2607.000\n",
            "Column: 2661, Selected False, Rank: 193.000\n",
            "Column: 2662, Selected False, Rank: 1133.000\n",
            "Column: 2663, Selected False, Rank: 2575.000\n",
            "Column: 2664, Selected False, Rank: 2773.000\n",
            "Column: 2665, Selected False, Rank: 2384.000\n",
            "Column: 2666, Selected False, Rank: 1800.000\n",
            "Column: 2667, Selected False, Rank: 772.000\n",
            "Column: 2668, Selected False, Rank: 689.000\n",
            "Column: 2669, Selected False, Rank: 857.000\n",
            "Column: 2670, Selected False, Rank: 2458.000\n",
            "Column: 2671, Selected False, Rank: 1364.000\n",
            "Column: 2672, Selected False, Rank: 340.000\n",
            "Column: 2673, Selected False, Rank: 1882.000\n",
            "Column: 2674, Selected False, Rank: 2460.000\n",
            "Column: 2675, Selected False, Rank: 1095.000\n",
            "Column: 2676, Selected False, Rank: 2144.000\n",
            "Column: 2677, Selected False, Rank: 2405.000\n",
            "Column: 2678, Selected False, Rank: 881.000\n",
            "Column: 2679, Selected False, Rank: 744.000\n",
            "Column: 2680, Selected False, Rank: 1063.000\n",
            "Column: 2681, Selected False, Rank: 960.000\n",
            "Column: 2682, Selected False, Rank: 1121.000\n",
            "Column: 2683, Selected False, Rank: 823.000\n",
            "Column: 2684, Selected False, Rank: 844.000\n",
            "Column: 2685, Selected False, Rank: 426.000\n",
            "Column: 2686, Selected False, Rank: 1089.000\n",
            "Column: 2687, Selected False, Rank: 362.000\n",
            "Column: 2688, Selected False, Rank: 82.000\n",
            "Column: 2689, Selected False, Rank: 972.000\n",
            "Column: 2690, Selected False, Rank: 1197.000\n",
            "Column: 2691, Selected False, Rank: 503.000\n",
            "Column: 2692, Selected False, Rank: 701.000\n",
            "Column: 2693, Selected False, Rank: 793.000\n",
            "Column: 2694, Selected False, Rank: 822.000\n",
            "Column: 2695, Selected False, Rank: 2121.000\n",
            "Column: 2696, Selected False, Rank: 1189.000\n",
            "Column: 2697, Selected False, Rank: 1713.000\n",
            "Column: 2698, Selected False, Rank: 212.000\n",
            "Column: 2699, Selected False, Rank: 1594.000\n",
            "Column: 2700, Selected False, Rank: 1650.000\n",
            "Column: 2701, Selected False, Rank: 370.000\n",
            "Column: 2702, Selected False, Rank: 86.000\n",
            "Column: 2703, Selected False, Rank: 2089.000\n",
            "Column: 2704, Selected False, Rank: 76.000\n",
            "Column: 2705, Selected False, Rank: 2468.000\n",
            "Column: 2706, Selected False, Rank: 837.000\n",
            "Column: 2707, Selected False, Rank: 440.000\n",
            "Column: 2708, Selected False, Rank: 181.000\n",
            "Column: 2709, Selected False, Rank: 2585.000\n",
            "Column: 2710, Selected False, Rank: 1400.000\n",
            "Column: 2711, Selected False, Rank: 2057.000\n",
            "Column: 2712, Selected False, Rank: 1774.000\n",
            "Column: 2713, Selected False, Rank: 368.000\n",
            "Column: 2714, Selected False, Rank: 169.000\n",
            "Column: 2715, Selected False, Rank: 1576.000\n",
            "Column: 2716, Selected False, Rank: 737.000\n",
            "Column: 2717, Selected False, Rank: 514.000\n",
            "Column: 2718, Selected False, Rank: 854.000\n",
            "Column: 2719, Selected False, Rank: 2627.000\n",
            "Column: 2720, Selected False, Rank: 510.000\n",
            "Column: 2721, Selected False, Rank: 899.000\n",
            "Column: 2722, Selected False, Rank: 584.000\n",
            "Column: 2723, Selected False, Rank: 2373.000\n",
            "Column: 2724, Selected False, Rank: 1294.000\n",
            "Column: 2725, Selected False, Rank: 1334.000\n",
            "Column: 2726, Selected False, Rank: 167.000\n",
            "Column: 2727, Selected False, Rank: 1150.000\n",
            "Column: 2728, Selected False, Rank: 886.000\n",
            "Column: 2729, Selected False, Rank: 809.000\n",
            "Column: 2730, Selected False, Rank: 798.000\n",
            "Column: 2731, Selected False, Rank: 1579.000\n",
            "Column: 2732, Selected False, Rank: 583.000\n",
            "Column: 2733, Selected False, Rank: 489.000\n",
            "Column: 2734, Selected False, Rank: 310.000\n",
            "Column: 2735, Selected False, Rank: 1849.000\n",
            "Column: 2736, Selected False, Rank: 285.000\n",
            "Column: 2737, Selected False, Rank: 1372.000\n",
            "Column: 2738, Selected False, Rank: 1221.000\n",
            "Column: 2739, Selected False, Rank: 91.000\n",
            "Column: 2740, Selected False, Rank: 275.000\n",
            "Column: 2741, Selected False, Rank: 888.000\n",
            "Column: 2742, Selected False, Rank: 152.000\n",
            "Column: 2743, Selected False, Rank: 403.000\n",
            "Column: 2744, Selected False, Rank: 2588.000\n",
            "Column: 2745, Selected False, Rank: 1765.000\n",
            "Column: 2746, Selected False, Rank: 263.000\n",
            "Column: 2747, Selected False, Rank: 374.000\n",
            "Column: 2748, Selected False, Rank: 495.000\n",
            "Column: 2749, Selected False, Rank: 611.000\n",
            "Column: 2750, Selected False, Rank: 2552.000\n",
            "Column: 2751, Selected False, Rank: 2039.000\n",
            "Column: 2752, Selected False, Rank: 2558.000\n",
            "Column: 2753, Selected False, Rank: 2613.000\n",
            "Column: 2754, Selected False, Rank: 2305.000\n",
            "Column: 2755, Selected False, Rank: 1729.000\n",
            "Column: 2756, Selected False, Rank: 2023.000\n",
            "Column: 2757, Selected False, Rank: 1570.000\n",
            "Column: 2758, Selected False, Rank: 1426.000\n",
            "Column: 2759, Selected False, Rank: 224.000\n",
            "Column: 2760, Selected False, Rank: 316.000\n",
            "Column: 2761, Selected False, Rank: 533.000\n",
            "Column: 2762, Selected False, Rank: 807.000\n",
            "Column: 2763, Selected False, Rank: 1166.000\n",
            "Column: 2764, Selected False, Rank: 2067.000\n",
            "Column: 2765, Selected False, Rank: 1827.000\n",
            "Column: 2766, Selected False, Rank: 49.000\n",
            "Column: 2767, Selected False, Rank: 2208.000\n",
            "Column: 2768, Selected False, Rank: 1284.000\n",
            "Column: 2769, Selected False, Rank: 829.000\n",
            "Column: 2770, Selected False, Rank: 2052.000\n",
            "Column: 2771, Selected False, Rank: 1178.000\n",
            "Column: 2772, Selected False, Rank: 289.000\n",
            "Column: 2773, Selected False, Rank: 2592.000\n",
            "Column: 2774, Selected False, Rank: 101.000\n",
            "Column: 2775, Selected False, Rank: 1363.000\n",
            "Column: 2776, Selected False, Rank: 1946.000\n",
            "Column: 2777, Selected False, Rank: 326.000\n",
            "Column: 2778, Selected False, Rank: 1563.000\n",
            "Column: 2779, Selected False, Rank: 1573.000\n",
            "Column: 2780, Selected False, Rank: 2600.000\n",
            "Column: 2781, Selected False, Rank: 2432.000\n",
            "Column: 2782, Selected False, Rank: 276.000\n",
            "Column: 2783, Selected False, Rank: 1358.000\n",
            "Column: 2784, Selected False, Rank: 1015.000\n",
            "Column: 2785, Selected False, Rank: 2484.000\n",
            "Column: 2786, Selected False, Rank: 1001.000\n",
            "Column: 2787, Selected False, Rank: 75.000\n",
            "Column: 2788, Selected False, Rank: 2735.000\n",
            "Column: 2789, Selected False, Rank: 457.000\n",
            "Column: 2790, Selected False, Rank: 1821.000\n",
            "Column: 2791, Selected False, Rank: 2100.000\n",
            "Column: 2792, Selected False, Rank: 1914.000\n",
            "Column: 2793, Selected False, Rank: 692.000\n",
            "Column: 2794, Selected False, Rank: 2278.000\n",
            "Column: 2795, Selected False, Rank: 1126.000\n",
            "Column: 2796, Selected False, Rank: 226.000\n",
            "Column: 2797, Selected False, Rank: 1033.000\n",
            "Column: 2798, Selected False, Rank: 554.000\n",
            "Column: 2799, Selected False, Rank: 623.000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ZUadgbXCq1k",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 92
        },
        "outputId": "7568de32-43e5-47ef-bc9b-d4803b2cb9d9"
      },
      "source": [
        "print(X.columns[rfe.get_support()]) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Index(['specific_bean_origin_or_bar_name_Malo Island, batch Ma20/19',\n",
            "       'specific_bean_origin_or_bar_name_Venezuela, Trinidad',\n",
            "       'second_taste_sweet'],\n",
            "      dtype='object')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DeHL343N31nv",
        "colab_type": "text"
      },
      "source": [
        "# Filter based univariate selection (Select K Best)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gy9mqu0t32Ps",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#import libraries\n",
        "from sklearn.feature_selection import SelectKBest\n",
        "from sklearn.feature_selection import chi2\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "atmDGtxU38G9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Fit the model\n",
        "bestfeatures = SelectKBest(score_func=chi2, k=10)\n",
        "fit = bestfeatures.fit(X,y)\n",
        "dfscores = pd.DataFrame(fit.scores_)\n",
        "dfcolumns = pd.DataFrame(X.columns)\n",
        "#concatenate the two dataframes\n",
        "featureScores = pd.concat([dfcolumns,dfscores],axis=1)\n",
        "featureScores.columns = ['Specs','Score']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uO4Rdpm63-JK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 284
        },
        "outputId": "f97b268e-ed0f-4c1f-fe44-21e3fc6831a2"
      },
      "source": [
        "#print 10 best features\n",
        "print(featureScores.nlargest(10,'Score').plot(kind='barh'))\n",
        "#plot graph of feature importances \n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "AxesSubplot(0.125,0.125;0.775x0.755)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eHaBrLir4HLY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 111
        },
        "outputId": "a12fd77a-a3a7-4f1f-d2e1-ae94f75a8386"
      },
      "source": [
        "#Name selected features\n",
        "X.iloc[:,62].name,X.iloc[:,127].name,X.iloc[:,1578].name,X.iloc[:,1493].name,X.iloc[:,911].name"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('company_location_U.S.A',\n",
              " 'country_of_bean_origin_Sierra leone',\n",
              " 'first_taste_basic',\n",
              " 'specific_bean_origin_or_bar_name_Venezuela, Trinidad',\n",
              " 'specific_bean_origin_or_bar_name_Malo Island, batch Ma20/19')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DftjvJ2J4D76",
        "colab_type": "text"
      },
      "source": [
        "# Feature Importance"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IQXPWgcO4KGv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.ensemble import ExtraTreesClassifier\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XNWmpRdx4NDT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "6ee0dcb2-8c55-49a3-c304-a567b9a15d48"
      },
      "source": [
        "#Fit the model\n",
        "model = ExtraTreesClassifier()\n",
        "model.fit(X,y)\n",
        "print(model.feature_importances_)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.03010474 0.015886   0.01243555 ... 0.         0.         0.        ]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "21wzD03M4Oik",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "c14fecd9-0886-4e0a-f76f-1bca1c1379b0"
      },
      "source": [
        "#plot graph of feature importances\n",
        "feat_importances = pd.Series(model.feature_importances_, index=X.columns)\n",
        "feat_importances.nlargest(10).plot(kind='barh')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f3sPl0TQ5wSA",
        "colab_type": "text"
      },
      "source": [
        "# Voting Selector using Xuniverse"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0g-9Pcks5w6v",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 375
        },
        "outputId": "7e44a99f-b402-4915-95e2-e53746f66aa1"
      },
      "source": [
        "!pip install xverse\n",
        "from xverse.ensemble import VotingSelector\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting xverse\n",
            "  Downloading https://files.pythonhosted.org/packages/c0/98/2656fa170116f8287d606e2f2c3ddd8ecdbcf04fbedd336c05f870f8043f/xverse-1.0.5-py3-none-any.whl\n",
            "Requirement already satisfied: statsmodels>=0.6.1 in /usr/local/lib/python3.6/dist-packages (from xverse) (0.10.2)\n",
            "Requirement already satisfied: scikit-learn>=0.19.0 in /usr/local/lib/python3.6/dist-packages (from xverse) (0.22.2.post1)\n",
            "Requirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.6/dist-packages (from xverse) (1.18.5)\n",
            "Requirement already satisfied: matplotlib>=3.0.3 in /usr/local/lib/python3.6/dist-packages (from xverse) (3.2.2)\n",
            "Requirement already satisfied: pandas>=0.21.1 in /usr/local/lib/python3.6/dist-packages (from xverse) (1.0.5)\n",
            "Requirement already satisfied: scipy>=0.19.0 in /usr/local/lib/python3.6/dist-packages (from xverse) (1.4.1)\n",
            "Requirement already satisfied: patsy>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from statsmodels>=0.6.1->xverse) (0.5.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.19.0->xverse) (0.16.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=3.0.3->xverse) (2.8.1)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=3.0.3->xverse) (2.4.7)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=3.0.3->xverse) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=3.0.3->xverse) (0.10.0)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.21.1->xverse) (2018.9)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from patsy>=0.4.0->statsmodels>=0.6.1->xverse) (1.15.0)\n",
            "Installing collected packages: xverse\n",
            "Successfully installed xverse-1.0.5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kdrKQ33b57wO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "dc4afe8a-7b60-4f81-d9a7-1377a1ae7166"
      },
      "source": [
        "#Fit the model\n",
        "clf = VotingSelector()\n",
        "clf.fit(X, y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "VotingSelector(exclude_features=None, feature_names='all',\n",
              "               handle_category='woe', minimum_votes=0, no_of_features=1400,\n",
              "               numerical_missing_values='median',\n",
              "               selection_techniques=['WOE', 'RF', 'RFE', 'ETC', 'CS', 'L_ONE'])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gNAAZezo597H",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 493
        },
        "outputId": "d013e180-78a0-42eb-ded6-8fdb7910175e"
      },
      "source": [
        "#Selected features\n",
        "clf.feature_importances_"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Variable_Name</th>\n",
              "      <th>Information_Value</th>\n",
              "      <th>Random_Forest</th>\n",
              "      <th>Recursive_Feature_Elimination</th>\n",
              "      <th>Extra_Trees</th>\n",
              "      <th>Chi_Square</th>\n",
              "      <th>L_One</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>first_taste_basic</td>\n",
              "      <td>3.849388e+00</td>\n",
              "      <td>0.056759</td>\n",
              "      <td>0.793520</td>\n",
              "      <td>0.081863</td>\n",
              "      <td>554.500450</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>company_location_Vanuatu</td>\n",
              "      <td>3.294181e+00</td>\n",
              "      <td>0.060856</td>\n",
              "      <td>0.753728</td>\n",
              "      <td>0.054168</td>\n",
              "      <td>276.252025</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>second_taste_sweet</td>\n",
              "      <td>2.827289e+00</td>\n",
              "      <td>0.054264</td>\n",
              "      <td>1.190692</td>\n",
              "      <td>0.060884</td>\n",
              "      <td>34.812985</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>country_of_bean_origin_Vanuatu</td>\n",
              "      <td>2.625398e+00</td>\n",
              "      <td>0.058440</td>\n",
              "      <td>0.743156</td>\n",
              "      <td>0.024299</td>\n",
              "      <td>90.759076</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>first_taste_gritty</td>\n",
              "      <td>1.767331e+00</td>\n",
              "      <td>0.057376</td>\n",
              "      <td>0.609678</td>\n",
              "      <td>0.042486</td>\n",
              "      <td>18.657932</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2795</th>\n",
              "      <td>specific_bean_origin_or_bar_name_Bocas del Toro</td>\n",
              "      <td>2.025861e-07</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000900</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2796</th>\n",
              "      <td>specific_bean_origin_or_bar_name_Blue Mountain...</td>\n",
              "      <td>2.025861e-07</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000900</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2797</th>\n",
              "      <td>specific_bean_origin_or_bar_name_Blue Mountain</td>\n",
              "      <td>2.025861e-07</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000900</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2798</th>\n",
              "      <td>specific_bean_origin_or_bar_name_Blend No. 1</td>\n",
              "      <td>2.025861e-07</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000900</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2799</th>\n",
              "      <td>beans_have_bean</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2800 rows × 7 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                          Variable_Name  ...  L_One\n",
              "0                                     first_taste_basic  ...    0.0\n",
              "1                              company_location_Vanuatu  ...    0.0\n",
              "2                                    second_taste_sweet  ...    0.0\n",
              "3                        country_of_bean_origin_Vanuatu  ...    0.0\n",
              "4                                    first_taste_gritty  ...    0.0\n",
              "...                                                 ...  ...    ...\n",
              "2795    specific_bean_origin_or_bar_name_Bocas del Toro  ...    0.0\n",
              "2796  specific_bean_origin_or_bar_name_Blue Mountain...  ...    0.0\n",
              "2797     specific_bean_origin_or_bar_name_Blue Mountain  ...    0.0\n",
              "2798       specific_bean_origin_or_bar_name_Blend No. 1  ...    0.0\n",
              "2799                                    beans_have_bean  ...    0.0\n",
              "\n",
              "[2800 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hmqhvPOw6B8m",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 284
        },
        "outputId": "e8d9a7df-97ee-43ba-a40c-b7b70bee8099"
      },
      "source": [
        "print(clf.feature_importances_['Random_Forest'].nlargest(10).plot(kind='barh'))\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "AxesSubplot(0.125,0.125;0.775x0.755)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3rKzdIxQ6KMO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 56
        },
        "outputId": "9c1467ee-1726-4c5f-91c5-ae698a6d8984"
      },
      "source": [
        "#Name selected features\n",
        "print(\n",
        "clf.feature_importances_['Variable_Name'][2],\n",
        "clf.feature_importances_['Variable_Name'][1],\n",
        "clf.feature_importances_['Variable_Name'][12],\n",
        "clf.feature_importances_['Variable_Name'][13])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "second_taste_sweet company_location_Vanuatu specific_bean_origin_or_bar_name_Malo Island, batch Ma20/19 specific_bean_origin_or_bar_name_Venezuela, Trinidad\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}